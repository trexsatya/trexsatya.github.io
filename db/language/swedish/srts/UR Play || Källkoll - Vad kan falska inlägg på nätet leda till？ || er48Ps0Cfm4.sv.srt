1
00:00:02,120 --> 00:00:05,360
-Kolla, Edwin, jag fick ut honom! 
-Ja...

2
00:00:05,520 --> 00:00:09,080
Edwin, hur är det fatt? 
Du ser så nedstämd ut.

3
00:00:09,240 --> 00:00:15,120
Det visade ju sig att massor av 
mina följare, mina Safaris, var fejk.

4
00:00:15,280 --> 00:00:20,880
Jag pratade med min byrå och 
de skulle kolla vad som hade hänt.

5
00:00:21,040 --> 00:00:25,480
Det kanske är fejkföljare. 
Köpta, bluff, fejk, liksom.

6
00:00:25,640 --> 00:00:31,720
-Som de köpte. 
-Nu tittar jag på en av mina följare.

7
00:00:31,880 --> 00:00:35,200
-Jaha. 
-Jag blir helt osäker.

8
00:00:35,360 --> 00:00:38,240
-På vadå? 
-Om hon ens finns!

9
00:00:38,400 --> 00:00:44,560
Är hon en hon? Tänk om det är ett 
datorprogram som lajkar mina grejer-

10
00:00:44,720 --> 00:00:48,720
-eller en hacker 
på nån "click farm" i nåt land-

11
00:00:48,880 --> 00:00:55,520
-eller ett troll som sitter 
och skrattar åt mina amazing videos.

12
00:00:56,520 --> 00:01:00,760
Det är svårt att veta 
vem som döljer sig bakom fejkkonton.

13
00:01:00,920 --> 00:01:05,400
Nu i veckan, på SVT Nyheter, 
så hade de ett företag i Skåne-

14
00:01:05,560 --> 00:01:08,560
-som avslöjades 
i en korruptionshärva.

15
00:01:08,720 --> 00:01:13,320
Det visade sig att pressansvarig 
på företaget var en påhittad person.

16
00:01:31,040 --> 00:01:33,120
Va? Så hon fanns inte alls?

17
00:01:33,280 --> 00:01:39,640
Nej, de hade använt en sida på nätet 
där man kan randomisera ansikten-

18
00:01:39,800 --> 00:01:44,360
-och det genereras ett ansikte 
som egentligen inte finns.

19
00:01:44,520 --> 00:01:48,840
Man får nog acceptera ovissheten 
som är på sociala medier.

20
00:01:49,000 --> 00:01:52,120
Man vet inte 
om den man pratar med finns.

21
00:01:52,280 --> 00:01:57,000
Många sajter tillåter en 
att döpa sig till vad man vill.

22
00:01:57,160 --> 00:02:00,960
På Facebook ska man ju ha 
sitt riktiga namn-

23
00:02:01,120 --> 00:02:06,080
-men även där är det lätt att skapa 
nya konton och heta nåt annat.

24
00:02:06,240 --> 00:02:11,240
På andra sociala medier eller forum 
kan man döpa sig till vad man vill.

25
00:02:11,400 --> 00:02:15,680
"Skinn62" eller "Lars den fete" 
eller vad sjutton som helst.

26
00:02:15,840 --> 00:02:20,640
Den där anonymiteten är ju där 
för att vi ska kunna använda den.

27
00:02:20,800 --> 00:02:25,400
-Det blir så på internet. 
-Man kanske inte vill vara sig själv.

28
00:02:25,560 --> 00:02:31,600
Nej, och det ska man inte behöva 
vara. Anonymiteten är också bra.

29
00:02:31,760 --> 00:02:36,920
Med den kan vi bli visselblåsare 
eller larma om missförhållanden-

30
00:02:37,080 --> 00:02:40,280
-och säga till 
när nåt inte står rätt till.

31
00:02:40,440 --> 00:02:45,920
Det blir uselt när många blir rädda 
för att inte kunna berätta saker-

32
00:02:46,080 --> 00:02:50,080
-som de upplever. 
Så anonymiteten behövs.

33
00:02:50,240 --> 00:02:53,640
Men kom ihåg 
att allt inte är svart och vitt.

34
00:02:53,800 --> 00:02:56,640
Anonymiteten kan leda till problem.

35
00:02:56,800 --> 00:03:02,840
En som gömmer sig bakom anonymi- 
teten kan häckla, håna, hata eller hota.

36
00:03:03,000 --> 00:03:06,920
-Så det finns problem med anonymitet. 
-Åh...

37
00:03:07,080 --> 00:03:10,960
Hela livet är en lögn. 
Vad mer är inte på riktigt?

38
00:03:11,120 --> 00:03:17,200
Just nu har du ett "rycka undan 
mattan under fötterna"-moment-

39
00:03:17,360 --> 00:03:22,640
-och det är jobbigt, men det är det 
här vi gör "Källkoll"-programmen om.

40
00:03:22,800 --> 00:03:27,120
Vad är fejk på nätet 
och vad blir konsekvenserna av det?

41
00:03:27,280 --> 00:03:30,840
Nu är det dags för tre viktiga saker:

42
00:03:31,000 --> 00:03:35,680
Frisk luft, fika 
och lite brainstormning.

43
00:03:50,720 --> 00:03:55,400
Skulle du säga att du är bra på 
att upptäcka falska nyheter?

44
00:03:55,560 --> 00:04:02,040
Nej, egentligen inte. Jag är inte 
jättenoga med att faktakolla.

45
00:04:02,200 --> 00:04:04,120
Ja, det skulle jag säga.

46
00:04:04,280 --> 00:04:07,640
-O ja. 
-Ja.

47
00:04:07,800 --> 00:04:12,840
Men vissa saker är väldigt svåra 
att säga emot.

48
00:04:13,000 --> 00:04:15,640
Man ska inte vara för självsäker.

49
00:04:15,800 --> 00:04:17,280
Nej.

50
00:04:17,440 --> 00:04:24,920
Det beror väl på vad det gäller för 
ämne och hur insatt man är i det.

51
00:04:25,920 --> 00:04:28,920
Jag vill säga ja, 
men man är nog ofta dålig.

52
00:04:29,080 --> 00:04:33,040
Ja, jag är ganska skolad i det 
genom alla år.

53
00:04:33,200 --> 00:04:34,680
Nej.

54
00:04:34,840 --> 00:04:38,680
Folk gör allt möjligt dumt 
när de är anonyma.

55
00:04:38,840 --> 00:04:42,040
Under Melodifestivalen 
som Tusse vann...

56
00:04:42,200 --> 00:04:47,200
96 poäng, vilket betyder att Tusse 
har vunnit Melodifestivalen 2021!

57
00:04:47,360 --> 00:04:54,080
Nån ändrade Tusses Wikipediaartikel 
så att det stod att han fuskade.

58
00:04:54,240 --> 00:04:58,920
Det låg inte ute så länge 
och den som gjorde det blev blockad.

59
00:04:59,080 --> 00:05:02,320
Okej, 
men det låter ju inte jättefarligt.

60
00:05:02,480 --> 00:05:06,480
-Sen skrev de att han var död. 
-Oj, det var ganska onajs.

61
00:05:08,440 --> 00:05:12,240
Wikipedia är ett uppslagsverk 
alla kan redigera.

62
00:05:12,400 --> 00:05:16,920
Att alla kan redigera betyder 
att vissa kan förstöra-

63
00:05:17,080 --> 00:05:21,680
-men på Wikipedia finns ett starkt 
community med seriösa redaktörer-

64
00:05:21,840 --> 00:05:25,840
-som brukar slå ner stenhårt 
på den typen av klotter.

65
00:05:26,000 --> 00:05:28,000
Så kan man lita på dem, då?

66
00:05:28,160 --> 00:05:32,640
Egentligen ska du nog utgå från 
att du ska kolla allt du ser...

67
00:05:32,800 --> 00:05:37,960
-...i forum och kommentarsfält. 
-Allt är alltid värt att dubbelkolla.

68
00:05:38,120 --> 00:05:42,120
Särskilt när det kommer till 
overifierade konton.

69
00:05:42,280 --> 00:05:46,840
Att tro på vad de säger rakt av 
är som att tro på rykten.

70
00:05:47,000 --> 00:05:50,400
Vi har sagt 
att vi ska prata om journalister-

71
00:05:50,560 --> 00:05:54,160
-och hur de jobbar med 
att bekräfta uppgifter.

72
00:05:54,320 --> 00:05:59,240
Sen när man ser nåt är det lika bra 
att gå ut och kolla på nyhetsmedier-

73
00:05:59,400 --> 00:06:01,240
-och se vad som skrivs.

74
00:06:01,400 --> 00:06:05,440
Om de pratar om obekräftade uppgifter 
så ska man veta-

75
00:06:05,600 --> 00:06:09,000
-att en obekräftad uppgift 
inte måste vara falsk-

76
00:06:09,160 --> 00:06:13,360
-men man bör vänta och se 
hur det utvecklas.

77
00:06:13,520 --> 00:06:18,880
Det är fejkgrejerna med verkliga 
konsekvenser som vi pratar om här.

78
00:06:19,040 --> 00:06:23,640
Att nån sitter bakom 
ett anonymt konto-

79
00:06:23,800 --> 00:06:30,320
-och skriver en massa grejer. Det kan 
väl växa och get out of control?

80
00:06:30,480 --> 00:06:32,840
Ja, redan på medeltiden...

81
00:06:33,000 --> 00:06:37,560
Inte dina uråldriga exempel! 
Har vi nåt lite mer färskt?

82
00:06:37,720 --> 00:06:42,040
Instagramupploppet i Göteborg är 
ett bra exempel.

83
00:06:43,960 --> 00:06:48,360
Bråket, som utvecklades till nåt 
som kan liknas vid ett upplopp-

84
00:06:48,520 --> 00:06:53,720
-har sitt ursprung i ett stort antal 
bilder publicerade på Instagram.

85
00:06:53,880 --> 00:06:59,040
Det är ett bra exempel på nåt litet 
som sen blir som ett monster-

86
00:06:59,200 --> 00:07:03,200
-som inte kan kontrolleras. 
Det är ett bra exempel.

87
00:07:03,360 --> 00:07:07,760
Det här var ju några tjejer 
som startade ett Instagramkonto-

88
00:07:07,920 --> 00:07:14,080
-och sen började de lägga ut skvaller 
och rykten om andra tjejers sexliv.

89
00:07:14,240 --> 00:07:18,920
Herregud! Jag minns det där! Jag 
bodde där då. Men det var ju 2012.

90
00:07:19,080 --> 00:07:23,480
Ja, men det är ju inte som att folk 
inte hänger ut varandra på nätet nu.

91
00:07:23,640 --> 00:07:27,040
Principerna är desamma. 
Det är nåt litet-

92
00:07:27,200 --> 00:07:30,600
-nåt i ett kommentarsfält 
eller i nåt forum-

93
00:07:30,760 --> 00:07:35,360
-och sen börjar folk bry sig i en 
vidare krets och så rullar det på.

94
00:07:35,520 --> 00:07:38,080
I det här fallet blev det kalabalik-

95
00:07:38,240 --> 00:07:41,840
-när folk skulle leta rätt 
på dem som gjort kontot.

96
00:07:42,000 --> 00:07:43,840
Oskyldiga hängdes ut.

97
00:07:44,000 --> 00:07:48,560
För att inte tala om hur det kändes 
för tjejerna som blev uthängda.

98
00:07:48,720 --> 00:07:53,480
Okej, men vi hoppar till modern tid. 
Ni faktagranskar saker på nätet.

99
00:07:53,640 --> 00:07:58,800
Senaste året har verkligen falska 
grejer fått verkliga konsekvenser.

100
00:07:58,960 --> 00:08:02,320
Gud, ja. Det räcker 
att titta på covid-testerna-

101
00:08:02,480 --> 00:08:07,280
-som folk fått för sig 
att de inte funkar, är falska.

102
00:08:07,440 --> 00:08:10,440
Vi kollade på den 
konspirationsteorin-

103
00:08:10,600 --> 00:08:15,800
-och den byggde på att folk som 
inte hade rätt kunskaper i frågan-

104
00:08:15,960 --> 00:08:20,000
-hade hittat detaljer 
i olika vetenskapliga studier-

105
00:08:20,160 --> 00:08:24,200
-och sen snurrat om det 
i till exempel Facebookgrupper.

106
00:08:24,360 --> 00:08:30,120
Ja. Konsekvensen av det blev att 
läkare på Sahlgrenska sjukhuset sa-

107
00:08:30,280 --> 00:08:33,880
-människor som var inne för annat 
vägrade ta covid-test-

108
00:08:34,040 --> 00:08:37,240
-trots att det är bra för dem 
att veta om de har det.

109
00:08:37,400 --> 00:08:42,080
Sen var det en kavalkad av helt 
felaktiga påståenden under året.

110
00:08:42,240 --> 00:08:47,360
Sen ser jag desinficeringsmedlet. 
Det slår ut det på en minut.

111
00:08:47,520 --> 00:08:54,280
En minut.Och kan vi göra 
nåt liknande, genom injektion-

112
00:08:54,440 --> 00:08:57,200
-eller nästan som att städa.

113
00:08:57,360 --> 00:08:59,640
Att vaccinet förändrar ditt DNA.

114
00:08:59,800 --> 00:09:03,360
Varken mRNA-vaccinet 
eller de andra som utvecklas-

115
00:09:03,520 --> 00:09:05,720
-har potential 
att förändra vårt DNA.

116
00:09:05,880 --> 00:09:08,440
Att du får syrebrist av 
att ha masker.

117
00:09:08,600 --> 00:09:12,120
Långvarig användning av 
masker kan vara obekvämt.

118
00:09:12,280 --> 00:09:16,720
Men det leder inte till koldioxid- 
förgiftning eller syrebrist.

119
00:09:16,880 --> 00:09:19,960
Att vaccinerna är 
otestade och farliga.

120
00:09:20,120 --> 00:09:23,600
Allt fler människor 
tänker inte ta vaccin.

121
00:09:23,760 --> 00:09:26,400
Jag vill inte injicera nåt sånt.

122
00:09:26,560 --> 00:09:28,760
Att det finns mikrochip i vaccinen.

123
00:09:28,920 --> 00:09:35,320
Dr Rose, första frågan: Finns det 
mikrochip i covid-vaccinet?

124
00:09:35,480 --> 00:09:38,640
Nej. Det finns inga mikrochip 
i vaccinet.

125
00:09:38,800 --> 00:09:41,920
Bara vaccin 
och lite av en kemikalie-

126
00:09:42,080 --> 00:09:45,960
-som gör att man reagerar rätt 
på vaccinet.

127
00:09:46,120 --> 00:09:49,240
Att 5G-nätet, 
det här med mobiltelefoni-

128
00:09:49,400 --> 00:09:53,520
-har nåt med coronavirus att göra, 
vilket det inte har.

129
00:09:53,680 --> 00:09:58,400
Jag känner igen det här från 
demonstrationsplakat jag har sett.

130
00:10:15,280 --> 00:10:21,080
Det var planerat att hålla en 
demonstration på Medborgarplatsen.

131
00:10:21,240 --> 00:10:25,320
-Den hade inte polisens tillstånd. 
-...mot ordningsmakten...

132
00:10:25,480 --> 00:10:29,200
Det har skapat effekter 
i verkligheten.

133
00:10:29,360 --> 00:10:32,640
Konspirationsteorierna 
kring vaccinet och viruset-

134
00:10:32,800 --> 00:10:36,720
-har skapat en mindre, 
men högljudd, grupp...

135
00:10:36,880 --> 00:10:40,720
-...som inte tror på covid-19. 
-Att det inte finns alls?

136
00:10:40,880 --> 00:10:45,520
En del tror så, andra kanske mer 
att vaccinen och viruset-

137
00:10:45,680 --> 00:10:48,800
-är en del 
av nån slags diabolisk plan-

138
00:10:48,960 --> 00:10:52,200
-från en elit 
som de tror styr i skuggorna.

139
00:10:52,360 --> 00:10:56,560
Och att världens makthavare 
antingen dansar till deras pipa-

140
00:10:56,720 --> 00:10:59,080
-eller är med i konspirationen.

141
00:10:59,240 --> 00:11:02,400
Okej, men då är det väl 
ett bra exempel?

142
00:11:02,560 --> 00:11:06,840
Det är ju ett färgstarkt exempel, 
spektakulärt och maxat-

143
00:11:07,000 --> 00:11:11,280
-men vill man verkligen sätta ljus 
på den gruppen av idéer?

144
00:11:11,440 --> 00:11:15,400
Hur stor är den egentligen? 
Hur många tror på det?

145
00:11:15,560 --> 00:11:19,360
Är inte risken att man bara 
visar upp idén för nya?

146
00:11:19,520 --> 00:11:22,640
Frågan är hur representativa de är.

147
00:11:22,800 --> 00:11:26,080
Det får vi se nu 
när det ska vaccineras i stor skala.

148
00:11:26,240 --> 00:11:30,280
Flera gånger har till och med 
vårdpersonal vägrat vaccinera sig.

149
00:11:30,440 --> 00:11:33,280
-Ja. 
-Å andra sidan, man får låta bli.

150
00:11:33,440 --> 00:11:35,680
-Det är helt okej. 
-Ja.

151
00:11:35,840 --> 00:11:40,160
Och man får vara kritisk mot 
restriktionerna och mot lagar.

152
00:11:40,320 --> 00:11:43,920
-Det här är ju åsikter. 
-Mycket "å ena sidan, å andra sidan".

153
00:11:44,080 --> 00:11:48,200
-Det blir dålig tv. 
-Det är så att vara faktagranskare.

154
00:11:48,360 --> 00:11:53,440
Det är svårt att avgöra vad man 
ska ta upp ge uppmärksamhet.

155
00:11:53,600 --> 00:11:57,720
Riskerar man att sprida nåt, 
eller är det bra att motbevisa det?

156
00:11:57,880 --> 00:12:02,680
-Sånt brottas vi med varje dag. 
-Ja, och konspirationsteoretiker...

157
00:12:02,840 --> 00:12:05,960
-Foliehattar. 
-Att kalla dem så...

158
00:12:06,120 --> 00:12:09,080
...gör bara 
att man vidgar en klyfta här.

159
00:12:09,240 --> 00:12:14,640
Det är svårt att närma sig varandra 
när man kallat nån dum i huvudet.

160
00:12:14,800 --> 00:12:17,920
Ja, det här har splittrat 
fler än en familj.

161
00:12:18,080 --> 00:12:21,040
Vissa har förlorat vänner 
på grund av sånt här.

162
00:12:21,200 --> 00:12:24,360
Det är en problematisk konsekvens 
i verkliga livet-

163
00:12:24,520 --> 00:12:27,000
-att det påverkar 
hur vi är mot varandra-

164
00:12:27,160 --> 00:12:31,920
-och hur vi litar på varandra 
och på samhällsinstitutioner.

165
00:12:32,080 --> 00:12:35,520
-Det är en konsekvens. 
-Vad är det värsta...

166
00:12:35,680 --> 00:12:38,840
-...med falska grejer på nätet? 
-Var ska man börja?

167
00:12:39,000 --> 00:12:42,200
Ja, det är ett stort område. 
Vi gör det enklare.

168
00:12:42,360 --> 00:12:45,840
Vilket är det hemskaste exemplet 
ni själva tycker-

169
00:12:46,000 --> 00:12:50,520
-om nåt som har varit falskt 
och fått en verklig konsekvens?

170
00:12:50,680 --> 00:12:55,840
Det är till exempel, tycker jag, 
rörelsen kring vaccinmotståndet-

171
00:12:56,000 --> 00:13:00,120
-där man på olika sätt utnyttjar 
föräldrar vars barn dött.

172
00:13:00,280 --> 00:13:04,560
Anna Nordbeck, granskande reporter 
på "Dokument inifrån".

173
00:13:04,720 --> 00:13:09,120
Det som är gemensamt 
för hur vaccinmotståndarna hanterar-

174
00:13:09,280 --> 00:13:13,560
-den här typen av berättelser om folk 
som förlorat sitt barn-

175
00:13:13,720 --> 00:13:17,920
-i en förebyggbar sjukdom 
som mässling är att påpeka-

176
00:13:18,080 --> 00:13:22,000
-att oavsett så är vaccinet farligare 
än själva sjukdomen.

177
00:13:22,160 --> 00:13:26,680
Jag har pratat med folk som säger 
att mässling inte är en sjukdom-

178
00:13:26,840 --> 00:13:30,760
-och att mässling inte kan döda, 
vilket är helt felaktigt.

179
00:13:30,920 --> 00:13:34,240
Det handlar om att försöka föra fram-

180
00:13:34,400 --> 00:13:39,400
-att det inte är allvarliga sjukdomar 
och att vaccin är farligt.

181
00:13:39,560 --> 00:13:43,560
Men det finns jättemånga bra tips här 
att ge.

182
00:13:43,720 --> 00:13:46,480
Det här kan vi göra ett inslag om 
i vår kanal.

183
00:13:46,640 --> 00:13:51,400
Okej, men upptempo den här gången. 
Kom ihåg var jag lärde dig.

184
00:13:52,320 --> 00:13:56,720
Falska påståenden på nätet 
kan orsaka rejält med skada.

185
00:13:56,880 --> 00:13:59,840
Här är några tips 
för att inte bli en del av det-

186
00:14:00,000 --> 00:14:02,960
-när du delar vidare saker 
i dina flöden.

187
00:14:03,120 --> 00:14:08,080
Tips ett: Utgå ifrån 
att nåt är fel eller fejk.

188
00:14:08,240 --> 00:14:12,400
Tänk som att det är första april 
och du inte vill gå på nåt-

189
00:14:12,560 --> 00:14:14,960
-när du är ute i sociala medier.

190
00:14:15,120 --> 00:14:20,200
Tips två: Kolla upp det. 
Om nåt var intressant nog att dela-

191
00:14:20,360 --> 00:14:25,120
-är det absolut tillräckligt viktigt 
att kolla upp om det stämmer.

192
00:14:25,280 --> 00:14:30,840
Även om det bara är nåt du läser kan 
det vara väl värt att kolla även det-

193
00:14:31,000 --> 00:14:34,320
-eftersom det kan påverka 
din bild av verkligheten.

194
00:14:34,480 --> 00:14:40,920
Tips tre: Tänk på effekterna, 
för dig, för den du skriver om.

195
00:14:41,080 --> 00:14:43,840
Kan det här orsaka skada för nån?

196
00:14:44,000 --> 00:14:47,320
Tips fyra: Tänk på 
att saker kan skala upp.

197
00:14:47,480 --> 00:14:50,080
Det här lilla, lilla du skriver-

198
00:14:50,240 --> 00:14:52,840
-eller postar om i ditt flöde-

199
00:14:53,000 --> 00:14:56,600
-ligger ganska öppet, 
och om många börjar dela nåt-

200
00:14:56,760 --> 00:15:01,080
-och nåt blir viralt, kan det få 
konsekvenser du inte föreställt dig.

201
00:15:03,280 --> 00:15:05,840
Åh. - Hallå?

202
00:15:06,880 --> 00:15:09,640
Ja. Okej. Jag fattar.

203
00:15:11,000 --> 00:15:15,320
Åh, vill ni? Ja, men absolut.

204
00:15:15,480 --> 00:15:18,360
-Okej! 
-Vad är det som händer?

205
00:15:18,520 --> 00:15:21,200
Perfect Beautiful Amazing 
Digital Media AB!

206
00:15:21,360 --> 00:15:24,360
De vill göra ett samarbete med mig. 
Det största som hänt-

207
00:15:24,520 --> 00:15:26,800
-sen Travis Scotts Fortnite-konsert.

208
00:15:26,960 --> 00:15:31,720
-Litar du på dem fortfarande? 
-Allt det här snacket om "lita på"...

209
00:15:31,880 --> 00:15:36,840
Jag väljer lycka! 
Det blir fantastiskt. Kör fram bilen!

210
00:15:37,000 --> 00:15:39,320
Ja, ja. Okej då.

211
00:15:39,480 --> 00:15:44,720
Let's go! Perfect Beautiful Amazing 
Digital Media AB, here we come!

212
00:15:44,880 --> 00:15:48,880
Svensktextning: A. Thorén/M. Karlsson 
Iyuno Media Group för UR

