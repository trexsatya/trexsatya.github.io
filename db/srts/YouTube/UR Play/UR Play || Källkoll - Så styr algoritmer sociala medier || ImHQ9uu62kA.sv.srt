1
00:00:02,920 --> 00:00:10,400
Wow, vilket ställe! 
Men... Jack? Jack?

2
00:00:10,560 --> 00:00:16,160
-Hallå! Här är jag! 
-Jaha, där hamnade du?

3
00:00:16,320 --> 00:00:19,320
Det händer galna grejer 
i min kanal ibland.

4
00:00:19,480 --> 00:00:22,200
Har du hundratusentals följare?

5
00:00:22,360 --> 00:00:26,280
Yes! Tricket är att gå upp 
med jämna mellanrum på natten-

6
00:00:26,480 --> 00:00:28,480
-för att täcka olika grupper.

7
00:00:28,640 --> 00:00:33,920
Jag är det tredje största kontot 
på Nya Zeeland efter fågeln Hector.

8
00:00:34,080 --> 00:00:35,840
Wow!

9
00:00:36,000 --> 00:00:40,480
Ni förstår inte riktigt sociala 
medier. Vi går igenom dem!

10
00:00:40,640 --> 00:00:43,840
-Men... 
-Lyssna, jag gillar er.

11
00:00:44,000 --> 00:00:48,520
Men er kanal är lite... 
Alltså, ni behöver lite mer...

12
00:00:48,680 --> 00:00:54,680
Alltså, väv in det... med lite la! 
Lite musik, unga människor.

13
00:00:54,840 --> 00:00:57,840
Roligt ska det vara! 
En najs bakgrund.

14
00:00:58,000 --> 00:00:59,960
Du har helt rätt, Edwin!

15
00:01:00,120 --> 00:01:03,080
Och lite ikoniska outfits.

16
00:01:08,360 --> 00:01:09,920
Anyway...

17
00:01:10,080 --> 00:01:15,080
Och slipa på ert budskap. 
Ni pratar om hundra saker samtidigt.

18
00:01:15,240 --> 00:01:18,320
Men det är intressanta saker 
vi pratar om.

19
00:01:18,480 --> 00:01:23,280
Välj en grej och fokusera på den. 
Det ska vara tydligt och lättsamt.

20
00:01:23,440 --> 00:01:27,560
Ni vill ha fler följare, va? 
Vilka följer er nu?

21
00:01:27,720 --> 00:01:32,920
Ja... Vi ska se... 
Ulla-Britt i Växjö, bibliotekarie.

22
00:01:33,080 --> 00:01:36,320
Titta, hon har roliga bilder 
på sin katt!

23
00:01:36,480 --> 00:01:39,480
Ens följare brukar ju vara 
som en själv är.

24
00:01:39,640 --> 00:01:45,520
När vuxna försöker vara "down 
with the kids" kan det bli cringe.

25
00:01:45,680 --> 00:01:49,280
Sociala medier handlar ju 
om att kunna spegla sig-

26
00:01:49,440 --> 00:01:53,120
-och relatera till den 
som blir avsändaren.

27
00:01:53,280 --> 00:01:55,800
Det blir ju lite av en åldersfråga.

28
00:01:55,960 --> 00:02:00,840
På tal om det, jag blir snurrig här. 
Kan vi sätta oss nån annanstans?

29
00:02:01,000 --> 00:02:04,360
-Vi går ut härifrån. 
-Okej.

30
00:02:20,240 --> 00:02:24,840
-Jag får inte ut honom ur kanalen. 
-Det gör väl inget.

31
00:02:27,600 --> 00:02:30,800
Konstigt att du inte hört av 
nåt företag-

32
00:02:30,960 --> 00:02:34,960
-som vill att du ska göra reklam 
för nån produkt.

33
00:02:35,120 --> 00:02:37,560
Funny you should say that, Åsa!

34
00:02:37,720 --> 00:02:43,680
Jag har fått ett kontrakt med Perfect 
Beautiful Amazing Digital Media AB.

35
00:02:43,840 --> 00:02:46,200
De sköter mina sociala medier.

36
00:02:46,360 --> 00:02:50,560
Sociala medier är en bra grej 
att ta upp i "Källkoll".

37
00:02:50,720 --> 00:02:53,800
De påverkar vår tids 
informationsflöde.

38
00:02:53,960 --> 00:02:58,880
Många får sin information 
nästan bara från sociala medier.

39
00:02:59,040 --> 00:03:03,360
Precis! Man pratar ju om 
sociala medieplattformar-

40
00:03:03,520 --> 00:03:07,680
-och då menar man kanske 
främst tekniken-

41
00:03:07,840 --> 00:03:12,240
-alltså, hur det ser ut under huven 
på Youtube och så vidare.

42
00:03:12,400 --> 00:03:15,440
Men man menar också världen 
som uppstår-

43
00:03:15,600 --> 00:03:19,920
-när vi interagerar med varandra.

44
00:03:20,080 --> 00:03:24,760
Typ algoritmer? 
De är läskigt accurate ibland.

45
00:03:24,920 --> 00:03:27,080
Hur funkar de rent tekniskt?

46
00:03:27,240 --> 00:03:30,920
Jag heter Ania 
och jobbar på tidningen "Ny Teknik".

47
00:03:31,080 --> 00:03:34,520
Algoritmer funkar lite som recept.

48
00:03:34,680 --> 00:03:42,120
Om du tänker dig att informationen 
är ingredienserna i ett recept-

49
00:03:42,280 --> 00:03:45,640
-och sen kommer du att få 
ett visst resultat.

50
00:03:45,800 --> 00:03:49,360
En viss kaka, 
om vi ska ta en sån jämförelse.

51
00:03:49,520 --> 00:03:52,840
I sociala medier-sammanhang 
kan man säga-

52
00:03:53,000 --> 00:03:58,840
-att algoritmerna framför allt 
hjälper till att sortera innehåll-

53
00:03:59,000 --> 00:04:04,800
-och bestämmer vad du som användare 
ser först i ditt flöde-

54
00:04:04,960 --> 00:04:08,600
-eller vilken typ av innehåll 
som du ser mer av.

55
00:04:08,760 --> 00:04:13,240
Det kan vara baserat på vem du är 
och vad du har gillat och följt-

56
00:04:13,400 --> 00:04:18,400
-men också vad dina vänner har följt 
och kommenterat, eller var du bor.

57
00:04:18,560 --> 00:04:23,280
Det viktiga är att algoritmerna 
inte är skapade från ingenstans.

58
00:04:23,440 --> 00:04:27,240
Människor skapar dem. 
De är inte alltid perfekta.

59
00:04:27,400 --> 00:04:33,960
Man tänker att de gör ett perfekt 
individanpassat innehåll för dig.

60
00:04:34,120 --> 00:04:39,480
Men det kan slå fel och det tror jag 
att många har märkt vid annonser.

61
00:04:39,640 --> 00:04:43,280
Man kan undra: 
"Varför får jag den här?"

62
00:04:43,440 --> 00:04:47,720
Då har den samlat in en massa 
olika information och bestämt:

63
00:04:47,880 --> 00:04:51,280
"Det här är nog den typ av kaka 
som passar."

64
00:04:51,440 --> 00:04:53,040
Okej!

65
00:04:53,200 --> 00:04:59,400
Men algoritmer är gjorda av människor 
och får med sig våra fördomar.

66
00:04:59,560 --> 00:05:01,040
Hur då?

67
00:05:01,200 --> 00:05:04,320
Blunda och föreställ dig en sko.

68
00:05:04,480 --> 00:05:07,400
Okej. Såg den ut så här?

69
00:05:07,560 --> 00:05:10,680
Så här? Eller kanske så här?

70
00:05:10,840 --> 00:05:16,400
Vi vet kanske inte varför, men alla 
föredrar en sko över en annan.

71
00:05:16,560 --> 00:05:20,480
Tänk dig att du ska lära en dator 
vad en sko är.

72
00:05:20,640 --> 00:05:23,280
Du kanske lär den 
dina egna åsikter.

73
00:05:23,440 --> 00:05:26,280
Så tar sig fördomar in 
i maskininlärning.

74
00:05:26,440 --> 00:05:30,920
Youtube har ju anklagats för att 
deras förslag till nästa video-

75
00:05:31,080 --> 00:05:32,920
-har radikaliserat folk.

76
00:05:33,080 --> 00:05:37,160
Folk börjar med matlagning 
och blir konspirationsteoretiker.

77
00:05:37,320 --> 00:05:41,520
Är inte det ett sätt som teknik 
interagerar med våra tankar?

78
00:05:41,680 --> 00:05:45,000
Precis, det är svårt 
att gå till botten med sånt.

79
00:05:45,160 --> 00:05:49,520
Teknikföretagen är inte så öppna 
med hur algoritmerna funkar.

80
00:05:49,680 --> 00:05:53,840
Man får inte veta receptet 
för att nåt ska bli tokviralt.

81
00:05:54,000 --> 00:05:58,280
-För då skulle vi utnyttja det? 
-Precis, gejma systemet.

82
00:05:58,440 --> 00:06:01,240
Men ibland har det varit uppenbart.

83
00:06:01,400 --> 00:06:08,280
På Facebook har arga klick 
lett till virala saker.

84
00:06:08,440 --> 00:06:12,800
Vilka sociala medier finns det? 
Vilka är störst?

85
00:06:12,960 --> 00:06:15,760
-Facebook. 
-Om du är typ 40.

86
00:06:15,920 --> 00:06:18,640
Jag skulle säga Tiktok.

87
00:06:18,800 --> 00:06:23,720
Tiktok är på uppåtgående, 
men de är inte riktigt där än.

88
00:06:23,880 --> 00:06:30,240
Tiktok har som alla såna appar fått 
problem med misstankar om säkerhet-

89
00:06:30,400 --> 00:06:34,320
-och hur de använder data 
och kopplingen till Kina.

90
00:06:34,480 --> 00:06:39,440
I ett land där massövervakning är 
vanligt, både på gatan och internet-

91
00:06:39,600 --> 00:06:43,160
-kan man anta att det även gäller 
datan Tiktok samlar in.

92
00:06:43,320 --> 00:06:48,040
Det har upptäckts att appen utnyttjat 
en sårbarhet i Apples telefoner-

93
00:06:48,200 --> 00:06:53,680
-som gjort att man kunnat läsa allt 
som användaren har kopierat.

94
00:06:53,840 --> 00:06:58,680
Facebook har också haft en del 
kring säkerhet och användardata.

95
00:06:58,840 --> 00:07:04,280
Min vän gjorde ett quiz som hette 
"This is your digitial life".

96
00:07:04,440 --> 00:07:09,280
Det gjorde att de fick tag på 
information om mig-

97
00:07:09,440 --> 00:07:12,760
-som sen användes av 
Cambridge Analytica.

98
00:07:12,920 --> 00:07:18,160
Det här var ett stort svek. 
Jag ber om ursäkt för att det hände.

99
00:07:18,320 --> 00:07:21,800
Det är vårt ansvar 
att skydda folks data.

100
00:07:21,960 --> 00:07:25,520
Ryska hackare försökte påverka 
det amerikanska valet.

101
00:07:25,680 --> 00:07:31,360
En rysk påverkanskampanj 
som godkänts på högsta nivå.

102
00:07:31,520 --> 00:07:38,440
Du påstår att du kan ta dig in 
på mitt Facebook-konto.

103
00:07:38,600 --> 00:07:42,280
Och där har vi din Facebook.

104
00:07:42,440 --> 00:07:48,440
Facebook och Tiktok är inte de enda 
som har de här problemen.

105
00:07:48,600 --> 00:07:52,560
Som Clubhouse, den nya appen 
där man snackar med varandra.

106
00:07:52,720 --> 00:07:58,280
Där har man undrat hur appen 
använder ens kontakter.

107
00:07:58,440 --> 00:08:00,080
Appen är invite only.

108
00:08:00,240 --> 00:08:05,160
För att bjuda in nån måste du ge 
Clubhouse tillgång till telefonboken.

109
00:08:05,320 --> 00:08:11,000
Clubhouse gick ut i veckan och sa 
att man kan ta ut kontakterna nu.

110
00:08:11,160 --> 00:08:16,680
Det är en generationsfråga. Det beror 
på vilken plattform man är på.

111
00:08:16,840 --> 00:08:21,640
En undersökning om svenskars 
internetvanor gjordes förra året.

112
00:08:21,800 --> 00:08:26,680
40 % av de som svarade, 
som var studenter hade testat Tiktok.

113
00:08:26,840 --> 00:08:33,320
Jämför det med 12 % av de som jobbar 
och 3 % av pensionärerna.

114
00:08:33,480 --> 00:08:36,720
Stor skillnad! 
Instagram och Snapchat-

115
00:08:36,880 --> 00:08:43,440
-var betydligt vanligare än Facebook 
i gruppen 16- till 25-åringar.

116
00:08:43,600 --> 00:08:48,720
Sen kommer det nåt annat nytt. 
Vem är det då som är gammal?

117
00:08:48,880 --> 00:08:52,200
-Det är fortfarande vi. 
-Var inte oroliga.

118
00:08:52,360 --> 00:08:56,200
Det kommer nån social stegräknare 
ni kan underhålla er med.

119
00:08:56,360 --> 00:08:58,120
Jag kollade med folk.

120
00:08:58,280 --> 00:09:02,640
Instagram, Tiktok, 
Snapchat om det gills.

121
00:09:02,800 --> 00:09:07,240
Det är Instagram och Snapchat. 
Det är de jag använder.

122
00:09:07,400 --> 00:09:10,600
Det är inte mycket. 
Vi är åldringar.

123
00:09:10,760 --> 00:09:14,680
Instagram kör jag mycket, 
både för arbetet och privat.

124
00:09:14,840 --> 00:09:19,240
Även Tiktok har jag börjat med, 
arbetsrelaterat.

125
00:09:19,400 --> 00:09:23,400
-Vilka känner du till? 
-Facebook. I princip.

126
00:09:23,560 --> 00:09:28,400
Sociala medier är fantastiska, 
men det finns en del problem.

127
00:09:28,560 --> 00:09:33,560
Ja, den yngre generationen är trötta 
på att allt ska skrikas ut.

128
00:09:33,720 --> 00:09:37,720
Nu vill man vara i privata rum 
och dela saker med varandra.

129
00:09:37,880 --> 00:09:42,600
Man kan säga så här, sociala 
medier-företag har byggt system-

130
00:09:42,760 --> 00:09:48,480
-som är skapade för att rikta reklam 
så noggrant som möjligt.

131
00:09:48,640 --> 00:09:54,400
Ja, ja. Och vi användare, vi bjussar 
ganska mycket på våra grejer.

132
00:09:54,560 --> 00:09:57,920
Vi lägger upp bilder 
på vad vi håller på med.

133
00:09:58,080 --> 00:10:01,040
Det finns en risk att det utnyttjas.

134
00:10:04,160 --> 00:10:05,880
Vad är det som händer?

135
00:10:06,040 --> 00:10:10,760
Jag är ju stor på Nya Zeeland. 
Det tredje största kontot.

136
00:10:10,920 --> 00:10:14,120
Eller, 
jag var det tredje största kontot.

137
00:10:14,280 --> 00:10:18,120
Kontot för fågeln Hector 
har krävt en utrensning av bottar.

138
00:10:18,280 --> 00:10:20,800
Än sen? Vad då, då?

139
00:10:20,960 --> 00:10:25,680
Det betyder att tusentals 
av mina Safaris var bottar!

140
00:10:28,200 --> 00:10:31,680
Det är katastrof! 
Varför händer det här mig?

141
00:10:31,840 --> 00:10:35,000
Det kan ha att göra med 
det där företaget.

142
00:10:35,160 --> 00:10:39,720
Perfect Beautiful Amazing 
Digital Media AB?

143
00:10:39,880 --> 00:10:45,800
Har de boostat mina följare så att 
jag ska verka som en större stjärna?

144
00:10:45,960 --> 00:10:51,960
Så att de kan använda mig som reklam, 
som deras poster girl? Oh my god!

145
00:10:52,120 --> 00:10:59,000
Det har ju hänt förr 
att följare har avslöjats som fejk.

146
00:10:59,160 --> 00:11:03,240
Det går att göra rätt friskt, 
om man skulle vilja.

147
00:11:03,520 --> 00:11:08,840
Köpa Tiktok-likes.

148
00:11:09,000 --> 00:11:13,640
Men de kan användas 
till mer vardagliga saker.

149
00:11:13,800 --> 00:11:20,640
I Uppsala var det bokningsbottar som 
stal och sålde vidare träningstider.

150
00:11:20,800 --> 00:11:24,040
Det vi ser är privatpersoner-

151
00:11:24,200 --> 00:11:29,120
-som har byggt bottar, "script", 
som bevakar vår sida.

152
00:11:29,280 --> 00:11:34,160
När det släpps nya tider bokas de upp 
fortare än vad en människa hinner.

153
00:11:34,320 --> 00:11:36,320
Bottar är ett vapen med.

154
00:11:36,480 --> 00:11:42,000
Länder som påverkar varandra genom 
propaganda kan använda dem som vapen.

155
00:11:42,160 --> 00:11:46,600
Det som har hänt dig kan ha 
att göra med köpta fejkföljare.

156
00:11:46,760 --> 00:11:52,200
Köpta användare? 
Jag måste gå och krishantera!

157
00:11:53,240 --> 00:11:56,080
Det kan ju vara en bugg. Eller hur?

158
00:11:56,240 --> 00:12:01,640
Ja, som på Twitter när folk blockades 
för att de använde ordet "Memphis"?

159
00:12:01,800 --> 00:12:06,720
Konton som använde ordet "Memphis" 
har begränsats på grund av en bugg.

160
00:12:06,880 --> 00:12:10,160
Nåt tjall är det. 
Hoppas att det är det.

161
00:12:10,320 --> 00:12:17,480
-Kan du göra en sammanfattande bit? 
-Hur ska vi göra det? Vi löser det.

162
00:12:17,640 --> 00:12:20,360
Bot kommer från ordet robot.

163
00:12:20,520 --> 00:12:27,360
Det är ett datorprogram som ska 
göra automatiserade uppgifter-

164
00:12:27,520 --> 00:12:33,240
-allt från att chatta i en kundtjänst 
till att sprida propaganda.

165
00:12:33,400 --> 00:12:36,800
Det beror på vad 
den är programmerad till.

166
00:12:36,960 --> 00:12:41,080
När man försöker få det att se ut som 
att man har en massa följare-

167
00:12:41,240 --> 00:12:44,840
-med till exempel köpta likes 
eller bottar-

168
00:12:45,000 --> 00:12:50,040
-så vill man att det ska se ut som om 
man naturligt har de följarna.

169
00:12:50,200 --> 00:12:56,920
Då lurar man algoritmen att man 
är intressantare än vad man är.

170
00:12:57,080 --> 00:12:59,440
Vad är då en algoritm?

171
00:12:59,600 --> 00:13:03,560
En algoritm är som ett recept 
som har skapats-

172
00:13:03,720 --> 00:13:08,680
-för att säga till datorn hur 
den ska agera i olika situationer.

173
00:13:08,840 --> 00:13:13,120
Om det är en fråga om hur ditt 
sociala medie-flöde ser ut-

174
00:13:13,280 --> 00:13:16,640
-vad som kommer överst 
och prioriteras-

175
00:13:16,800 --> 00:13:22,000
-så bygger det på en algoritm 
som är ett recept för just dig.

176
00:13:22,160 --> 00:13:27,720
När det handlar om ditt flöde 
då är det ett recept som gäller dig.

177
00:13:27,880 --> 00:13:33,360
Det receptet har byggts upp av vad 
du tidigare har gjort på plattformen.

178
00:13:33,520 --> 00:13:37,320
Hur du har interagerat 
och saker du har gillat.

179
00:13:37,480 --> 00:13:40,320
Företagen vill ha dina uppgifter-

180
00:13:40,480 --> 00:13:44,000
-till att kunna rikta reklam 
men också annat.

181
00:13:44,160 --> 00:13:46,760
Vi bjuder på mycket information.

182
00:13:46,920 --> 00:13:51,320
Vi bjuder på det som vi lägger upp, 
bilder, personliga uppgifter...

183
00:13:51,480 --> 00:13:57,080
I grunden är algoritmer programmering 
och kan användas till en massa saker.

184
00:13:57,240 --> 00:14:01,880
-All right! Det gick väl bra. 
-Ja, han kanske har poäng ändå.

185
00:14:02,040 --> 00:14:08,280
Kanske. Hur som helst, vi får försöka 
hjälpa honom med hans följarbortfall.

186
00:14:08,440 --> 00:14:11,480
Du menar väl "bot-fall"?

187
00:14:21,320 --> 00:14:25,320
Svensktextning: 
Iyuno Media Group för UR

