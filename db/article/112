{"name":"Supervised Learning Algorithms","id":112,"content":"<p><strong>Regression</strong> =&gt; Predicting a continuous value, for example anything between<span class=\"math\">0</span>and<span class=\"math\">1</span>.<br />\n<strong>Classification</strong> =&gt; Predicting a discrete value e.g. Either<span class=\"math\">0</span>or<span class=\"math\">1</span>.</p>\n\n<p>&nbsp;</p>\n\n<div style=\"\">Visit this link for understanding Linear Regression in detail: <a href=\"https://www.oreilly.com/library/view/practical-statistics-for/9781491952955/ch04.html\">Oreilly Regression</a></div>\n\n<div style=\"\">&nbsp;</div>\n\n<div style=\"\"><strong>Prediction:</strong> If X=(X1, X2,..) changes, does the Y also change? If yes, can we predict the change? Correlation measures the strength of such relationship, Regression quantifies the nature of relationship.</div>\n\n<div style=\"\">Vocabulary of Linear Regression:</div>\n\n<div style=\"margin-left: 40px;\"><strong><em>Response</em></strong>&nbsp;/&nbsp;dependent variable /&nbsp;Y-variable /&nbsp;target /&nbsp;outcome</div>\n\n<div style=\"margin-left: 40px;\"><strong><em>Independent variable</em></strong>&nbsp;/&nbsp;X-variable /&nbsp;feature /&nbsp;attribute / factor</div>\n\n<div style=\"margin-left: 40px;\"><strong><em>Record</em></strong>&nbsp;/&nbsp;row /&nbsp;case /&nbsp;instance /&nbsp;example</div>\n\n<div style=\"margin-left: 40px;\"><strong><em>Intercept</em></strong>&nbsp;/ b0 / beta0</div>\n\n<div style=\"margin-left: 40px;\"><strong><em>Regression coefficient</em></strong>&nbsp;/&nbsp;slope /&nbsp;b1/&nbsp;&beta;1/&nbsp;parameter estimates/&nbsp;weights</div>\n\n<div style=\"margin-left: 40px;\"><strong><em>Fitted values</em></strong>&nbsp;/&nbsp;predicted values</div>\n\n<div style=\"margin-left: 40px;\"><strong><em>Residuals</em></strong>&nbsp;/&nbsp;errors</div>\n\n<div style=\"margin-left: 40px;\"><strong><em>Least squares</em></strong>&nbsp;/&nbsp;ordinary least squares</div>\n\n<div style=\"margin-left: 40px;\"><strong><em>Root mean squared error</em></strong>&nbsp;/&nbsp;RMSE:&nbsp;The square root of the average squared error of the regression</div>\n\n<div style=\"margin-left: 40px;\"><strong><em>Residual standard error</em></strong>&nbsp;/&nbsp;RSE:&nbsp;The same as the root mean squared error, but adjusted for degrees of freedom.</div>\n\n<div style=\"margin-left: 40px;\"><strong><em>R-squared</em></strong>&nbsp;/&nbsp;coefficient of determination,&nbsp;<span class=\"math\">R^2</span>:&nbsp;The same as the root mean squared error, but adjusted for degrees of freedom.</div>\n\n<div style=\"margin-left: 40px;\"><strong><em>t-statistic</em></strong>&nbsp;:&nbsp;The coefficient for a predictor, divided by the standard error of the coefficient&nbsp;</div>\n\n<div style=\"\">&nbsp;</div>\n\n<div style=\"\">Remember, in data science Regression means numerical prediction as opposed to classification. In statistics however, it means a linear or non-linear model to explain relationship b/w numerical output and feature&nbsp;variables.</div>\n\n<div style=\"\">&nbsp;</div>\n\n<div style=\"\">&nbsp;</div>\n\n<div style=\"\"><strong><span style=\"color:#8e44ad;\">We learn by examples (for which we know the input and corresponding output). After seeing a lot of examples we can guess the output using a function-of-features. Features are different traits/properties in the example input.&nbsp;</span></strong><span style=\"color:#2c3e50;\">See the function below</span></div>\n\n<div class=\"math\" style=\"\">\\mathbf{h_\\theta(x) = \\color{#228B22}{\\theta_0 + \\theta_1x_1 + \\theta_2x_2 \\implies \\sum_{i=0}^n\\theta_ix_i} \\color{black}{ \\implies \\large\\vec\\Theta^T\\vec{X}}} \\implies \\large\\vec\\Theta\\vec{X}^T</div>\n\n<div style=\"\">&nbsp;</div>\n\n<div style=\"\"><img alt=\"Linear Regression\" src=\"/images/linear_regression.jpg\" style=\"max-width: 100%\" /></div>\n\n<div style=\"\">To find the best values for unknown parameters, we will define a cost/error function, start with some random parameter values, and will try to minimize the value of this error function, by applying on all available training examples.</div>\n\n<div style=\"\">This cost function is called <strong>Squared Error Function</strong> based on <a href=\"https://en.wikipedia.org/wiki/Mean_squared_error\" target=\"_blank\">Mean Squared Error</a>. There are others like this. (<a href=\"https://online.stat.psu.edu/stat508/lesson/3/3.4\" target=\"_blank\">Why do we choose MSE?</a>)</div>\n\n<div style=\"\">&nbsp;</div>\n\n<div class=\"math\" style=\"border:1px solid #cccccc;padding:5px 10px;\">J(\\Theta) = \\frac{1}{2m}\\sum_{i=1}^m(h_\\theta(x^{(i)}) - y^{(i)})^2</div>\n\n<div style=\"\"><br />\nThe Goal is to minimize this cost function.</div>\n\n<div style=\"\">&nbsp;</div>\n\n<div style=\"\"><strong><span style=\"font-size:22px;\">How to minimize this cost function?</span></strong></div>\n\n<div style=\"\">&nbsp;</div>\n\n<div style=\"\">Start with some random values for all parameters i.e. <span class=\"math\">\\Theta</span></div>\n\n<div style=\"\">&nbsp;</div>\n\n<div style=\"\">Continously substract &nbsp;<span class=\"math\">\\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\Theta)</span> &nbsp;alpha is the <strong>learning rate</strong>.</div>\n\n<div style=\"\">&nbsp;</div>\n\n<div class=\"math\" style=\"border:1px solid #cccccc;padding:5px 10px;\">\\theta_j = \\theta_j - \\alpha\\frac{\\partial}{\\partial\\theta_j}J(\\theta) \\implies ... \\implies \\theta_j = \\theta_j + \\alpha(y^{(i)} - h_{\\theta}(x^{(i)}))x_j^{(i)}</div>\n\n<div style=\"\">&nbsp;</div>\n\n<div style=\"\">So for-each-feature go through all training examples and repeat until convergence ⟹ <strong><em>BATCH</em></strong> <a href=\"https://en.wikipedia.org/wiki/Gradient_descent\" target=\"_blank\">GRADIENT DESCENT</a></div>\n\n<div style=\"\">Another way is to go through all&nbsp;training examples and update each parameter Theta, so with more examples our parameters become more accurate ⟹&nbsp;<strong><em>STOCHASTIC</em></strong> GRADIENT DESCENT (also incremental gradient descent)</div>\n\n<p>&nbsp;</p>\n\n<p><em>Remember: The initial value of parameters affects the time taken to minimize the cost function and also the optimal value of cost function (in case there are multiple local minima for the function, one choice may lead to some local minima value different from the other). However, for the cost function above there will be only one local minimum (which is also the global minimum) as it is a <a href=\"https://en.wikipedia.org/wiki/Convex_function\" target=\"_blank\"><strong>Convex Function</strong></a>.</em></p>\n\n<p>Also, if learning rate is too small then Gradient Descent will take too long to <em>converge</em> to local minima. On the other hand, if it is too large, then it is possible that Gradient Descent will never converge. We need to find balance.</p>\n\n<p>Gradient Descent works best if the feature values are approximately on the same scale i.e. the difference between values is not much in any instance. E.g. if x1 values lie between { -3, 3 } and x2 values lie between {-200, 2000} then it&#39;s a problem. You can scale feature values by simple division by maximum value for feature, or by</p>\n\n<p><strong>Rescaling (Min-Max Normalization):-</strong></p>\n\n<div class=\"math\">x&#39;=a+\\frac{(x - min(x))(b-a)}{ max(x) - min(x)}</div>\n\n<p>This would scale the feature values into a range of [a,b]</p>\n\n<p><strong>Mean Normalization:-</strong></p>\n\n<div class=\"math\">x&#39;= \\frac{(x - avg(x))}{ max(x) - min(x)}</div>\n\n<p><strong>Z-score Normalization (a.k.a. Standardization):-</strong></p>\n\n<div class=\"math\">x&#39;= \\frac{(x - avg(x))}{ std.deviation}</div>\n\n<p><strong>Polynomial Regression</strong></p>\n\n<p>Our hypothesis function need not be linear (a straight line) if that does not fit the data well.</p>\n\n<p>We can <strong>change the behavior or curve</strong> of our hypothesis function by making it a quadratic, cubic or square root function (or any other form).</p>\n\n<p>&nbsp;</p>\n\n<div style=\"\">&nbsp;</div>\n\n<div style=\"\">If we write everything i.e. features, parameters and expected outputs in form of matrix.</div>\n\n<div style=\"\">&nbsp;</div>\n\n<div class=\"math\" style=\"border:1px solid #cccccc;padding:5px 10px;\">X =\\begin{bmatrix} --(x^{(1)})^T-- \\\\ --(x^{(2)})^T-- \\\\ forall-training-examples \\end{bmatrix}, \\vec{y} =\\begin{bmatrix} -- y^{(1)} -- \\\\ -- y^{(2)} -- \\\\ forall-training-examples \\end{bmatrix}</div>\n\n<div style=\"\">&nbsp;</div>\n\n<div style=\"\"><span class=\"math\">J(\\theta)</span> from above can be written as (using matrix proeprties of transpose)</div>\n\n<div style=\"\">&nbsp;</div>\n\n<div class=\"math\" style=\"border:1px solid #cccccc;padding:5px 10px;\">J(\\theta) = \\frac{1}{2m}(X\\theta - \\vec{y})^T(X\\theta - \\vec{y})</div>\n\n<div style=\"\"><br />\nFind the derivative of above now implies <span class=\"math\"> X^TX\\theta - X^T\\vec{y}</span> To find the value of theta when this difference is minimum set it equal to zero and we get <strong>Normal Equation</strong>\n\n<div class=\"math\">\\theta = (X^TX)^{-1}X^T\\vec{y}</div>\n</div>\n\n<div style=\"\">&nbsp;</div>\n\n<div style=\"\">So, instead of applying Gradient Descent, now we can simply use the above equation to find out the values of parameters that will minimize the cost function. However, remember that solving the above equation for very large number of parameters is costly and might be slower than running Gradient Descent instead. Also, notice that some matrices are <a href=\"https://en.wikipedia.org/wiki/Invertible_matrix\" target=\"_blank\"><strong>non-invertible</strong></a>, so the above equation will not work.</div>\n\n<div style=\"\">&nbsp;</div>\n\n<div style=\"\">When is the matrix non-invertible? - If one feature is linearly dependent on some other (<em>Redundant Features</em>). Or there are too many features (much more than we have examples). In that case you can use cut down on number of features or <a href=\"https://en.wikipedia.org/wiki/Regularization_(mathematics)\" target=\"_blank\"><strong>Regularization</strong></a> to make it work.</div>\n\n<div style=\"\">How would you cut down on number of features? <a href=\"https://towardsdatascience.com/the-5-feature-selection-algorithms-every-data-scientist-need-to-know-3a6b566efd2\" target=\"_blank\">Variable selection</a>, Feature Engineering.</div>\n\n<div style=\"\">&nbsp;</div>\n\n<div style=\"\">How to&nbsp;regularize Linear Regression? <a href=\"http://online.stat.psu.edu/stat508/lesson/5/5.1\">Ridge Regression</a>, <a href=\"https://online.stat.psu.edu/stat508/lesson/5/5.4\">Lasso Regression</a>.</div>\n\n<div style=\"\">&nbsp;</div>\n\n<div style=\"\">We have another way of minimizing the cost/error function where not every training example have equal importance while calculating the error/cost, instead the training examples having closer-feature-values&nbsp;(more similar examples) will have more importance.</div>\n\n<div style=\"\">&nbsp;</div>\n\n<div style=\"\">&nbsp; <span class=\"math\"> J(\\theta) = \\frac{1}{2}\\sum_{i=1}^mw^{(i)}(h_\\theta(x^{(i)}) - y^{(i)})^2</span>.</div>\n\n<div style=\"\">&nbsp;</div>\n\n<div style=\"\">A fair enough weight function <span class=\"math\"> w^{(i)} = exp(-\\frac{(x^{(i)}-x)^2}{2\\tau^2})</span></div>\n\n<div style=\"\">&nbsp;</div>\n\n<div style=\"\">This is called <strong>Locally-Weighted-Linear-Regression</strong> model and it is an example of <a href=\"https://en.wikipedia.org/wiki/Nonparametric_statistics\" target=\"_blank\"><strong>Non-Parametric-Algorithms</strong></a>.<br />\nHere everytime you want to predict, you have to fit theta on the whole training set again and then output guess.</div>\n\n<div style=\"\">&nbsp;</div>\n\n<div style=\"\">\n<hr /><br />\n<span style=\"color:#2980b9;\"><strong>But <span title=\"the above one\">Linear-Regression model </span>is not suitable for Classification problems, where there are fixed number of possible outputs. In a special case, where output can be either zero or one. </strong>We would have to modify our guess function</span></div>\n\n<div class=\"math\" style=\"border:1px solid #cccccc;padding:5px 10px;\">h(\\theta) = g(\\theta^Tx) = \\frac{1}{1+e^{-\\theta^Tx} }</div>\n\n<div style=\"\">&nbsp;</div>\n\n<div style=\"\">This is a sigmoid function which will output values between zero and one only. Using the probabilistic analysis, we can conclude that the updation rule of this function to find accurate values of parameters is similar to Least-Mean-Square updation.</div>\n\n<div style=\"\">&nbsp;</div>\n\n<div style=\"\">The cost function which we want to minimize in this case is the following:</div>\n\n<div style=\"\">\n<div class=\"math\">\\displaystyle\\frac{1}{m}\\sum_{i=1}^n y^{(i)}(-\\text{log }h_\\theta(x^{(i)})) + (1-y^{(i)})(-\\text{log }(1-h_\\theta(x^{(i)}))) + \\frac{\\lambda}{2m}\\sum_{j=1}^{n}\\theta_j^2</div>\n\n<p>&nbsp;</p>\n</div>\n\n<div style=\"\">The above model is called <strong>Logistic-Regression model</strong>. The rightmost term&nbsp;of the equation is for <a href=\"https://en.wikipedia.org/wiki/Regularization_(mathematics)\" target=\"_blank\">Regularization</a>.</div>\n\n<div style=\"\">In Logistic Regression we map the probability that output belongs to class 1 is mappeds&nbsp;to a more expansive scale suitable for linear modeling. E.g.</div>\n\n<div style=\"\">\n<div class=\"math\">p = \\frac{1}{ 1 + e^{-(\\theta_0 + \\theta_1 x_1 + ... + \\theta_q x_q)} }</div>\n\n<p>Now to get exponential term out of denominator (because that would be difficult to deal with), we use Odds instead&nbsp; of probability.</p>\n\n<div class=\"math\">\\text{Odds}(Y=1) = \\frac{1}{1-p}</div>\n\n<p>Apply this to the above function and taake log on both sides. And we get log-odd&nbsp; function for Logistic Regression.</p>\n\n<p>The coefficients of Logistic Regression model tell us the Log of Odd ratios for the&nbsp;feature&nbsp;variables.<br />\n<br />\nIn case of Logistic-Regression-model-using-sigmoid-function there is a faster algorithm to update the parameters if the number of training exmaples is not very large . This algorithm is called <a href=\"https://en.wikipedia.org/wiki/Scoring_algorithm\" target=\"_blank\">Fischer Scoring</a> which uses Newtons method to maximize the likelihood of parameters while doing probabilistic analysis.</p>\n</div>\n\n<div style=\"\"><br />\n<br />\n<span style=\"color:#8e44ad;\"><strong>There exists a <a href=\"https://en.wikipedia.org/wiki/Generalized_linear_model\" target=\"_blank\">Generalized Linear Model</a> (GLM) which covers both Logistic-Regression and Linear-Regression models.</strong></span><br />\nWe define a general function for distributions <span class=\"math\"> p(y;\\eta) = b(y).\\text{exp}(\\eta^TT(y) - a(\\eta))</span><br />\nwhere <span class=\"math\"> a(\\eta)= log(1+e^{\\eta})</span><br />\nKeep <span class=\"math\">T(y) = y, </span>&nbsp; <span class=\"math\"> a(\\eta)= -log(1-\\phi)</span> and <span class=\"math\">b(y) = 1 </span><span class=\"math\"> \\implies</span> We can map <strong>Bernoulli-Distribution</strong> <span class=\"math\">p(y;\\phi) = \\phi^y(1-\\phi)^{1-y}</span> to this general function<br />\n<br />\nSimilarly <strong>Gaussian</strong>, <strong>Multinomial</strong>, <strong>Poisson</strong>, <strong>Gamma</strong>, <strong>Beta</strong> and <strong>Dirichlet</strong> distributions can be mapped to this general function.<br />\n<br />\nWe can use&nbsp;a General Linear Model if the problem statement satisfies these conditions:<br />\n(1) Given inputs x and parameters theta, the output y is distributed according to above mentioned exponential distribution for some natural parameter&nbsp;eta.<br />\n(2) The goal is to guess Expected value of T(y) given x i.e. <span class=\"math\"> h(x) = E[T(y)|x]</span> &nbsp;<br />\n(3) The natural parameter&nbsp; <span class=\"math\"> \\eta = \\Theta^TX</span><br />\n&nbsp;</div>\n\n<div style=\"\">\n<p><strong>Example of classifying among k possible classes</strong><br />\n<br />\nWe will use Multinomial Distribution, map it to our General Exponential Function, Find Likelihood of classes and maximize them using gradient descent.<br />\n&nbsp; <span class=\"math\"> \\phi_i=</span> probability that output is equal to class number i, given other phi parameters i.e <span class=\"math\"> \\phi_i= p[y=i;\\phi]</span></p>\n\n<p>Then probability of class k, <span class=\"math\"> p(y=k; \\phi)= 1 - \\sum_{i=1}^{k-1}\\phi_i </span></p>\n\n<div class=\"math\">p(y;\\phi) = \\phi_1^{{y==1}}.\\phi_2^{{y==2}}..\\space \\text{and so onto k}</div>\n\n<p>&nbsp;</p>\n\n<p>Represent T(y) as <span> one dimensional column vector of zeroes and ones where only row with value one will be if y==row</span><br />\n<br />\nWe can map this multinomial distribution to our General Exponential function, and it comes out that<br />\n&nbsp; <span class=\"math\"> \\eta = \\begin{bmatrix} log(\\frac{\\phi_1}{\\phi_k}) \\\\ log(\\frac{\\phi_2}{\\phi_k}) \\\\ \\text{upto} \\\\ log(\\frac{\\phi_{k-1}}{\\phi_k}) \\end{bmatrix}, a(\\eta) = -log(\\phi_k), b(y)=1</span><br />\n<br />\n&nbsp;<span class=\"math\"> \\phi_i</span> comes out to be <span class=\"math\" style=\"font-size: 25px\"> \\phi_i = \\frac{e^{\\eta_i}}{ \\sum_{j=1}^ke^{\\eta_j}}</span><br />\nSo the log likelihood for parameters over all training examples&nbsp;</p>\n\n<div class=\"math\" style=\"font-size: 23px\">l(\\theta) = \\sum_{i=1}^mlog\\space\\prod_{l=1}^k \\begin{pmatrix} \\frac{e^{\\theta_j^Tx^{(i)}} }{ \\sum_{j=1}^k e^{\\theta_j^Tx^{(i)} } } \\end{pmatrix}^{y^i == l}</div>\n</div>\n\n<p>&nbsp;</p>\n\n<p>There are other classifiers e.g. Naive<strong> Bayes Classifier,</strong> Gaussian Naive Bayes Classifier</p>\n\n<p>Multinomial Naive Bayes:</p>\n\n<p>From the data you have, find the probability of each class (called Prior Probabilities). Find all probabilities of each feature/factor variable given that the record belongs to class k. Now the probability that a&nbsp;record (with given feature values) belongs to particular class is product of probabilities of that class and conditional probabilities of features conditioned on that class.</p>\n\n<p>Gaussian Naive Bayes:</p>\n\n<p>Same as above, just multiply prior probability with likelihoods of the feature&nbsp;variables. Use log function to compare the results, otherwise in case of Gaussian distribution some likelihoods are very close to zero,&nbsp; so close that computers are not able to handle efficiently.</p>\n\n<p>In&nbsp;fact you could use other probability models in place of Gaussian.</p>\n\n<p>This analysis can also give you idea about which feature&nbsp;variables are more important for prediction. However, do verify by cross-validation.</p>\n\n<p>&nbsp;</p>\n\n<div style=\"font-size: larger;\">\n<p><strong>Discriminant Anslysis</strong></p>\n</div>\n\n<p><strong>Covariance:</strong>&nbsp;A measure of the extent to which one variable varies in concert with another (i.e., similar magnitude and direction).</p>\n\n<p><strong>Discriminant function:</strong>&nbsp;The function that, when applied to the predictor variables, maximizes the separation of the classes.</p>\n\n<p><strong>Discriminant weights:</strong>&nbsp;The scores that result from the application of the discriminant function, and are used to estimate probabilities of belonging to one class or another.</p>\n\n<p>Linear Discriminant Analysis, are now less used in favour of Tree models and Logistic Regression. However, it still has its usage in PCA for example. It can help in feature selection.</p>\n\n<p>LDA requires Covariance b/w variables.&nbsp;Recall that the standard deviation is used to normalize a variable to a&nbsp;<em>z</em>-score; the covariance matrix is used in a multivariate extension of this standardization process.</p>\n\n<p>The method finds the linear combination&nbsp;<span class=\"math\">w_x x+w_z z</span>&nbsp;that maximizes that sum of squares ratio <span class=\"math\">\\frac{\\text{SS}_\\text{between}}{\\text{SS}_\\text{within} }</span>.</p>\n\n<p>The between sum of squares is the squared distance between the two group means, and the within sum of squares is the spread around the means within each group, weighted by the covariance matrix. Intuitively, by maximizing the between sum of squares and minimizing the within sum of squares, this method yields the greatest separation between the two groups.</p>\n\n<p>Quadratic Discriminant Analysis: There are other variants of discriminant analysis.<a data-primary=\"quadratic discriminant analysis\" data-type=\"indexterm\" id=\"idm45909258641560\"></a>&nbsp;The best known is quadratic discriminant analysis (QDA). Despite its name, QDA is still a linear discriminant function. The main difference is that in LDA, the covariance matrix is assumed to be the same for the two groups corresponding to&nbsp;<em>Y</em>&nbsp;= 0 and&nbsp;<em>Y</em>&nbsp;= 1. In QDA, the covariance matrix is allowed to be different for the two groups. In practice, the difference in most applications is not critical.</p>\n\n<p>&nbsp;</p>\n\n<p>Discriminant analysis works with continuous or categorical predictors, as well as categorical outcomes.</p>\n\n<p>&nbsp;</p>\n\n<p><strong>Assessing the Model</strong></p>\n\n<p>The most important performance metric from a data science perspective is&nbsp;<em>root mean squared error</em>, or&nbsp;<em>RMSE</em>.&nbsp;RMSE is the square root of the average squared error in the predicted&nbsp;values.</p>\n\n<p>This measures the overall accuracy of the model, and is a basis for comparing it to other models (including models fit using machine learning techniques). Similar to RMSE is the&nbsp;<em>residual standard error</em>, or&nbsp;<em>RSE</em>.<a data-primary=\"residual standard error\" data-type=\"indexterm\" id=\"idm45909263854408\"></a><a data-primary=\"RSE\" data-see=\"residual standard error\" data-type=\"indexterm\" id=\"idm45909263853672\"></a>&nbsp;In this case we have&nbsp;<em>p</em>&nbsp;predictors, and the RSE is given by (The only difference is that the denominator is the degrees of freedom, as opposed to number of records):</p>\n\n<div class=\"math\">\\text{RSE} = \\sqrt{ \\frac{ \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 }{(n-p-1)} }</div>\n\n<p>Another measure is R-squared. R-squared ranges from 0 to 1 and measures the proportion of variation in the data that is accounted for in the model.<a data-primary=\"R-squared\" data-type=\"indexterm\" id=\"idm45909262358040\"></a><a data-primary=\"coefficient of determination\" data-type=\"indexterm\" id=\"idm45909262357336\"></a>&nbsp;It is useful mainly in explanatory uses of regression where you want to assess how well the model fits the data. A<em>djusted R-squared</em>, adjusts for the degrees of freedom; seldom is this significantly different in multiple regression.</p>\n\n<p>Standard Errors (SE) for coefficients.</p>\n\n<p>T-statistics:&nbsp;<span class=\"math\">t_b = \\frac{\\hat{b}}{ \\text{SE} \\hat{b} }</span></p>\n\n<p>The t-statistic&mdash;and its mirror image, the p-value&mdash;measures the extent to which a coefficient is &ldquo;statistically significant&rdquo;&mdash;that is, outside the range of what a random chance arrangement of predictor and target variable might produce.<a data-primary=\"p-values\" data-secondary=\"t-statistic and\" data-type=\"indexterm\" id=\"idm45909262323528\"></a>&nbsp;The higher the t-statistic (and the lower the p-value), the more significant the predictor.&nbsp;</p>\n\n<p>&nbsp;</p>\n\n<p>Interpretation of the p-value comes with the same caveat as in regression, and should be viewed more as a relative indicator of variable importance than as a formal measure of statistical significance. A logistic regression model, which has a binary response, does not have an associated RMSE or R-squared. Instead, a logistic regression model is typically evaluated using more general metrics for classification</p>\n\n<p>&nbsp;</p>\n\n<p><strong>Does Degrees of Freedom matter?</strong></p>\n\n<p>Is it important for data science? Not really, at least in the context of significance testing. For one thing, formal statistical tests are used only sparingly in data science. For another, the data size is usually large enough that it rarely makes a real difference for a data scientist whether, for example, the denominator has&nbsp;<em>n</em>&nbsp;or&nbsp;<em>n</em>&nbsp;&ndash; 1.</p>\n\n<p>There is one context, though, in which it is relevant: the use of factored variables in regression (including logistic regression). Regression algorithms choke if exactly redundant predictor variables are present. This most commonly occurs when factoring categorical variables into binary indicators (dummies). Including the n-th variable results in multicollinearity.</p>\n\n<p>&nbsp;</p>\n\n<p>&nbsp;</p>\n\n<hr />\n<h2>From Logistic Regression to Support Vector Machines</h2>\n\n<p>If we consider cost function to be:</p>\n\n<div class=\"math\">\\displaystyle C\\sum_{i=1}^n y^{(i)}\\text{cost}_1(\\theta^T x^{(i)})) + (1-y^{(i)})\\text{cost}_0(\\theta^T x^{(i)})) + \\frac{1}{2}\\sum_{j=1}^{n}\\theta_j^2</div>\n\n<p>Here&nbsp;<span class=\"math\">C</span> controls the behavior of SVM classifier. Large C <span class=\"math\">\\implies</span> Lower <strong>Bias</strong>, High <strong>Variance</strong>. Small C <span class=\"math\">\\implies</span> Higher Bias, Low Variance.</p>\n\n<p>SVMs are considered Large Margin Classifiers.</p>\n\n<p>In short, SVM, unlike Logistic Regression, not just cares about getting a boundary between positive and negative examples, it also tries to get a boundary which has larger minimum distance to an example on the both sides of the boundary i.e. it gets a safer boundary.</p>\n\n<p><strong>Kernels:</strong></p>\n\n<p>To have a good non-linear function, choose some arbitrary landmarks among examples/data-points. And use some function to create features as function of x&#39;s, and landmarks. One such function is Gaussian Kernel.</p>\n\n<div class=\"math\">\\displaystyle \\text{exp}\\big( -\\frac{||x-l||^2}{2\\sigma^2}\\big)</div>\n\n<p>Intead of using x&#39;s in SVM cost function, use this function. Large&nbsp;<span class=\"math\">\\sigma^2</span> <span class=\"math\">\\implies</span> Features vary more smoothly. Higher <strong>Bias</strong>, Low <strong>Variance</strong>.</p>\n\n<p>You can apply the Kernel idea to other regression models, but the computational optimization techniques which work on SVM do not generalize to other models, and it becomes costly then.</p>\n\n<p>You can&#39;t just have any function as Kernel. They need to satisfy Mercer&#39;s Theorem.</p>\n\n<p>Other off-the-shelf kernels available:</p>\n\n<ul>\n\t<li>Polynomial Kernel</li>\n\t<li>String Kernel, Chi Squared Kernel, Histogram Intersection Kernel etc</li>\n</ul>\n\n<p><strong>Which one to use Logistic Regression or SVM?</strong></p>\n\n<p>When&nbsp;<span class=\"math\">n \\gt \\gt m</span> : Use LR, or SVM without Kernel.</p>\n\n<p>When n is small, m is intermediate: Use SVM with Kernel.</p>\n\n<p>When&nbsp;<span class=\"math\">n \\lt \\lt m</span> : Create/add more features, use LR or SVM without Kernel.</p>\n\n<p>&nbsp;</p>\n\n<p>&nbsp;</p>\n\n<div style=\"\">Regression models are called <span style=\"color:#8e44ad;\"><strong>Discriminative Learning Algorithms</strong></span>, they start modelling <span class=\"math\">p(y|x) </span> right away,&nbsp;<br />\n<span style=\"color:#8e44ad;\"><strong>Generative Learning Algorithms</strong></span> instead tend to find <span class=\"math\"> p(x|y) </span> and then find <span class=\"math\"> p(y|x) </span> using Bayes rule.</div>\n\n<div style=\"\"><br />\nIn simple words, suppose we have many examples of SPAM mails, and many examples of non-SPAM mails, we can create two models using those examples. When a new new mail comes we will find the similarity with both, and output one with the maximum similarity.<br />\n<br />\nThese are Generative Algorithms:</div>\n\n<ul>\n\t<li style=\"\">GDA (Gaussian Discriminant Analysis)</li>\n\t<li style=\"\">NBC (Naive Bayes Classification)</li>\n</ul>\n\n<p>&nbsp;</p>\n\n<p style=\"padding: 5px 10px;\"><strong>Gaussian Discriminant Analysis:</strong></p>\n\n<div style=\"padding:5px 10px;\">Assumes that p(x|y)&nbsp;is distributed according to Multivariate Normal(Gaussian) distribution<br />\n&nbsp;&nbsp; GDA has similarity to Logistic Regression and will perform better when the assumptions about distribution are more accurate.<br />\nPractically in general cases, Logistic Regression does just fine or better when you the assumptions about data are not very accurate.<br />\n<br />\nLet&#39;s take the problem of identifying one of two classes something belongs to:<br />\n<br />\nOur Model (Assumptions+):<br />\n&nbsp;&nbsp; <span class=\"math\">y</span> &nbsp; &nbsp; is distributed as Bernoulli(p)<br />\n<span class=\"math\">x | y=0 </span> is distributed as multivariate Gaussian <span class=\"math\">(\\mu_0, \\Sigma)</span><br />\n<span class=\"math\">x | y=1 </span> is distributed as multivariate Gaussian <span class=\"math\">(\\mu_1, \\Sigma)</span><br />\n<br />\n<br />\nlog-likelihood of data, given all these parameters <span class=\"math\"> \\displaystyle = \\text{log} \\prod_i^{\\text{all training sets}}p(x^{(i)} | y^{(i)};\\mu_0,\\mu_1,\\Sigma)p(y^{(i)};\\phi)</span><br />\n&nbsp; &nbsp;&nbsp;<br />\nBy maximizing this log-likelihood, we establish these params to be:\n<div class=\"math\">\\phi = \\frac{1}{m}\\displaystyle\\prod_i^{all-training-sets}(y == 1)</div>\nIts just average number of times when examples belonged to class 1\n\n<div class=\"math\">\\mu_0 = avg(x_i)\\text{ when y=0}</div>\n\n<div class=\"math\">\\mu_1 = avg(x_i)\\text{ when y=1}</div>\n\n<div class=\"math\">\\Sigma = \\frac{1}{m}\\sum_{i=1}^m(x_i - \\mu_{y_i})(x_i - \\mu_{y_i})^T</div>\n</div>\n\n<div style=\"padding:5px 10px;\"><strong>Naive Bayes Learning Algorithm</strong></div>\n\n<div style=\"padding:5px 10px;\">\n<p>GDA was for continuous values.<br />\nLets build a generative model for problem where feature vector is made of discrete values. Taking example of classifying emails.<br />\n<br />\nfeature-vector = X = column-matix of {0 or 1}&nbsp; where column = 1 if the word is in email, zero otherwise.<br />\nTo develop a generative model we have to find p(x|y)<br />\n<span class=\"math\">p(x_1, x_2,....|y) = p(x_1|y) p(x_2|y,x_1)p(x_3|y,x1,x2)....</span><br />\n<br />\nNow if we consider all events to be independent of each other <span class=\"math\"> \\implies \\prod_{i=1}^np(x_i|y)</span><br />\n<br />\n&nbsp;</p>\n\n<div class=\"math\">\\displaystyle \\text{Joint-Likelihood of data }= \\prod_{m}^{all-training-examples}p(x^{(m)},y^{(m)})</div>\nparameterized by\n\n<div class=\"math\">\\displaystyle p(x_i = 1|y = 1) \\space i.e.\\space \\phi_{i|y=1},\\space p(x_i = 1|y = 0)\\space i.e \\space \\phi_{i|y=0},\\space \\space p(y = 1) \\space i.e. \\space \\phi_y</div>\n<br />\nMaximizing this with respect to parameters,\n<p>&nbsp;</p>\n\n<p>&nbsp;</p>\n\n<div class=\"math\">\\displaystyle \\phi_{i|y=1} = \\frac{\\text{#times when }x_i=1 \\text{ and } y=1}{\\text{#times when } y=1}</div>\n;\n\n<div class=\"math\">\\displaystyle \\phi_{i|y=0} = \\frac{\\text{#times when }x_i=1 \\text{ and } y=0}{\\text{#times when } y=0}</div>\n\n<p>&nbsp;</p>\n\n<p><br />\n<span class=\"math\">\\phi_y = \\text{ avg. num of times }y=1</span></p>\n\n<p>&nbsp;</p>\n<br />\nNow to make a prediction on new example simply calculate:\n<div class=\"math\">p(y = 1|x) = \\frac{p(x|y = 1)p(y = 1)}{p(x)} = \\frac{\\displaystyle\\prod_{i=1}^np(x_i|y = 1)p(y=1)}{\\displaystyle\\prod_{i=1}^np(x_i|y = 1)p(y=1)+\\displaystyle\\prod_{i=1}^np(x_i|y = 0)p(y=0)}</div>\n\n<p><br />\nBut if there comes a new word in email, which was not in feature-vector say at i-th position, <span class=\"math\"> \\phi_{i|y=1} = \\phi_{i|y=0} = 0 \\implies p(y=1|x) = \\frac{0}{0}</span> So, we can&#39;t make a prediction because a new word came in. To avoid this: add 1 to numerator and 2(=number-of-classes) to denominator in both of <span class=\"math\"> \\phi_{i|y=1} \\text{ and } \\phi_{i|y=0} </span><br />\n<br />\nThe algo described above uses a Multi-variate Bernoulli event model. In place of that we can use Multinomial Event model, which gives better results.</p>\n\n<p>&nbsp;</p>\n</div>\n\n<h2>K-Nearest Neighbors</h2>\n\n<p>For each record to be classified<a data-primary=\"classification\" data-secondary=\"K-Nearest Neighbors\" data-type=\"indexterm\" id=\"idm45909256440200\"></a>&nbsp;or<a data-primary=\"prediction\" data-secondary=\"K-Nearest Neighbors\" data-type=\"indexterm\" id=\"idm45909256439128\"></a>&nbsp;predicted:</p>\n\n<ol>\n\t<li>\n\t<p>Find&nbsp;<em>K</em>&nbsp;records that have similar features (i.e., similar predictor values).</p>\n\t</li>\n\t<li>\n\t<p>For classification: Find out what the majority class is among those similar records, and assign that class to the new record.</p>\n\t</li>\n\t<li>\n\t<p>For prediction (also called&nbsp;<em>KNN regression</em>): Find the average among those similar records, and predict that average for the new record.</p>\n\t</li>\n</ol>\n\n<p><strong><em>Standardization / </em></strong>Normalization<strong><em>:</em></strong>&nbsp;Subtract the mean and divide by the standard deviation.</p>\n\n<p><strong><em>Z-score:</em></strong>&nbsp;The value that results after standardization.</p>\n\n<p><strong><em>Distance metrics:</em></strong>&nbsp;Measures that sum up in a single number how far one record is from another.</p>\n\n<p>The prediction results depend on how the features are scaled, how similarity is measured, and how big&nbsp;<em>K</em>&nbsp;is set. Also, all predictors must be in numeric form.</p>\n\n<p>Similarity (nearness) is determined using a&nbsp;<em>distance metric</em>, which is a function that measures how far two records (<em>x<sub>1</sub></em>,&nbsp;<em>x<sub>2</sub></em>, &hellip;&nbsp;<em>x<sub>p</sub></em>) and (<em>u<sub>1</sub></em>,&nbsp;<em>u<sub>2</sub></em>, &hellip;&nbsp;<em>u<sub>p</sub></em>) are from one another.</p>\n\n<p>Euclidean distance,&nbsp;<em>Manhattan distance,&nbsp;Mahalanobis distance (which also accounts for correlation b/w features)</em></p>\n\n<p>Euclidean distance corresponds to the straight-line distance between two points (e.g., as the crow flies). Manhattan distance is the distance between two points traversed in a single direction at a time (e.g., traveling along rectangular city blocks). For this reason, Manhattan distance is a useful approximation if similarity is defined as point-to-point travel time.</p>\n\n<p>In linear and logistic regression, one hot encoding causes problems with multicollinearity; &nbsp;In such cases, one dummy is omitted (its value can be inferred from the other values). This is not an issue with KNN and other methods.</p>\n\n<p>Standardization, also called&nbsp;<em>normalization</em>, puts all variables on similar scales by subtracting the mean and dividing by the standard deviation.<a data-primary=\"standardization\" data-secondary=\"in K-Nearest Neighbors\" data-type=\"indexterm\" id=\"idm45909256183016\"></a><a data-primary=\"normalization\" data-type=\"indexterm\" id=\"idm45909256182040\"></a>&nbsp;In this way, we ensure that a variable does not overly influence a model simply due to the scale of its original measurement.</p>\n\n<p>Using the&nbsp;<em>z</em>-score is just one way to rescale variables.<a data-primary=\"z-score\" data-secondary=\"rescaling variables\" data-type=\"indexterm\" id=\"idm45909256021128\"></a><a data-primary=\"variables\" data-secondary=\"rescaling with z-scores\" data-type=\"indexterm\" id=\"idm45909255866040\"></a>&nbsp;Instead of the mean, a more robust estimate of location could be used, such as the median. Likewise, a different estimate of scale such as the interquartile range could be used instead of the standard deviation. Sometimes, variables are &ldquo;squashed&rdquo; into the 0&ndash;1 range. It&rsquo;s also important to realize that scaling each variable to have unit variance is somewhat arbitrary. This implies that each variable is thought to have the same importance in predictive power. If you have subjective knowledge that some variables are more important than others, then these could be scaled up.&nbsp;</p>\n\n<p>Normalization (standardization) does not change the distributional shape of the data; it does not make it normally shaped if it was not already normally shaped.</p>\n\n<p>Generally speaking, if&nbsp;<em>K</em>&nbsp;is too low, we may be overfitting: including the noise in the data. Higher values of&nbsp;<em>K</em>&nbsp;provide smoothing that reduces the risk of overfitting in the training data. On the other hand, if&nbsp;<em>K</em>&nbsp;is too high, we may oversmooth the data and miss out on KNN&rsquo;s ability to capture the local structure in the data, one of its main advantages.</p>\n\n<p>The&nbsp;<em>K</em>&nbsp;that best balances between overfitting and oversmoothing is typically determined by accuracy metrics and, in particular, accuracy with holdout or validation data. There is no general rule about the best&nbsp;<em>K</em>&mdash;it depends greatly on the nature of the data. For highly structured data with little noise, smaller values of&nbsp;<em>K</em>&nbsp;work best.&nbsp;</p>\n\n<p>KNN is more useful for feature enhancement instead of working as an actual predictor. In practical model fitting, KNN can be used to add &ldquo;local knowledge&rdquo; in a staged process with other classification techniques.</p>\n\n<ol>\n\t<li>\n\t<p>KNN is run on the data, and for each record, a classification (or quasi-probability of a class) is derived.</p>\n\t</li>\n\t<li>\n\t<p>That result is added as a new feature to the record, and another classification method is then run on the data. The original predictor variables are thus used twice.</p>\n\t</li>\n</ol>\n\n<p>This process, if you are thinking that would cause multicollinearity, would not cause multicollinearity because the&nbsp;the information being incorporated into the second-stage model is highly local, derived only from a few nearby records, and is therefore additional information, and not redundant.</p>\n\n<p>&nbsp;</p>\n\n<h2>Tree Models</h2>\n\n<p><em>Classification and Regression Trees</em>&nbsp;(<em>CART</em>),&nbsp;<em>decision trees</em>, or just&nbsp;<em>trees:</em></p>\n\n<p>Its descendants are Random Forests and Boosting algos.</p>\n\n<p><strong><em>Recursive partitioning:</em></strong>&nbsp;Repeatedly dividing and subdividing the data with the goal of making the outcomes in each final subdivision as homogeneous as possible.</p>\n\n<p><strong><em>Split value:</em></strong>&nbsp;A predictor value that divides the records into those where that predictor is less than the split value, and those where it is more.</p>\n\n<p><strong><em>Loss:</em></strong>&nbsp;The number of misclassifications at a stage in the splitting process; the more losses, the more impurity.</p>\n\n<p><strong><em>Impurity /&nbsp;</em></strong>Heterogeneity:&nbsp;The extent to which a mix of classes is found in a subpartition of the data (the more mixed, the more impure).</p>\n\n<p><strong><em>Pruning:</em></strong>&nbsp;The process of taking a fully grown tree and progressively cutting its branches back, to reduce overfitting.</p>\n\n<p>&nbsp;</p>\n\n<p><strong>How is Homogeneity measured?</strong></p>\n\n<p>two common measures for impurity are the&nbsp;<em>Gini impurity</em>&nbsp;and&nbsp;<em>entropy</em>&nbsp;of&nbsp;<em>information</em>.<a data-primary=\"entropy\" data-type=\"indexterm\" id=\"idm45909255223192\"></a><a data-primary=\"information\" data-type=\"indexterm\" id=\"idm45909255222456\"></a><a data-primary=\"Gini impurity\" data-type=\"indexterm\" id=\"idm45909255221784\"></a>&nbsp;While these (and other) impurity measures apply to classification problems with more than two classes, we focus on the binary case. The Gini impurity for a set of records&nbsp;<em>A</em>&nbsp;is:</p>\n\n<p><span class=\"math\">I(A)=p(1&minus;p)</span></p>\n\n<p>The entropy measure is given by:</p>\n\n<p><span class=\"math\">I(A)=&minus;p \\text{log}_2(p)&minus;(1&minus;p) \\text{log}_2(1&minus;p)</span></p>\n\n<p>Gini impurity is not to be confused with the&nbsp;<em>Gini coefficient</em>. They represent similar concepts,<a data-primary=\"Gini coefficient\" data-type=\"indexterm\" id=\"idm45909255191720\"></a>&nbsp;but the Gini coefficient is limited to the binary classification problem and is related to the AUC metric</p>\n\n<p>&nbsp;</p>\n\n<p><strong>But tree can grow big, and include noise and overfit.</strong></p>\n\n<p>A simple and intuitive method of reducing tree size is to&nbsp;<em>prune</em>&nbsp;back the terminal and smaller branches of the tree, leaving a smaller tree.<a data-primary=\"pruning\" data-type=\"indexterm\" id=\"idm45909255181960\"></a>&nbsp;How far should the pruning proceed? A common technique is to prune the tree back to the point where the error on holdout data is minimized.</p>\n\n<ol>\n\t<li>Avoid splitting a partition if a resulting subpartition is too small, or if a terminal leaf is too small.</li>\n\t<li>Don&rsquo;t split a partition if the new partition does not &ldquo;significantly&rdquo; reduce the impurity.</li>\n</ol>\n\n<p>The first method involves arbitrary rules, and can be usful for exploratory work, but we can&rsquo;t easily determine optimum values (i.e., values that maximize predictive accuracy with new data).&nbsp;</p>\n\n<p>For&nbsp; second libraries provide some option to&nbsp; control&nbsp; tree&nbsp; complexity.&nbsp;</p>\n\n<p>Trees are not&nbsp; as Black Box&nbsp; as other&nbsp; data science methods.</p>\n\n<p>&nbsp;</p>\n\n<h2>Bagging and Random Forest:</h2>\n\n<p>Applies the principle of &quot;Wisdom of&nbsp; the Crowd&quot; to predictive models. That many weak learning models can be combined to come up with a better&nbsp; model.</p>\n\n<p><strong><em>Ensemble/&nbsp;</em></strong>Model averaging:&nbsp;Forming a prediction by using a collection of models.</p>\n\n<p><strong><em>Bagging</em></strong>&nbsp;/&nbsp;Bootstrap aggregation:&nbsp;A general technique to form a collection of models by bootstrapping the data.</p>\n\n<p><strong><em>Random forest</em></strong>&nbsp;/&nbsp;Bagged decision trees:&nbsp;A type of bagged estimate based on decision tree models.</p>\n\n<p><strong><em>Variable importance:</em></strong>&nbsp;A measure of the importance of a predictor variable in the performance of the model.&nbsp;</p>\n\n<p>The simple version of ensembles is as follows:</p>\n\n<ol>\n\t<li>\n\t<p>Develop a predictive model and record the predictions for a given data set.</p>\n\t</li>\n\t<li>\n\t<p>Repeat for multiple models, on the same data.</p>\n\t</li>\n\t<li>\n\t<p>For each record to be predicted, take an average (or a weighted average, or a majority vote) of the predictions.</p>\n\t</li>\n</ol>\n\n<p>Bagging, which stands for &ldquo;bootstrap aggregating&rdquo;.&nbsp;Bagging is like the basic algorithm for ensembles, except that, instead of fitting the various models to the same data, each new model is fit to a bootstrap resample.</p>\n\n<p>The&nbsp;<em>random forest</em>&nbsp;is based on applying bagging to decision trees with one important extension: in addition<a data-primary=\"random forests\" data-type=\"indexterm\" id=\"ix_randfor\"></a>&nbsp;to sampling the records, the algorithm also samples the variables.&nbsp;In traditional decision trees, to determine how to create a subpartition of a partition&nbsp;<em>A</em>, the algorithm makes the choice of variable and split point by minimizing a criterion such as Gini impurity.&nbsp;With random forests, at each stage of the algorithm, the choice of variable is limited to a&nbsp;<em>random subset of variables</em>.</p>\n\n<ol>\n\t<li>\n\t<p>Take a bootstrap (with replacement) subsample from the&nbsp;<em>records</em>.</p>\n\t</li>\n\t<li>\n\t<p>For the first split, sample&nbsp;<em>p</em>&nbsp;&lt;&nbsp;<em>P</em>&nbsp;<em>variables</em>&nbsp;at random without replacement.</p>\n\t</li>\n\t<li>\n\t<p>For each of the sampled variables&nbsp;Xj(1),Xj(2),...,Xj(p)Xj(1),Xj(2),...,Xj(p), apply the splitting&nbsp;algorithm:</p>\n\n\t<ol>\n\t\t<li>\n\t\t<p>For each value&nbsp;sj(k)sj(k)&nbsp;of&nbsp;Xj(k)Xj(k):</p>\n\n\t\t<ol>\n\t\t\t<li>\n\t\t\t<p>Split the records in partition&nbsp;<em>A</em>&nbsp;with&nbsp;<em>X</em><sub>j(k)</sub>&nbsp;&lt;&nbsp;<em>s</em><sub>j(k)</sub>&nbsp;as one partition, and the remaining records where&nbsp;Xj(k)&ge;sj(k)Xj(k)&ge;sj(k)&nbsp;as another partition.</p>\n\t\t\t</li>\n\t\t\t<li>\n\t\t\t<p>Measure the homogeneity of classes within each subpartition of&nbsp;<em>A</em>.</p>\n\t\t\t</li>\n\t\t</ol>\n\t\t</li>\n\t\t<li>\n\t\t<p>Select the value of&nbsp;sj(k)sj(k)&nbsp;that produces maximum within-partition homogeneity of class.</p>\n\t\t</li>\n\t</ol>\n\t</li>\n\t<li>\n\t<p>Select the variable&nbsp;Xj(k)Xj(k)&nbsp;and the split value&nbsp;sj(k)sj(k)&nbsp;that produces maximum within-partition homogeneity of class.</p>\n\t</li>\n\t<li>\n\t<p>Proceed to the next split and repeat the previous steps, starting with step 2.</p>\n\t</li>\n\t<li>\n\t<p>Continue with additional splits following the same procedure until the tree is grown.</p>\n\t</li>\n\t<li>\n\t<p>Go back to step 1, take another bootstrap subsample, and start the process over again.</p>\n\t</li>\n</ol>\n\n<p>How many variables to sample at each step? A rule of thumb is to choose&nbsp;P&oline;&oline;&radic;P&nbsp;where&nbsp;<em>P</em>&nbsp;is the number of predictor variables.&nbsp;</p>\n\n<p>The random forest method is a &ldquo;black box&rdquo; method. It produces more accurate predictions than a simple tree, but the simple tree&rsquo;s intuitive decision rules are lost.&nbsp;</p>\n\n<p>The power of the random forest algorithm shows itself when you build predictive models for data with many features and records.<a data-primary=\"variables\" data-secondary=\"importance of, determining in random forests\" data-type=\"indexterm\" id=\"idm45909254657304\"></a><a data-primary=\"random forests\" data-secondary=\"determining variable importance\" data-type=\"indexterm\" id=\"idm45909254656296\"></a>&nbsp;It has the ability to automatically determine which predictors are important and discover complex relationships between predictors corresponding to interaction terms</p>\n\n<p>There are two ways to measure variable importance:</p>\n\n<ul>\n\t<li>\n\t<p>By the decrease in accuracy of the model if the values of a variable are randomly permuted (<code>type=1</code>). Randomly permuting the values has the effect of removing all predictive power for that variable. The accuracy is computed from the out-of-bag data (so this measure is effectively a cross-validated estimate).</p>\n\t</li>\n\t<li>\n\t<p>By the mean decrease in the Gini impurity score &nbsp;for all of the nodes that were split on a variable (<code>type=2</code>). This measures how much improvement to the purity of the nodes that variable contributes. This measure is based on the training set, and therefore less reliable than a measure calculated on out-of-bag data.</p>\n\t</li>\n</ul>\n\n<p>Why would you eveer use the second one then if it&#39;s less reliable? &mdash; Because it is byproduct of Random Forest algo, doesn&#39;t need extra calculation.</p>\n\n<p>Hyperparameters for RF:</p>\n\n<ol>\n\t<li><code>nodesize</code>: The minimum size for terminal nodes (leaves in the tree). The default is 1 for classification and 5 for regression.</li>\n\t<li><code>maxnodes</code>: The maximum number of nodes in each decision tree. By default, there is no limit and the largest tree will be fit subject to the constraints of&nbsp;<code>nodesize</code>.</li>\n</ol>\n\n<dl>\n\t<dt>It may be tempting to ignore these parameters and simply go with the default values. However, using the default may lead to overfitting when you apply the random forest to noisy data. When you increase&nbsp;<code>nodesize</code>&nbsp;or set&nbsp;<code>maxnodes</code>, the algorithm will fit smaller trees and is less likely to create spurious predictive rules. Cross-validation can be used to test the effects of setting different values for hyperparameters.</dt>\n\t<dt>&nbsp;</dt>\n\t<dt>\n\t<h2>Boosting</h2>\n\n\t<p>While bagging can be done with relatively little tuning, boosting requires much greater care in its application.</p>\n\n\t<p>Boosting&nbsp;fits a series of models with each successive model fit to minimize the error of the previous models. Several variants of the algorithm are&nbsp;commonly&nbsp;used:&nbsp;<em>Adaboost</em>,&nbsp;<em>gradient boosting</em>, and&nbsp;<em>stochastic gradient boosting</em>. The latter, stochastic gradient boosting, is the most general and widely used. Indeed, with the right choice of parameters, the algorithm can emulate the random forest.</p>\n\n\t<p>&nbsp;</p>\n\t</dt>\n</dl>\n\n<h2>Anomaly Detection</h2>\n\n<p>Suppose you have 2 classes X, Y and you want to test whether a test item belongs to class X or class Y. What would you use?</p>\n\n<p>&quot;Logistic Regression, or SVM&quot;</p>\n\n<p>But, here&#39;s a catch you don&#39;t have as many examples for class X as you have for class Y.</p>\n\n<p>Then there&#39;s another option: Anomaly Detection.</p>\n\n<p>Consider the class with fewer examples to be &quot;anomaly&quot;, and train a model over the other class.</p>\n\n<p>&nbsp;</p>\n\n<p>&nbsp;</p>\n\n<p><a href=\"https://projecteuclid.org/euclid.ss/1294167961\">https://projecteuclid.org/euclid.ss/1294167961</a></p>\n","authorId":null,"subject":"ai","tags":["prity=1"],"img":null,"summary":"This is a summary of regression models commonly used in machine learning: Linear Regression, Logistic Regression, SVM","lastUpdated":"2020-06-16T16:36:39.605+0000"}