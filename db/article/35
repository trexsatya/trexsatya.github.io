{"name":"Statistical Learning","id":35,"content":"<p>Sources:&nbsp;<a href=\"https://arxiv.org/pdf/1603.04929.pdf\">https://arxiv.org/pdf/1603.04929.pdf</a></p>\n\n<p><a href=\"https://online.stat.psu.edu/stat508/resource/analysis/gcd\">https://online.stat.psu.edu/stat508/resource/analysis/gcd</a></p>\n\n<p>&nbsp;</p>\n\n<div style=\"background-color: #f3f3f3;color: #17175f;padding: 2%;\">\n<p><strong>Statistical</strong> <strong>Inference</strong> or <strong>Learning&nbsp;</strong>is the process of getting some general sense of data. How do we get this general sense? &mdash; By trying to find the distribution that generated the data (the data that you have gathered somehow randomly).</p>\n\n<p>A statistical <strong>Model</strong> is a set of distributions (or densities&nbsp;or regression functions) <em>[Distributions are functions that tell us probability of observing some data]</em>.</p>\n\n<p>A <strong>parametric model</strong>&nbsp;is a set that can be parameterized by a finite number of parameters e.g. a set of Normals.</p>\n\n<p>In general a parametric model is written in this form:&nbsp;<span class=\"math\">\\bigg\\{ f(x; \\theta): \\theta \\in \\Theta \\bigg\\}</span>&nbsp;E.g. if the data comes from a Normally distributed phenomena, there&#39;ll be 2 params (real numbers): mean, variance.</p>\n\n<p><u>To infer the distribution we make some assumptions</u> e.g:-</p>\n\n<p>Let&nbsp;<span class=\"math\">X_1, X_2, ... X_n</span>&nbsp;be independent RVs(observations)&nbsp; from a CDF&nbsp;<span class=\"math\">F</span>&nbsp;. The problem is to estimate&nbsp;<span class=\"math\">F</span>&nbsp;assuming only that&nbsp;<span class=\"math\">F \\in \\bigg \\{ \\text{all CDF&#39;s} \\bigg \\}</span>&nbsp;This doesn&#39;t actually say much, just that its possible to get some general idea about data if we just assume that we have IIDs from <em>some</em> distribution (we don&#39;t know which). This is <strong>non-parametric model</strong>, we don&#39;t know how many parameters are invloved.</p>\n\n<p>Statistical inference is kind of logical Induction, you get data from a sample space of population. You figure out some numbers, and some functions (think of them as charts/graphs for simplicity), and then make some conclusions about the whole population. Of course, it&#39;s just an attempt,&nbsp;the conclusion may be false.</p>\n\n<p>The chances of conclusion being false increases if the data collected is not from random sample (i.e. the sample itself is biased).</p>\n\n<p>Remember, probability and statistical inference is all about dealing with uncertainties. <a href=\"http://www.utstat.toronto.edu/mikevans/jeffrosenthal/chap5.pdf\" target=\"_blank\">Read this pdf</a>. &quot;This uncertainty is caused both by variation, which can be modeled via probability, and by the fact that we cannot collect enough observations to know the correct probability models precisely.&quot;</p>\n\n<p><strong>Estimator (a.k.a. Statistic):</strong>&nbsp;is a function of&nbsp; (observed) data which approximates real value of parameters of the assumed model.&nbsp; Estimator is said to be <strong><em>consistent</em></strong>&nbsp;if with more and more data, the computed parameter&nbsp;becomes more and more accurate. How far off the calculated value&nbsp;of parameter&nbsp;is (on average if the experiment is done multiple times) from the real value, is called <strong>Bias</strong>.</p>\n\n<p><em>Absence of Bias is desired, but it&#39;s not the only important thing.</em></p>\n\n<p>The squared distance between real value of parameter and calculated value by estimator is called <em>Quadratic Risk</em> (or L2 Risk).&nbsp;</p>\n\n<p>Sometimes, Bias might not even tell you whether your estimator will become better with more and more data. Quadratic Risk, on the other hand, does. If it goes to zero, estimator&nbsp;becomes consistent.</p>\n</div>\n\n<p>If we wanted to find PDF&nbsp;<span class=\"math\">f = F&#39;</span>&nbsp; its not enough to assume only above, we need to assume some smoothness on&nbsp;<span class=\"math\">f</span>&nbsp;e.g.&nbsp;<span class=\"math\">f \\in \\Im = \\Im _{\\text{DENS}} \\cap\\Im _{\\text{SOB}}; \\text{ where } \\Im _{\\text{SOB}} = \\bigg \\{ f: \\int(f&#39;&#39;(x))^2 \\text{d}x \\lt \\infty \\bigg \\}</span>&nbsp; Intersection of set of all PDFs&nbsp;and Sobolev Space.</p>\n\n<p>Suppose we want to estimate mean. Mean can be thought of as function of&nbsp;<span class=\"math\">F</span> &nbsp;<span class=\"math\">\\mu = \\text{E}(X_1) = \\int x \\text{ d}F(x)</span>&nbsp;assuming only that mean exists. Any function of&nbsp;<span class=\"math\">F</span>&nbsp;is called <strong>statistical function</strong>&nbsp;Variance, Median can also be thought of as function of&nbsp;<span class=\"math\">F</span>&nbsp;</p>\n\n<p>&nbsp;</p>\n\n<p>How do we get some general sense of data?</p>\n\n<h2>Histograms and Distributions</h2>\n\n<p>By plotting data as histogram, we get a rough idea of their distribution. And, if we geenerate a curve from the histogram, and then a function for that curve, that gives us better general idea about nature of data. The area under curve represents probability (<em>of range of probabilities</em>).</p>\n\n<p>We generate following statistics from data:</p>\n\n<ol>\n\t<li>Mean</li>\n\t<li>Median</li>\n\t<li>Alpha-trimmed mean (a compromise between above two)</li>\n\t<li>Range, Min, Max, Standard Deviation</li>\n\t<li>Interquartile Range, Q1, Q2, Q3</li>\n</ol>\n\n<p>For Normal Distributions, width of the curve tells us Standard Deviation. More width &rArr;&nbsp;More variation. Center of the curve is at Mean (Average).</p>\n\n<p>We find out skewness of the data: left, or right.</p>\n\n<p>Remarkably most of the data samples after plotting histogram look like Normally distributed. Quantile-quantile plots are used to gain more insight about their shape&#39;s resemblance to Normal distribution.</p>\n\n<p>It is a common misconception that the normal distribution is called that because most data follows a normal distribution&mdash;that is, it is the normal thing. Most of the variables used in a typical data science project&mdash;in fact most raw data as a whole&mdash;are&nbsp;<em>not</em>&nbsp;normally distributed: see&nbsp;<a data-type=\"xref\" href=\"https://learning.oreilly.com/library/view/practical-statistics-for/9781491952955/ch02.html#LongTailedData\">&ldquo;Long-Tailed Distributions&rdquo;</a>. The utility of the normal distribution derives from the fact that many statistics&nbsp;<em>are</em>&nbsp;normally distributed in their sampling distribution. Even so, assumptions of normality are generally a last resort, used when empirical probability distributions, or bootstrap distributions, are not available.</p>\n\n<p>&nbsp;</p>\n\n<p>Histograms are good for showing single variables distribution, but there are many other tools:</p>\n\n<ul>\n\t<li>Boxplots - which are helpful in finding outliers.</li>\n\t<li>Scatterplot - for visualizing relationships b/w two variables.</li>\n\t<li>Contour plot&nbsp;- for visualizing relationships b/w two variables especially when variables are continuous values.</li>\n\t<li>Starplot - for visualizing relationship among multiple variables.</li>\n</ul>\n\n<p>&nbsp;</p>\n\n<p>Ok, but how would you get these statistics for a population that is huge. You can&#39;t measure all members of population, that would&nbsp;be too&nbsp;costly, time-consuming. So, instead we choose some random sample from the population and estimate these statistics.</p>\n\n<p>How to choose <em>Sample</em> from <em>Population</em>?</p>\n\n<h2>Random Sampling</h2>\n\n<p><strong>Simple Random Sampling (SRS)</strong></p>\n\n<p>Select <em>units</em>&nbsp;(members of population) uniformly at random, without replacement. Note: since the selection is without replacement, the Random Variables that denote the selection become dependent.</p>\n\n<p>We find sample mean, and find out how accurately it approximates the population mean.</p>\n\n<p>We find variance of sample mean, Standard Errors (Standard deviation of estimators are called S.E. is square-root of Variance)</p>\n\n<p>The variance of a sample is given by (in terms of population mean, which we don&#39;t know)&nbsp;<span class=\"math\">\\frac{\\sigma^2}{n}(1-\\frac{n-1}{N-1})</span></p>\n\n<p>&nbsp;</p>\n\n<h2>Confidence Intervals</h2>\n\n<p>Sample Mean is <em>point estimate</em> (a single number), we would also like to know the entire distribution of&nbsp;sample mean. <a href=\"https://en.wikipedia.org/wiki/Central_limit_theorem\" target=\"_blank\">Central Limit Theorem </a>(CLT) tells us about the distribution of sample means.</p>\n\n<p>CLT is strictly speaking for IIDs (Independent and Identically Distributed), and our Simple Random Sampling is not independent. But, if both n and N are large, then&nbsp;<span class=\"math\">X_i</span>&nbsp;are nearly independent.&nbsp;</p>\n\n<p>If we know how much accurate our approximation of sample mean should be to population (Normal) mean:</p>\n\n<div class=\"math\">\\displaystyle P(|\\overline{X}_n -\\mu| \\le \\epsilon) \\approx 2\\Phi \\bigg( \\frac{\\epsilon}{\\text{se}[ \\overline X_n] }\\bigg) -1 \\text{ where } \\Phi(z) \\text{ is CDF of } N(0,1)</div>\n\n<p>We calculate interval and say &quot;x% confidence interval for population parameter e.g. mean&quot;.&nbsp;</p>\n\n<div class=\"math\">P \u0010( \\overline X_n &minus; z_{1&minus; &alpha;/2} \\text{ se}[\\overline X_n] &le; &micro; &le; \\overline X_n + z_{1&minus; &alpha; /2} \\text{ se}[\\overline X_n] \u0011 &asymp; 1 &minus; &alpha;. \\text{ where }z_i \\text{ is the } i^{th} \\text{ standard normal quantile}</div>\n\n<p>The interpretation of this probability is Frequentist.</p>\n\n<p><span class=\"math\">\\alpha</span>&nbsp;is called &quot;<strong>Significance</strong> level&quot; It tells &quot;we know that we can make&nbsp;<em>&alpha;%</em>&nbsp;of the times, Type-I error i.e. reject Null Hypothesis when it actually is true&quot;.</p>\n\n<p>The probability of rejecting the null hypothesis when it is in fact false is called the <strong>power</strong> of the test and is denoted by 1 -&nbsp;&beta;.</p>\n\n<p>Given a sample of size&nbsp;<em>n</em>, and a sample statistic of interest, the algorithm for a<a data-primary=\"confidence intervals\" data-secondary=\"generating with bootstrap\" data-type=\"indexterm\" id=\"idm45909266890712\"></a><a data-primary=\"bootstrap\" data-secondary=\"confidence interval generation\" data-type=\"indexterm\" id=\"idm45909266889672\"></a>&nbsp;bootstrap confidence interval is as follows:</p>\n\n<ol>\n\t<li>\n\t<p>Draw a random sample of size&nbsp;<em>n</em>&nbsp;with replacement from the data (a resample).</p>\n\t</li>\n\t<li>\n\t<p>Record the statistic of interest for the resample.</p>\n\t</li>\n\t<li>\n\t<p>Repeat steps 1&ndash;2 many (<em>R</em>) times.</p>\n\t</li>\n\t<li>\n\t<p>For an&nbsp;<em>x</em>% confidence interval, trim [(100-<em>x</em>) / 2]% of the&nbsp;<em>R</em>&nbsp;resample results from either end of the distribution.</p>\n\t</li>\n\t<li>\n\t<p>The trim points are the endpoints of an&nbsp;<em>x</em>% bootstrap confidence interval.</p>\n\t</li>\n</ol>\n\n<p>Its complement, the probability of accepting the null hypothesis when the alternative hypothesis is, in fact, true (type II error), is called&nbsp;&beta; and can only be computed for a specific alternative hypothesis.</p>\n\n<p>Confidence limits for the mean can be used to answer the following questions:</p>\n\n<ol>\n\t<li>What is a reasonable estimate for the mean?</li>\n\t<li>How much variability is there in the estimate of the mean?</li>\n\t<li>Does a given target value fall within the confidence limits?</li>\n</ol>\n\n<p>Confidence Set: If the parameter is a vector instead of a single number, we choose confidence set instead of interval. It can be cube, ellipsoid, sphere, or any other random set that traps parameter with certain confidence (probability).</p>\n\n<p>The bootstrap is a general tool that can be used to generate confidence intervals for most statistics, or model parameters. Statistical textbooks and software, with roots in over a half-century of computerless statistical analysis, will also reference confidence intervals generated by formulas, especially the t-distribution (see&nbsp;<a data-type=\"xref\" href=\"https://learning.oreilly.com/library/view/practical-statistics-for/9781491952955/ch02.html#t-distribution\">&ldquo;Student&rsquo;s t-Distribution&rdquo;</a>).</p>\n\n<p>The probability question associated with a confidence interval starts out with the phrase &ldquo;Given a sampling procedure and a population, what is the probability that&hellip;&rdquo; To go in the opposite direction, &ldquo;Given a sample result, what is the probability that (something is true about the population),&rdquo; involves more complex calculations and deeper imponderables.</p>\n\n<p>&nbsp;</p>\n\n<h2>Statistical Models</h2>\n\n<p>We get Standard Error from sample Variance.</p>\n\n<p>Bias is the difference between average of point estimate of a parameter (e.g.&nbsp;mean of sample) from the actual mean of population.</p>\n\n<p>Mean Squared Error is the average of these differences; and can be represented in terms of Bias and Variance</p>\n\n<div class=\"math\">\\text{MSE}[\\hat\\theta_n] = \\text{E}[ (\\hat \\theta_n - \\theta)^2] = \\text{Bias}^2 + \\text{se}^2 \\text{ where Bias}= \\text{E}[\\hat \\theta_n] - \\theta</div>\n\n<p>&nbsp;</p>\n\n<h2>Statistical Functions</h2>\n\n<p>Any function of CDF. Here&#39;s a common list of such functions:</p>\n\n<ol>\n\t<li><span class=\"math\">\\int x dF(x) = &micro;_F, \\text{ mean}</span></li>\n\t<li><span class=\"math\">\\int (x &minus; &micro;_F)^ 2dF(x) = &sigma;^2_F , \\text{variance}</span></li>\n\t<li><span class=\"math\">\\frac{&sigma;_F }{&micro;_F} = &delta;_F \\text{ coefficient of variation,}</span></li>\n\t<li><span class=\"math\">F^{-1}(1/2) = m_F \\text{ median,}</span></li>\n\t<li><span class=\"math\">\\frac{ \\int (x&minus;&micro;_F)^3 dF(x) } {( \\int (x&minus;&micro;_F)^3dF(x))^{3/2}} = &kappa;_F, \\text{skewness}</span></li>\n</ol>\n\n<p>&nbsp;</p>\n\n<p>How do we get functional from sample data?</p>\n\n<ul>\n\t<li>Simply plug-in the parameter calculated from sample in the functional&#39;s function</li>\n\t<li>If we somehow already have estimated some other parameter, plugin conditional F in the functional</li>\n</ul>\n\n<p>&nbsp;</p>\n\n<h2>Jacknife Method</h2>\n\n<p>How do you estimate a Bias when you only have a single sample? If you had m samples, you could use Law of Large numbers and take the average over m values of sample-parameters.</p>\n\n<p>The idea is to emulate by copying the given sample m&nbsp;times but each time leaving one sample-point out.</p>\n\n<p>&nbsp;</p>\n\n<h2>Population Variance and Bootstrap Method</h2>\n\n<p>We can find a number close to variance of the population just by using samples:</p>\n\n<div class=\"math\">s^2 = \\hat{\\sigma_n}^2\\frac{Nn-n}{Nn-N} \\text{ and } \\text{se}[\\overline{X}_n] \\approx \\frac{s}{\\sqrt{n}} \\sqrt{( 1- \\frac{n-1}{N-1})}</div>\n\n<p>Bootstrap Principle:</p>\n\n<p>Once we select n samples from population, we clone each sample point N/n times, thus getting a &quot;population&quot; of size N. This is called Monte Carlo Simulation.</p>\n\n<p>Rest is same. We get standard errors by using formula:</p>\n\n<div class=\"math\">\\displaystyle \\text{se}[\\overline{X}_n] \\approx \\hat{\\text{se}}[\\overline{X}_n] = \\sqrt{\\frac{1}{B}\\sum_{i=1}^B \\bigg(\\overline{X}_n ^{(i)} - \\frac{1}{B} \\sum_{j=1}^B \\overline{X}_n ^{(j)} \\bigg)^2}</div>\n\n<p>&nbsp;</p>\n\n<p><img alt=\"Bootstrap\" src=\"/images/ml_bootstrap_method.png\" style=\"max-height: 300px; max-width: 600px;\" /></p>\n\n<p>But then an obvious question arises, how many replications would you make?&nbsp;<a href=\"https://books.google.co.in/books?id=gLlpIUxRntoC&amp;redir_esc=y\">An Introduction to the Bootstrap</a>. A rule of thumb is not more than 200 are required normally.</p>\n\n<p>&nbsp;</p>\n\n<p><strong>Bootstrap Confidence Intervals:</strong></p>\n\n<p>By virtue of Central Limit Theorem, it turns out that many for many reasonable distributions F and functionals t, the distribution of&nbsp;</p>\n\n<div class=\"math\">\\hat \\theta_n = t(\\hat F_n) \\sim N(\\theta, \\hat{\\text{se} }^2 ) \\text{ or equivalently } \\frac{\\hat &theta;_n &minus; &theta;}{\\hat{\\text{se}} } \\sim N (0, 1)</div>\n\n<p>The confidence interval for bootstrapped samples will be:</p>\n\n<div class=\"math\">I = \\hat&theta;_n &plusmn; z_{&alpha;/2} \\hat{\\text{ se}} \\text{ where } z_&alpha; = \\Phi^{-1}(&alpha;); \\Phi \\text{ is Standard Normal CDF}</div>\n\n<p>We can also construct confidence interval without Normal theory assumptions.</p>\n\n<p>There are many ways to construct confidence intervals under&nbsp;Bootstrap method.</p>\n\n<p>&nbsp;</p>\n\n<h2>Parametric Modelling</h2>\n\n<p>Whenever the number of parameters is known, it&#39;s a parametric model. Basically in parametric modelling, we believe that there exists some value of &theta; in &Theta; such that the distribution f(x; &theta;) does well (for all practical purposes) in describing the randomness in the data.</p>\n\n<p>But which parameter model to use? - That depends on prior experience and intuition.</p>\n\n<p>We might not just be interested in some parameter, but a function of that parameter as well.</p>\n\n<p>&nbsp;</p>\n\n<p><strong>Maximum Likelihood Estimation:</strong></p>\n\n<p>It&#39;s like asking &quot;What value of parameter makes the data at hand most likely?&quot; (We have the data, we just have to find a parameter which agrees with the data).</p>\n\n<p><em>Likelihood Function</em>&nbsp;is the joint probability of the data <em>viewed as a function of the parameter&nbsp;&theta;</em>.&nbsp;<span class=\"math\">\\displaystyle L(&theta;|X_1, . . . , X_n) = \\prod_{i=1}^n f(X_i ; &theta;)</span></p>\n\n<p>We can also reach this definition of likelihood through Total Variation Distance to KL-Divergence to Likelihood function. <a href=\"https://youtu.be/rLlZpnT02ZU?t=2117\" target=\"_blank\">See this video</a>.</p>\n\n<p>The above equation is for independent RVs, but likelihood function can be found&nbsp;for dependent RVs as well.</p>\n\n<p>Maximum Likelihood Estimation (MLE) looks for the&nbsp;<em>&theta;&nbsp;</em>that maximizes the value of likelihood function output.</p>\n\n<p>We generally find maximum value by equating differential of function to zero. But in most cases finding differential is a touch job, so instead we maximize the log of the likelihood function. And it doesn&#39;t change the result.</p>\n\n<p>The problem with MLEs is that:</p>\n\n<ol>\n\t<li>The MLE may not exist</li>\n\t<li>The MLE may not be unique</li>\n\t<li>Finding global maxima is a difficult job</li>\n\t<li>There may be many local maxima and finding global maxima requires extra effort</li>\n\t<li>Sometimes a slightly different sample may produce vaastly different MLE</li>\n</ol>\n\n<p>The good thing about MLEs (which make it very popular) are:</p>\n\n<ol>\n\t<li>It is consistent: As you get more and more data MLE of sample parameter approximates real value of parameter more and more accurately.</li>\n\t<li>Asymptotic Normality: For large n (i.e. you have huge sample), the MLE of parameter is approximately Normally distributed.</li>\n\t<li>Asymptotic Confidence Intervals: By virtue of the above, we can say that we can get asymptotic confidence interval</li>\n\t<li>For <strong><em>large</em></strong> samples, MLE has the smallest (compared to other estimates) variance.</li>\n\t<li>If we already know the MLE for a parameter, we can easily find MLE for a function of that parameter, by simply plugging-in the MLE into that function.</li>\n</ol>\n\n<p>&nbsp;</p>\n\n<h2>Statistical Experiments and Significance Testing:</h2>\n\n<p>Source:&nbsp;<a href=\"https://learning.oreilly.com/library/view/practical-statistics-for/9781491952955/ch03.html\">https://learning.oreilly.com/library/view/practical-statistics-for/9781491952955/ch03.html</a></p>\n\n<p>The process:</p>\n\n<ol>\n\t<li>Formulate Hypothesis. (e.g. Drug A is better than Drug B, price A is more profitable than price B&nbsp; etc)</li>\n\t<li>Design Experiment</li>\n\t<li>Collect Data</li>\n\t<li>Inference&nbsp;/ Conclusion</li>\n</ol>\n\n<p>Treatment</p>\n\n<p>Treatment Group</p>\n\n<p>Control Group: e.g. the group of subjects which are either given no drug or the traditional drug.</p>\n\n<p><em><strong>Test Statisitic</strong></em>: The metric used for comparision. Must be decided beforehand,&nbsp; otherwise it would be biased.</p>\n\n<p><em><strong>Hypothesis Tests</strong></em> / <em><strong>Significance Tests</strong></em>: the purpose is to determine whether random chance might be&nbsp; responsible for the observed effect.</p>\n\n<p><strong><em>Null Hypothesis</em></strong>: is that chance is to blame.&nbsp;<strong><em>Alternative hypothesis</em></strong>&nbsp;is counterpoint to null hypothesis.</p>\n\n<p>Why need hypothesis, why not just compare the experiment results? &mdash; To avoid being fooled by random chance, sometimes we can mistakenly try to find significant patterns in random events. It also helps us in considering extreme events e.g. Black Swans.</p>\n\n<p>One-way (one-tail) hypothesis: e.g. &quot;New Treatment is better than the Current Treatment&quot;</p>\n\n<p>Two-way (two-tail) hypothesis: e.g. &quot;New Treatment is different from the Current Treatment&quot;</p>\n\n<p>We start with a default theory <em>&quot;null hypothesis&quot; (H0)</em>&nbsp;and ask &quot;does the data collected provide sufficient evidence to reject this theory?&quot;. If yes, we reject it else we accept it (more precisely, keep it for now). Generally the Null Hypothesis represents <em>&quot;it&#39;s not special, different from general&quot;.</em></p>\n\n<p>We conceptually divide sample space in <em>Rejection-Region</em>, and non-rejection region. If the observed data falls in <em>Rejection-Region</em>&nbsp;we reject the hypothesis.&nbsp; Correspondingly we divide <em>parameter space</em> into two <span class=\"math\">&Theta;_0 \\text{ and } &Theta;_1</span>.&nbsp;</p>\n\n<p>While doing this there are two types of errors possible:</p>\n\n<ol>\n\t<li>Type I:&nbsp;Rejecting <em>H0</em>&nbsp;when it is true</li>\n\t<li>Type II: Accepting <em>H0</em><i>&nbsp;</i>when it is not true.</li>\n</ol>\n\n<p>Even though generally speaking both errors are bad, in few specific cases we can tolerate one type of error more than the other. E.g. declaring an innocent person guilty is worse than declaring a guilty person innocent.</p>\n\n<p>The power function of a parameter, of a hypothesis test with rejection region R is:&nbsp;</p>\n\n<div class=\"math\">&beta;(&theta;) = P(X &isin; R|&theta;). \\text{ or } &beta;(&theta;) = \\begin{cases} P(\\text{Type I error}) \\text{ if } &theta; &isin; &Theta;_0 \\\\ 1 &minus; P(\\text{Type II error}) \\text{ if } &theta; &isin; &Theta;_1 \\end{cases}</div>\n\n<p>The <em>level</em> or <em>size</em> of the test is said to be&nbsp;the largest possible probability of the type I error (rejecting H0 when it is true).</p>\n\n<p><strong>Wald Test</strong></p>\n\n<p>Let &theta; be the parameter of interest, and suppose we want to test&nbsp;<span class=\"math\">H_0 : &theta; = &theta;_0 \\text{ versus } H_1 : &theta;\\ne &theta;_0</span></p>\n\n<p>Let&nbsp;<span class=\"math\">\\hat{&theta;} = \\hat{&theta;}_\\text{MLE}</span>&nbsp;be an estimate of parameter, and&nbsp;<span class=\"math\">\\hat{\\text{se}} \\approx\\frac{1}{\\sqrt{nI(\\theta_0)}}; \\text{ where } I(\\theta_0) = E \\bigg [ \\bigg( \\frac{&part;\\text{ log } f(X; \\theta)}{&part;\\theta} \\bigg \\vert_{&theta;=&theta;_0} \\bigg)^2 \\bigg]</span>&nbsp;be estimated standard error. Assume that estimated parameter is Normally distributed i.e&nbsp;<span class=\"math\">\\frac{\\hat{&theta;} &minus; &theta;}{\\hat{\\text{se}}} \\sim N(0,1)</span></p>\n\n<p>In this setting if null hypothesis is true, then the above quantity is likely to be small. So, it seems rational to reject ull hypothesis if&nbsp;<span class=\"math\">W = \\bigg\\lvert \\frac{\\hat{&theta;} &minus; &theta;}{\\hat{\\text{se}}} \\bigg\\rvert \\gt c</span>&nbsp;As usual we find the critical value c from the <em>size</em> of the test.&nbsp;</p>\n\n<p>Since&nbsp;<span class=\"math\">H_0</span>&nbsp;is a simple hypothesis, the <em>size</em>&nbsp;<span class=\"math\">&alpha; = \\underset{&theta; &isin; &Theta;_0}{\\text{sup }} &beta;(&theta;) = &beta;(&theta;_0)</span></p>\n\n<p>Since under null hypothesis&nbsp;<span class=\"math\">\\frac{\\hat{&theta;} &minus; &theta;}{\\hat{\\text{se}}} \\sim N(0,1)</span>&nbsp;we have&nbsp;<span class=\"math\">&beta;(&theta;_0) = P (W \\gt c|&theta; = &theta;_0) = P\\bigg( \\bigg\\lvert \\frac{\\hat{&theta;} &minus; &theta;}{\\hat{\\text{se}}} \\bigg\\rvert \\gt c \\bigg ) \\approx 2\\Phi(-c)</span> &nbsp;</p>\n\n<p>We can find critical value c by taking inverse of it.</p>\n\n<p>We can also get the power function and confidence interval easily. Wald test gives straightforward formulae under some assumptions.</p>\n\n<p>&nbsp;</p>\n\n<p><strong>T-Test</strong></p>\n\n<p>T-test is commonly used in place of Wald test for simple hypothesis, if:</p>\n\n<ol>\n\t<li>The data is modeled as a sample from the normal distribution,</li>\n\t<li>The sample size is small</li>\n</ol>\n\n<p>When n is moderately large (say, n &asymp; 30), the t-test is essentially identical to the Wald test.</p>\n\n<p>You can perform these tests in two ways:</p>\n\n<ol>\n\t<li>One-sample: To compare sample statistic to target statistic</li>\n\t<li>Two-samples: To compare two given samples.</li>\n</ol>\n\n<p>Two-sample&nbsp;<i>t</i>-tests can be used to answer the following questions:</p>\n\n<ol>\n\t<li>Is process 1 equivalent to process 2?</li>\n\t<li>Is the new process better than the current process?</li>\n\t<li>Is the new process better than the current process by at least some pre-determined threshold amount?</li>\n</ol>\n\n<p>&nbsp;</p>\n\n<h2>P-Values</h2>\n\n<p>Why P-Values? Because &quot;just saying that accept&nbsp;or reject this hypothesis&quot; is not enough, we need more information.</p>\n\n<p>Given a chance model that embodies the null hypothesis, the p-value is the probability of obtaining results as unusual or extreme as the observed results.</p>\n\n<p>P-Values cane be seen to represent probability of False-Positives of Null-Hypothesis when same experiment is repeated number of times. It is probability that the sample statistics (mean for example) is greater than or equal to observed sample statistics <em>given</em>&nbsp;that the Null-hypothesis is true. Higher p-value basically means maybe there&#39;s nothing interesting going on, it&#39;s just chance.</p>\n\n<p>There&#39;re two kinds of p-values: One sided, Two Sided.</p>\n\n<p>P-Values is sum of probabilities:</p>\n\n<ol>\n\t<li>Probability that observation is due to random chance.</li>\n\t<li>Probability of observing something else that is equally likely. (Because this and below one will also contribute to rejecting the null-hypothesis)</li>\n\t<li>Probability of observing something else that is rarer or more extreme.</li>\n</ol>\n\n<p>If a test rejects a hypothesis at size&nbsp;&alpha; it will also reject it at any size greater than&nbsp;&alpha;. So, there exists a minimum value of &alpha; at which test rejects, that value is called P-Value.</p>\n\n<p>When p-value is close to 0.05, adding a few more data points to both distributions (which we are comparing) will result in a False-Positive (smaller p-value). This is misuse of p-value. To avoid this, fix the sample size before doing the experiment. For that use Power Analysis.</p>\n\n<p>Typically, researchers use the following evidence scale:&nbsp;</p>\n\n<ol>\n\t<li>p(X) &lt; 0.01 very strong evidence agianst H0 ,</li>\n\t<li>p(X) &isin; (0.01, 0.05) strong evidence agianst H0,</li>\n\t<li>p(X) &isin; (0.05, 0.1) weak evidence agianst H0,</li>\n\t<li>p(X) &gt; 0.1 little or no evidence agianst H0</li>\n</ol>\n\n<p>Calcultaing p-value from sample: <a href=\"https://www.khanacademy.org/math/ap-statistics/tests-significance-ap/idea-significance-tests/v/estimating-p-value-from-simulation\" target=\"_blank\">Khan Academy</a></p>\n\n<p>&nbsp;</p>\n\n<h2>Resampling</h2>\n\n<p>Done by either Bootstrap tests or Permutation tests</p>\n\n<dl>\n\t<dt><strong><em>Permutation test /&nbsp;</em></strong>Randomization test&nbsp;/&nbsp;random permutation test /&nbsp;exact test:</dt>\n\t<dd>\n\t<p>The procedure of combining two or more samples together, and randomly (or exhaustively) reallocating the observations to resamples<a data-primary=\"randomization tests\" data-seealso=\"permutation tests\" data-type=\"indexterm\" id=\"idm45909266145864\"></a></p>\n\t</dd>\n\t<dt><strong><em>With or without replacement</em></strong>: In sampling, whether or not an item is returned to the sample before the next draw.</dt>\n\t<dd>\n\t<p>&nbsp;</p>\n\t</dd>\n</dl>\n\n<p>Further Readings:</p>\n\n<p><a href=\"http://pages.stat.wisc.edu/~ifischer/Intro_Stat/Lecture_Notes/6_-_Statistical_Inference/6.1_-_One_Sample.pdf\">http://pages.stat.wisc.edu/~ifischer/Intro_Stat/Lecture_Notes/6_-_Statistical_Inference/6.1_-_One_Sample.pdf</a></p>\n\n<p><a href=\"https://www.cbs.nl/-/media/imported/documents/2009/07/2009-15-x10-pub.pdf\">https://www.cbs.nl/-/media/imported/documents/2009/07/2009-15-x10-pub.pdf</a></p>\n\n<p><a href=\"https://www.diva-portal.org/smash/get/diva2:881207/FULLTEXT01.pdf\">https://www.diva-portal.org/smash/get/diva2:881207/FULLTEXT01.pdf</a></p>\n\n<p><a href=\"https://drive.uqu.edu.sa/_/maatia/files/Sampling.pdf\">https://drive.uqu.edu.sa/_/maatia/files/Sampling.pdf</a></p>\n\n<p><a href=\"https://projecteuclid.org/download/pdf_1/euclid.ss/1009213726\">https://projecteuclid.org/download/pdf_1/euclid.ss/1009213726</a></p>\n\n<p><a href=\"https://www.researchgate.net/publication/37434447_Bootstrap_Methods_and_Their_Application\">https://www.researchgate.net/publication/37434447_Bootstrap_Methods_and_Their_Application</a></p>\n\n<p><a href=\"http://www.deeplearningbook.org/\">http://www.deeplearningbook.org/</a></p>\n\n<h2>Examples-1</h2>\n\n<p><a href=\"https://online.stat.psu.edu/stat508/resource/analysis/gcd\" target=\"_blank\">German Credit Data</a>:</p>\n\n<table style=\"border-collapse:collapse; border:undefined\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<td style=\"width:57.0px; border-style:solid; border-width:1.0px 1.0px 1.0px 1.0px; border-color:#000000 #000000 #000000 #000000\">\n\t\t\t<p style=\"margin:0.0px 0.0px 0.0px 0.0px; padding:4.0px 4.0px 4.0px 4.0px\"><span style=\"height:11.0px\"><span style=\"background-color:#d4d4d4\"><font face=\"Helvetica Neue\"><font size=\"2\"><font color=\"#000000\"><font style=\"font: 10.0px 'Helvetica Neue'; font-kerning: none; font-variant-ligatures: common-ligatures; color: #000000; -webkit-text-stroke: 0px #ffffff\"><b>Creditability</b></font></font></font></font></span></span></p>\n\n\t\t\t<p style=\"margin:0.0px 0.0px 0.0px 0.0px; padding:4.0px 4.0px 4.0px 4.0px\"><span style=\"height:11.0px\"><span style=\"background-color:#d4d4d4\"><font face=\"Helvetica Neue\"><font size=\"2\"><font color=\"#000000\"><font style=\"font: 10.0px 'Helvetica Neue'; font-kerning: none; font-variant-ligatures: common-ligatures; color: #000000; -webkit-text-stroke: 0px #ffffff\"><b>(0/1)</b></font></font></font></font></span></span></p>\n\t\t\t</td>\n\t\t\t<td style=\"width:81.0px; border-style:solid; border-width:1.0px 1.0px 1.0px 1.0px; border-color:#000000 #000000 #000000 #000000\">\n\t\t\t<p style=\"margin:0.0px 0.0px 0.0px 0.0px; padding:4.0px 4.0px 4.0px 4.0px\"><span style=\"height:11.0px\"><font face=\"Helvetica Neue\"><font size=\"2\"><font color=\"#000000\"><font style=\"font: 10.0px 'Helvetica Neue'; font-kerning: none; font-variant-ligatures: common-ligatures; color: #000000; -webkit-text-stroke: 0px #ffffff\">Account Balance</font></font></font></font></span></p>\n\t\t\t</td>\n\t\t\t<td style=\"width:124.0px; border-style:solid; border-width:1.0px 1.0px 1.0px 1.0px; border-color:#000000 #000000 #000000 #000000\">\n\t\t\t<p style=\"margin:0.0px 0.0px 0.0px 0.0px; padding:4.0px 4.0px 4.0px 4.0px\"><span style=\"height:11.0px\"><font face=\"Helvetica Neue\"><font size=\"2\"><font color=\"#000000\"><font style=\"font: 10.0px 'Helvetica Neue'; font-kerning: none; font-variant-ligatures: common-ligatures; color: #000000; -webkit-text-stroke: 0px #ffffff\">Duration of Credit (month)</font></font></font></font></span></p>\n\t\t\t</td>\n\t\t\t<td style=\"width:163.0px; border-style:solid; border-width:1.0px 1.0px 1.0px 1.0px; border-color:#000000 #000000 #000000 #000000\">\n\t\t\t<p style=\"margin:0.0px 0.0px 0.0px 0.0px; padding:4.0px 4.0px 4.0px 4.0px\"><span style=\"height:11.0px\"><font face=\"Helvetica Neue\"><font size=\"2\"><font color=\"#000000\"><font style=\"font: 10.0px 'Helvetica Neue'; font-kerning: none; font-variant-ligatures: common-ligatures; color: #000000; -webkit-text-stroke: 0px #ffffff\">Payment Status of Previous Credit</font></font></font></font></span></p>\n\t\t\t</td>\n\t\t\t<td style=\"width:40.0px; border-style:solid; border-width:1.0px 1.0px 1.0px 1.0px; border-color:#000000 #000000 #000000 #000000\">\n\t\t\t<p style=\"margin:0.0px 0.0px 0.0px 0.0px; padding:4.0px 4.0px 4.0px 4.0px\"><span style=\"height:11.0px\"><font face=\"Helvetica Neue\"><font size=\"2\"><font color=\"#000000\"><font style=\"font: 10.0px 'Helvetica Neue'; font-kerning: none; font-variant-ligatures: common-ligatures; color: #000000; -webkit-text-stroke: 0px #ffffff\">Purpose</font></font></font></font></span></p>\n\t\t\t</td>\n\t\t\t<td style=\"width:69.0px; border-style:solid; border-width:1.0px 1.0px 1.0px 1.0px; border-color:#000000 #000000 #000000 #000000\">\n\t\t\t<p style=\"margin:0.0px 0.0px 0.0px 0.0px; padding:4.0px 4.0px 4.0px 4.0px\"><span style=\"height:11.0px\"><font face=\"Helvetica Neue\"><font size=\"2\"><font color=\"#000000\"><font style=\"font: 10.0px 'Helvetica Neue'; font-kerning: none; font-variant-ligatures: common-ligatures; color: #000000; -webkit-text-stroke: 0px #ffffff\">Credit Amount</font></font></font></font></span></p>\n\t\t\t</td>\n\t\t\t<td style=\"width:102.0px; border-style:solid; border-width:1.0px 1.0px 1.0px 1.0px; border-color:#000000 #000000 #000000 #000000\">\n\t\t\t<p style=\"margin:0.0px 0.0px 0.0px 0.0px; padding:4.0px 4.0px 4.0px 4.0px\"><span style=\"height:11.0px\"><font face=\"Helvetica Neue\"><font size=\"2\"><font color=\"#000000\"><font style=\"font: 10.0px 'Helvetica Neue'; font-kerning: none; font-variant-ligatures: common-ligatures; color: #000000; -webkit-text-stroke: 0px #ffffff\">Value Savings/Stocks</font></font></font></font></span></p>\n\t\t\t</td>\n\t\t\t<td style=\"width:144.0px; border-style:solid; border-width:1.0px 1.0px 1.0px 1.0px; border-color:#000000 #000000 #000000 #000000\">\n\t\t\t<p style=\"margin:0.0px 0.0px 0.0px 0.0px; padding:4.0px 4.0px 4.0px 4.0px\"><span style=\"height:11.0px\"><font face=\"Helvetica Neue\"><font size=\"2\"><font color=\"#000000\"><font style=\"font: 10.0px 'Helvetica Neue'; font-kerning: none; font-variant-ligatures: common-ligatures; color: #000000; -webkit-text-stroke: 0px #ffffff\">Length of current employment</font></font></font></font></span></p>\n\t\t\t</td>\n\t\t\t<td style=\"width:92.0px; border-style:solid; border-width:1.0px 1.0px 1.0px 1.0px; border-color:#000000 #000000 #000000 #000000\">\n\t\t\t<p style=\"margin:0.0px 0.0px 0.0px 0.0px; padding:4.0px 4.0px 4.0px 4.0px\"><span style=\"height:11.0px\"><font face=\"Helvetica Neue\"><font size=\"2\"><font color=\"#000000\"><font style=\"font: 10.0px 'Helvetica Neue'; font-kerning: none; font-variant-ligatures: common-ligatures; color: #000000; -webkit-text-stroke: 0px #ffffff\">Instalment per cent</font></font></font></font></span></p>\n\t\t\t</td>\n\t\t\t<td style=\"width:96.0px; border-style:solid; border-width:1.0px 1.0px 1.0px 1.0px; border-color:#000000 #000000 #000000 #000000\">\n\t\t\t<p style=\"margin:0.0px 0.0px 0.0px 0.0px; padding:4.0px 4.0px 4.0px 4.0px\"><span style=\"height:11.0px\"><font face=\"Helvetica Neue\"><font size=\"2\"><font color=\"#000000\"><font style=\"font: 10.0px 'Helvetica Neue'; font-kerning: none; font-variant-ligatures: common-ligatures; color: #000000; -webkit-text-stroke: 0px #ffffff\">Sex &amp; Marital Status</font></font></font></font></span></p>\n\t\t\t</td>\n\t\t\t<td style=\"width:54.0px; border-style:solid; border-width:1.0px 1.0px 1.0px 1.0px; border-color:#000000 #000000 #000000 #000000\">\n\t\t\t<p style=\"margin:0.0px 0.0px 0.0px 0.0px; padding:4.0px 4.0px 4.0px 4.0px\"><span style=\"height:11.0px\"><font face=\"Helvetica Neue\"><font size=\"2\"><font color=\"#000000\"><font style=\"font: 10.0px 'Helvetica Neue'; font-kerning: none; font-variant-ligatures: common-ligatures; color: #000000; -webkit-text-stroke: 0px #ffffff\">Guarantors</font></font></font></font></span></p>\n\t\t\t</td>\n\t\t\t<td style=\"width:132.0px; border-style:solid; border-width:1.0px 1.0px 1.0px 1.0px; border-color:#000000 #000000 #000000 #000000\">\n\t\t\t<p style=\"margin:0.0px 0.0px 0.0px 0.0px; padding:4.0px 4.0px 4.0px 4.0px\"><span style=\"height:11.0px\"><font face=\"Helvetica Neue\"><font size=\"2\"><font color=\"#000000\"><font style=\"font: 10.0px 'Helvetica Neue'; font-kerning: none; font-variant-ligatures: common-ligatures; color: #000000; -webkit-text-stroke: 0px #ffffff\">Duration in Current address</font></font></font></font></span></p>\n\t\t\t</td>\n\t\t\t<td style=\"width:140.0px; border-style:solid; border-width:1.0px 1.0px 1.0px 1.0px; border-color:#000000 #000000 #000000 #000000\">\n\t\t\t<p style=\"margin:0.0px 0.0px 0.0px 0.0px; padding:4.0px 4.0px 4.0px 4.0px\"><span style=\"height:11.0px\"><font face=\"Helvetica Neue\"><font size=\"2\"><font color=\"#000000\"><font style=\"font: 10.0px 'Helvetica Neue'; font-kerning: none; font-variant-ligatures: common-ligatures; color: #000000; -webkit-text-stroke: 0px #ffffff\">Most valuable available asset</font></font></font></font></span></p>\n\t\t\t</td>\n\t\t\t<td style=\"width:53.0px; border-style:solid; border-width:1.0px 1.0px 1.0px 1.0px; border-color:#000000 #000000 #000000 #000000\">\n\t\t\t<p style=\"margin:0.0px 0.0px 0.0px 0.0px; padding:4.0px 4.0px 4.0px 4.0px\"><span style=\"height:11.0px\"><font face=\"Helvetica Neue\"><font size=\"2\"><font color=\"#000000\"><font style=\"font: 10.0px 'Helvetica Neue'; font-kerning: none; font-variant-ligatures: common-ligatures; color: #000000; -webkit-text-stroke: 0px #ffffff\">Age (years)</font></font></font></font></span></p>\n\t\t\t</td>\n\t\t\t<td style=\"width:91.0px; border-style:solid; border-width:1.0px 1.0px 1.0px 1.0px; border-color:#000000 #000000 #000000 #000000\">\n\t\t\t<p style=\"margin:0.0px 0.0px 0.0px 0.0px; padding:4.0px 4.0px 4.0px 4.0px\"><span style=\"height:11.0px\"><font face=\"Helvetica Neue\"><font size=\"2\"><font color=\"#000000\"><font style=\"font: 10.0px 'Helvetica Neue'; font-kerning: none; font-variant-ligatures: common-ligatures; color: #000000; -webkit-text-stroke: 0px #ffffff\">Concurrent Credits</font></font></font></font></span></p>\n\t\t\t</td>\n\t\t\t<td style=\"width:86.0px; border-style:solid; border-width:1.0px 1.0px 1.0px 1.0px; border-color:#000000 #000000 #000000 #000000\">\n\t\t\t<p style=\"margin:0.0px 0.0px 0.0px 0.0px; padding:4.0px 4.0px 4.0px 4.0px\"><span style=\"height:11.0px\"><font face=\"Helvetica Neue\"><font size=\"2\"><font color=\"#000000\"><font style=\"font: 10.0px 'Helvetica Neue'; font-kerning: none; font-variant-ligatures: common-ligatures; color: #000000; -webkit-text-stroke: 0px #ffffff\">Type of apartment</font></font></font></font></span></p>\n\t\t\t</td>\n\t\t\t<td style=\"width:122.0px; border-style:solid; border-width:1.0px 1.0px 1.0px 1.0px; border-color:#000000 #000000 #000000 #000000\">\n\t\t\t<p style=\"margin:0.0px 0.0px 0.0px 0.0px; padding:4.0px 4.0px 4.0px 4.0px\"><span style=\"height:11.0px\"><font face=\"Helvetica Neue\"><font size=\"2\"><font color=\"#000000\"><font style=\"font: 10.0px 'Helvetica Neue'; font-kerning: none; font-variant-ligatures: common-ligatures; color: #000000; -webkit-text-stroke: 0px #ffffff\">No of Credits at this Bank</font></font></font></font></span></p>\n\t\t\t</td>\n\t\t\t<td style=\"width:55.0px; border-style:solid; border-width:1.0px 1.0px 1.0px 1.0px; border-color:#000000 #000000 #000000 #000000\">\n\t\t\t<p style=\"margin:0.0px 0.0px 0.0px 0.0px; padding:4.0px 4.0px 4.0px 4.0px\"><span style=\"height:11.0px\"><font face=\"Helvetica Neue\"><font size=\"2\"><font color=\"#000000\"><font style=\"font: 10.0px 'Helvetica Neue'; font-kerning: none; font-variant-ligatures: common-ligatures; color: #000000; -webkit-text-stroke: 0px #ffffff\">Occupation</font></font></font></font></span></p>\n\t\t\t</td>\n\t\t\t<td style=\"width:85.0px; border-style:solid; border-width:1.0px 1.0px 1.0px 1.0px; border-color:#000000 #000000 #000000 #000000\">\n\t\t\t<p style=\"margin:0.0px 0.0px 0.0px 0.0px; padding:4.0px 4.0px 4.0px 4.0px\"><span style=\"height:11.0px\"><font face=\"Helvetica Neue\"><font size=\"2\"><font color=\"#000000\"><font style=\"font: 10.0px 'Helvetica Neue'; font-kerning: none; font-variant-ligatures: common-ligatures; color: #000000; -webkit-text-stroke: 0px #ffffff\">No of dependents</font></font></font></font></span></p>\n\t\t\t</td>\n\t\t\t<td style=\"width:49.0px; border-style:solid; border-width:1.0px 1.0px 1.0px 1.0px; border-color:#000000 #000000 #000000 #000000\">\n\t\t\t<p style=\"margin:0.0px 0.0px 0.0px 0.0px; padding:4.0px 4.0px 4.0px 4.0px\"><span style=\"height:11.0px\"><font face=\"Helvetica Neue\"><font size=\"2\"><font color=\"#000000\"><font style=\"font: 10.0px 'Helvetica Neue'; font-kerning: none; font-variant-ligatures: common-ligatures; color: #000000; -webkit-text-stroke: 0px #ffffff\">Telephone</font></font></font></font></span></p>\n\t\t\t</td>\n\t\t\t<td style=\"width:73.0px; border-style:solid; border-width:1.0px 1.0px 1.0px 1.0px; border-color:#000000 #000000 #000000 #000000\">\n\t\t\t<p style=\"margin:0.0px 0.0px 0.0px 0.0px; padding:4.0px 4.0px 4.0px 4.0px\"><span style=\"height:11.0px\"><font face=\"Helvetica Neue\"><font size=\"2\"><font color=\"#000000\"><font style=\"font: 10.0px 'Helvetica Neue'; font-kerning: none; font-variant-ligatures: common-ligatures; color: #000000; -webkit-text-stroke: 0px #ffffff\">Foreign Worker</font></font></font></font></span></p>\n\t\t\t</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n<p>Objective:&nbsp;&nbsp;Minimization of Bank&#39;s Risk and Maximization of Bank&#39;s Profit</p>\n\n<p>Training Data: in the same format.</p>\n\n<p>Test Data:&nbsp;in the same format.</p>\n\n<p><strong>First Step: EDA (Exploratory Data Analysis) and Data Pre-processing</strong></p>\n\n<p>Observe:&nbsp;both categorical and continuous variables are included in the data set</p>\n\n<p>Classify data based on different parameters:</p>\n\n<p>E.g.&nbsp;</p>\n\n<table align=\"center\" border=\"1\" cellpadding=\"1\" cellspacing=\"1\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<th scope=\"row\">Account Balance</th>\n\t\t\t<td>No Account</td>\n\t\t\t<td>None</td>\n\t\t\t<td>Below 200 DM</td>\n\t\t\t<td>200 DM or Above</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n<p>&nbsp;</p>\n\n<p>Do we need to do cross-validation of all variables?</p>\n\n<p>Since most of the predictors are categorical with several levels, the full cross-classification of all variables will lead to zero observations in many cells. Hence we need to reduce the table size.</p>\n\n<p>After reducing the size, perform cross-validation <em>[How would you choose the categories that are likely to affect credibility/prediction]</em>:</p>\n\n<p>E.g.&nbsp;&nbsp;<span class=\"math\">\\text{Creditability} \\times \\text{Account.Balance}</span></p>\n\n<p><img alt=\"R output\" height=\"142\" src=\"https://online.stat.psu.edu/onlinecourses/sites/stat508/files/german_credit_Routput_01.png\" width=\"427\" /></p>\n\n<p>For contrinuous variables generate statistics&nbsp;</p>\n\n<table align=\"center\" border=\"1\" cellpadding=\"1\" cellspacing=\"1\">\n\t<thead>\n\t\t<tr>\n\t\t\t<th scope=\"row\">Predictors (Continuous)</th>\n\t\t\t<th scope=\"col\">Min</th>\n\t\t\t<th scope=\"col\">Q1</th>\n\t\t\t<th scope=\"col\">Median</th>\n\t\t\t<th scope=\"col\">Q3</th>\n\t\t\t<th scope=\"col\">Max</th>\n\t\t\t<th scope=\"col\">Mean</th>\n\t\t\t<th scope=\"col\">SD</th>\n\t\t</tr>\n\t</thead>\n\t<tbody>\n\t\t<tr>\n\t\t\t<th scope=\"row\">Duration of Credit (Month)</th>\n\t\t\t<td>4</td>\n\t\t\t<td>12</td>\n\t\t\t<td>18</td>\n\t\t\t<td>24</td>\n\t\t\t<td>72</td>\n\t\t\t<td>20.9</td>\n\t\t\t<td>12.06</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<th scope=\"row\">Amount of Credit (DM)</th>\n\t\t\t<td>250</td>\n\t\t\t<td>1366</td>\n\t\t\t<td>2320</td>\n\t\t\t<td>3972</td>\n\t\t\t<td>18420</td>\n\t\t\t<td>3271</td>\n\t\t\t<td>2822.75</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<th scope=\"row\">Age (of Applicant)</th>\n\t\t\t<td>19</td>\n\t\t\t<td>27</td>\n\t\t\t<td>33</td>\n\t\t\t<td>42</td>\n\t\t\t<td>75</td>\n\t\t\t<td>35.54</td>\n\t\t\t<td>11.35</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n<p>&nbsp;</p>\n\n<p>Also, for each continous variable plot distribution (frequency per histogram bin). Generate box-plot as well (will be helpful).</p>\n\n<p>Bivariate association of the response (Creditability) with the categorical predictors.</p>\n\n<p>Remember for Chi-Squared Test, we need to have following conditions satisfied:-</p>\n\n<ul>\n\t<li>The sample must be randomly selected.</li>\n\t<li>This test only works for&nbsp;<b>categorical</b>&nbsp;data (data in categories), such as Gender {Men, Women} or colour {Red, Yellow, Green, Blue} etc, but&nbsp;<b>not numerical</b>&nbsp;data such as height or weight.</li>\n\t<li>The numbers (expected values) must be large enough. Each entry must be&nbsp;<b>5</b>&nbsp;or more.&nbsp;</li>\n</ul>\n\n<p>And, Chi-Squared tests can be used for <a href=\"https://www.khanacademy.org/math/ap-statistics/chi-square-tests/chi-square-tests-two-way-tables/v/chi-square-test-homogeneity\" target=\"_blank\">testing homogeneity (e.g. do different categories have same preference of ...), association (independence)</a></p>\n\n<p>So, in our case we can apply this test to find p-value. Our hypotheses are: 1. H0: It doesn&#39;t matter,&nbsp;2. H1: That a given predictor influences creditability</p>\n\n<p>To calcualte p-value using Chi-Squared Test, first write data in a table format&nbsp;</p>\n\n<p>&nbsp;</p>\n\n<table align=\"center\" border=\"1\" cellpadding=\"1\" cellspacing=\"1\">\n\t<tbody>\n\t\t<tr>\n\t\t\t<th scope=\"row\">&nbsp; Account Balance&nbsp;&rarr;&nbsp;</th>\n\t\t\t<td>&nbsp; No Account&nbsp;&nbsp;</td>\n\t\t\t<td>&nbsp; None&nbsp;&nbsp;</td>\n\t\t\t<td>&nbsp; Below 200 DM&nbsp;&nbsp;</td>\n\t\t\t<td>&nbsp; &nbsp;200 DM or Above&nbsp;&nbsp;</td>\n\t\t\t<td>&nbsp; &nbsp;Row Sum&nbsp;&darr; &nbsp;</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<th scope=\"row\">Creditable&nbsp;&nbsp;</th>\n\t\t\t<td>&nbsp; &nbsp; &nbsp; &nbsp;Avg=(x*y)/N</td>\n\t\t\t<td>&nbsp; &nbsp;</td>\n\t\t\t<td>&nbsp; &nbsp;&nbsp;</td>\n\t\t\t<td>&nbsp; &nbsp;&nbsp;</td>\n\t\t\t<td>&nbsp; &nbsp; &nbsp;y</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<th scope=\"row\">&nbsp; Not-Creditable&nbsp;&nbsp;</th>\n\t\t\t<td>&nbsp; &nbsp;&nbsp;</td>\n\t\t\t<td>&nbsp; &nbsp;</td>\n\t\t\t<td>&nbsp;</td>\n\t\t\t<td>&nbsp;</td>\n\t\t\t<td>&nbsp;</td>\n\t\t</tr>\n\t\t<tr>\n\t\t\t<th scope=\"row\">Column-Sum&nbsp;&nbsp;&rarr;</th>\n\t\t\t<td>&nbsp; &nbsp; x</td>\n\t\t\t<td>&nbsp; &nbsp;</td>\n\t\t\t<td>&nbsp;</td>\n\t\t\t<td>&nbsp;</td>\n\t\t\t<td>&nbsp; &nbsp; N</td>\n\t\t</tr>\n\t</tbody>\n</table>\n\n<p>We are expecting independence, hence we multiply the frequencies to get Expected Values.&nbsp;</p>\n\n<p>After that we substract the Observed/Actual values correspondingly in each cell, and take the square of difference and divide by Expected value.&nbsp;&nbsp;<span class=\"math\">\\frac{ (\\text{Expected Avg} - \\text{Observed})^2 }{\\text{Expected}}</span></p>\n\n<p>To calculate p-value from chi-squared value, we need &quot;Degrees of Freedom&quot; (D.F) = (#rows-1)x(#columns-1)</p>\n\n<p>There&#39;s direct formula for calculating p-value from Chi-squared value and D.F.&nbsp;</p>\n\n<p>We reject the null hypothesis (which means that variables are not independent)&nbsp;if p-value comes out to be less than significance level <span class=\"math\">\\alpha</span>. Else we can&#39;t say that whether they are dependent or not. We have to look further.</p>\n\n<p>For Continuous Values we find P-Values using T-Test or Wald-Test.</p>\n\n<p>&nbsp;</p>\n\n<p>&nbsp;</p>\n\n<p>&nbsp;</p>\n\n<p>&nbsp;</p>\n<style type=\"text/css\">table td {\n    padding: 5px;\n }\n</style>\n","authorId":null,"subject":"ai","tags":[""],"img":null,"summary":"","lastUpdated":"2020-06-13T11:25:43.330+0000"}