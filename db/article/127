{"name": "Messaging Systems", "id": 127, "content": "<h2>Objective</h2>\n\n<p>To give short but complete overview of systems/tools/frameworks used to facilitate asynchronous messaging among applications (running on different servers). There are 2+ ways in Java:</p>\n\n<ol>\n\t<li>JMS&nbsp;</li>\n\t<li>Kafka</li>\n</ol>\n\n<p><span style=\"color:#8e44ad;\"><em>The fundamental requirement is that I should be able to place my message somewhere, and hope that someone else would pick the message and take action (and maybe place a message for me). You would definitely want to have control over who can pick the message. Things get more complicated when we use a distriibuted system for this, the load of messages is high.</em></span></p>\n\n<p>Java Messaging Service (JMS) is an API provided by standard Java. Note that it is just an API, not the implementation. It is just a contract. The actual work described by this API is done by implementation libraries from JMS Providers (a.k.a <b>Message-oriented middleware</b>&nbsp;(<b>MOM</b>)).</p>\n\n<p>There are many implementation libraries e.g. <strong>ActiveMQ</strong>, RabbitMQ, WebsphereMQ, OracleAQ etc.</p>\n\n<p><strong>What is JMS?</strong></p>\n\n<p>JMS is a specification. Different MOM products implement this specification. You do not directly use MOM products in your application, instead, connect using JMS. Otherwise, you will have a hard time replacing the library you have used in your project,&nbsp;in favor of more efficient library in the future.</p>\n\n<p><strong>What JMS is Not?</strong></p>\n\n<div style=\"background:#eeeeee;border:1px solid #cccccc;padding:5px 10px;\"><br />\nJMS does not specify a distributed version of the Java event model.<br />\n<br />\nJMS is not <strong>intelligent</strong>. Publishers do not get to know whether there is any subscriber or not, which would have been helpful so that publisher publishes only if there is any subscriber. Some MOM products might have this feature, but it&#39;s not part of JMS.<br />\n<br />\nJMS does not specify the protocol for <strong>secure</strong> access and <strong>message format</strong>.<br />\n<br />\nJMS is <strong>almost-real-time</strong> enough for general purpose requirements.<br />\n&nbsp;</div>\n\n<p>&nbsp;</p>\n\n<p>What to strive for while implementing/using a messaging system:</p>\n\n<p>Prevent (in production)&hellip;. message loss on failure, distribution of messages among consumers not working the way you had expected, or brokers &ldquo;hanging&rdquo; your producers or not distributing messages to your consumers.</p>\n\n<h2><br />\nBut Why Do We Need This?</h2>\n\n<p>When two applications want to communicate, and they cannot talk directly (might be because they are built on different technology stacks, or because they are not authorized to talk directly, in other words, you do not have access to their API either using JAR or using REST endpoints), MOM acts as a middleman. MOM (Message Oriented Middleware) may act as an intelligent router.</p>\n\n<p>This communication can be in Point-To-Point (one-to-one and many-to-one) or Publish-Subscribe style (many-to-many).</p>\n\n<p><img alt=\"\" src=\"/images/jms_queue_topic.png\" style=\"width: 600px; height: 408px;\" /></p>\n\n<p><strong>What do we mean by Point-To-Point?</strong></p>\n\n<p>&quot;<em>I want to send this message only to a particular queue (receiver) through MOM</em>&quot;. - This is Point-to-point.</p>\n\n<p><strong>What do we mean by Publish-Subscribe?</strong></p>\n\n<p>&quot;<em>I want to send the message to everybody who is interested in receiving it through MOM</em>&quot; - This is Pub-Sub.</p>\n\n<p>Any application can act as producer (which creates a message and puts it on the queue or topic), and any application can act as Consumer (who listens to the incoming messages). Instead of saying Application-x we generally say Client-x because the client could be anything a standalone application, or a microservice, or a simple java program.</p>\n\n<h2>Concepts</h2>\n\n<p><strong>Messag</strong><strong>e Queues</strong>: are a collection of messages on MQ Servers or MOMs. Mostly FIFO based queue. There can be multiple consumers attached to a queue waiting for a message. When the message arrives on queue, the queue delivers it to <strong>one (and only one)</strong> of the consumers attached, and the&nbsp;message is then removed from the&nbsp;queue. The message itself contains the information about the destination queue.</p>\n\n<p>In the case of Publish-Subscriber setup, the message will be delivered to multiple consumers attached to the Topic. <strong>There is no guarantee of the order in which messages are delivered.&nbsp;</strong></p>\n\n<p>Virtual Topics:</p>\n\n<p>VTs come into picture because of the limitations of the Topic. Topics can be made durable &mdash; I, as a subscriber to a Topic, can say that I want to receive all the messages while I was gone. But then the broker needs to be able to identify me, so I&#39;ll provide a ClientID. But the JMS specification mandates that I can give only one ClientID. So, I cannot run multiple threads to consume a lot of messages. I cannot have someone take my place while consuming messages in case I breakdown.</p>\n\n<p>So, ActiveMQ gives VirtualTopics, using which consumers and producers can use the Topic semantics from JMS, but the VirtualTopics will actually be implemented using Queues.</p>\n\n<p>E.g., let&rsquo;s say we have a topic called&nbsp;<strong>VirtualTopic.Orders</strong>.&nbsp;&nbsp;And we logically want to send orders to systems A and B. Now with regular durable topics we&rsquo;d create a JMS consumer for clientID_A and &ldquo;A&rdquo; along with clientID_B and &ldquo;B&rdquo;.</p>\n\n<p>With virtual topics we can just go right ahead and consume to queue&nbsp;<strong>Consumer.A.VirtualTopic.Orders</strong>&nbsp;to be a consumer for system A or consume to&nbsp;<strong>Consumer.B.VirtualTopic.Orders</strong>&nbsp;to be a consumer for system B.</p>\n\n<h2><strong>What is a Broker?</strong></h2>\n\n<p>The Broker is a service on the network or&nbsp;<a href=\"http://activemq.apache.org/how-do-i-embed-a-broker-inside-a-connection.html\" shape=\"rect\">embedded in the same JVM</a>&nbsp;which provides the message provider. So think of the ConnectionFactory as the client API for sending and receiving messages and the broker is a server-side implementation.</p>\n\n<p>JMS does not allow multiple receivers in P2P style, it will throw the exception <span style=\"color:#c0392b;\"><em>&quot;JMSException: Unable to create a receiver for the queue as it is already in use. Please close this object and try again.&quot;</em></span></p>\n\n<ul>\n\t<li>The session object acts a factory for creating message producers and message consumers.</li>\n\t<li>The session object also acts as a factory for creating messages.</li>\n\t<li>The session object defines a serial order for the messages it consumes and produces.</li>\n\t<li>The session object retains messages it consumes until they have been acknowledged.</li>\n\t<li>The session object serializes execution of message listeners registered with it.</li>\n\t<li>The session object supports a single series of transactions that combine work spanning that session&rsquo;s producers and consumers into atomic units that can either be committed or rolled back.</li>\n</ul>\n\n<h3><strong>What happens if Consumer is sleeping/down/not-listening while Producer sends a message?</strong></h3>\n\n<p>It depends on what kind of subscription the Consumer has taken. If it is <strong><em>durable</em></strong>&nbsp;then all the messages missed by Consumer will be delivered to it when Consumer&nbsp;becomes active again, otherwise, those messages will be lost.</p>\n\n<h3><strong>What happens if the Broker crashes or restarts?</strong></h3>\n\n<p>JMS specifies 2 types of delivery modes for messages:&nbsp;<em><strong>persistent</strong></em> and <em><strong>non-persistent</strong>.</em>&nbsp;JMS specification mandates that a provider must deliver a non-persistent message zero or one time at most <strong><em>(at-most-once)</em></strong>.</p>\n\n<p><span style=\"color:#8e44ad;\"><span style=\"font-size:12px;\">Durability is often confused with&nbsp;<i>persistence</i>, and while the two terms come across as interchangeable, they serve different functions. Persistence determines whether a messaging system writes the message to some form of storage between receiving and dispatching it to a consumer. Messages sent to a queue may or may not be persistent.</span></span></p>\n\n<p>The JMS specification mandates that a provider must deliver a persistent message <strong><em>once&minus;and&minus;only&minus;once*</em>.</strong>&nbsp;</p>\n\n<p>Persistence != Reliability:&nbsp;<strong>Retention</strong> of a message at the destination until its receipt is acknowledged is not guaranteed by a persistent delivery mode, instead it is an administrative setting.</p>\n\n<p>Persistence comes at a cost &mdash; a big cost. Writing to disk instead of just memory/cache costs in ratio 100(0):1 in time. By default JMS (and ActiveMQ) defaults to favour persistence.</p>\n\n<p>Storage engine for messages in AMQ is pluggable.</p>\n\n<p>Messages (their consumption info) are logged into a &ldquo;journal&rdquo; (append-only data structure comprising of multiple files). When all the messages in a journal are consumed, the journal can be deleted/archived. But, remember even a single unconsumed message will prevent it from deletion. <i>[Classical message brokers are not intended as a long-term storage mechanism&mdash;consume your messages!</i>] AMQ also maintains an index for the journal.</p>\n\n<p>Disk performance affects the performance of brokers, and it&rsquo;s not just about tuning the broker, it&rsquo;s also about how the producers interact with the broker. The factors are: Latency (max time for single operation such as &lsquo;write&rsquo; to complete), Bandwidth (how many operations can go together - filesystem caches may club a bunch of small writes into smaller set of larger ones), IOPS (carrying capacity over time).</p>\n\n<p>Persistence setting is <em>per-message</em>.</p>\n\n<p>What if Broker can&rsquo;t accept a message (maybe because of memory limit) &mdash; brokers can be configured to either hold the acknowledgement, or reject the message.</p>\n\n<p><strong><i>Why&nbsp; do we need an ACK for message persistence?</i></strong></p>\n\n<p>With the FileSystem based storage, the message(s) go through Broker cache &rarr; FS Buffer Cache &rarr; H/W level <i>disk drive controller cache </i>&rarr; <i>Disk caches. </i>The flow can be broken at any point in this flow. Broker calls java.io.FileDescriptor.sync() to ensure that message has reached the disk. This operation is very crucial in determining the performance.</p>\n\n<p>Broker threads which receive the message to be persisted also contend with each other (queue up) to avoid write conflict to journal. This adds delay. ActiveMQ uses a buffer to maximise the use of storage bandwidth, broker threads write to the buffer, and ActiveMQ flushes buffer at some time and notifies the threads.</p>\n\n<p>An optimization is to assign set of queues to their own journals through the use of the mKahaDB adapter. But using multiple journals can make the transactions more complicated if a transactional operations involve multiple journals, as extra coordination would then be required.</p>\n\n<p>On consumption side, ActiveMQ,&nbsp; when it becomes aware of consumer, pages messages from storage into memory for distribution. [Storage -&gt; Cursor ( a cache) -&gt; Consumer] The message goes to the <i>prefetch buffer</i>. Application code at some point consumes this, and ACK of consumption is sent to the broker.</p>\n\n<p>ACK modes: AUTO_ACKNOWLEDGE, CLIENT_ACKNOWLEDGE, DUPS_OK_ACKNOWLEDGE</p>\n\n<p>Acknowledgement modes are supplemented by a transactional consumption facility. When a&nbsp;Session&nbsp;is created, it may be flagged as being transacted. This means that it is up to the programmer to explicitly call&nbsp;Session.commit()&nbsp;or&nbsp;Session.rollback(). On the consumption side, transactions expand the range of interactions that the code can perform as a single atomic operation. For example, it is possible to consume and process multiple messages as a single unit, or to consume a message from one queue and then send to another queue using the same&nbsp;Session.</p>\n\n<p>In case of multiple consumers: the default behavior of the broker is to dispatch messages in a round-robin fashion to consumers that have space in their prefetch buffers. When a consumer shuts down unexpectedly, any messages that had been dispatched to it but had not yet been acknowledged will be re-dispatched to another available consumer.</p>\n\n<p>This raises an important point: even where consumer transactions are being used, there is no guarantee that a message will not be processed multiple times.</p>\n\n<p><i>There&nbsp;is no such thing as&nbsp;</i><a href=\"http://bravenewgeek.com/you-cannot-have-exactly-once-delivery/\"><i>exactly-once message delivery</i></a><i>. </i>Queues provide an&nbsp;<i>at-least-once</i>&nbsp;delivery guarantee, and sensitive pieces of code should always consider the possibility of receiving duplicate messages.&nbsp;</p>\n\n<h2><strong>Transactions and Redelivery</strong></h2>\n\n<p>If a failure occurs while execution of message receiver code, then the message is automatically redelivered.</p>\n\n<p>When calling&nbsp;<code>connection.createSession(false, Session.AUTO_ACKNOWLEDGE);</code>&nbsp;you have other options in place of&nbsp;<code>Session.AUTO_ACKNOWLEDGE</code>&nbsp;</p>\n\n<p><code>(1) Session.DUPS_OK_ACKNOWLEDGE</code> just like&nbsp;<code>Session.AUTO_ACKNOWLEDGE</code>&nbsp;but duplicates allowed (which happens in rare scenarios). <strong>Gives more throughput</strong>.</p>\n\n<p>(2)&nbsp; <code>Session.CLIENT_ACKNOWLEDGE</code>: in this mode client (message reciever ) has to acknowledge that it has received the message by calling <code>acknowledge()</code> on the <code>Message</code>. Once the client&nbsp;acknowledges a particular message acknowledges all prior messages the session receives. <strong>Adds code complexity</strong>.</p>\n\n<p><strong>What happens to messages that are in the session but never acknowledged?</strong></p>\n\n<p>The messages remain at the destination until they expire or forever if they lack an expiration date. Message redelivery is not automatic, but messages are redelivered under certain circumstances:-</p>\n\n<p>(1) Calling the&nbsp;<code>Session</code>&nbsp;class&#39;s&nbsp;<code>recover()</code>&nbsp;method recovers the session. Invoking the&nbsp;<code>recover()</code>&nbsp;method causes the redelivery of all unacknowledged messages</p>\n\n<p>(2) The receiving application (client) restarts, causing the session to restart. Restarting the session causes all unacknowledged messages to be redelivered.</p>\n\n<p><br />\nTo create transactional sessions: Use&nbsp;<code>connection.createSession(true)</code>&nbsp;</p>\n\n<p>The client (receiver application) creates transacted session, calls <code>commit()</code>&nbsp;when message processing has been successful, otherwise calls <code>rollback()</code>.&nbsp;</p>\n\n<p><strong>What happens to the rolled-back messages?&nbsp;</strong></p>\n\n<p>The JMS provider automatically redelivers these messages so the application can reprocess them. We can customize how this redlivery logic in case of transaction rollback is handled.</p>\n\n<ul>\n\t<li><em>Redelivery count</em>: The number of times to redeliver a message. You do not want to crash&nbsp;the system by allowing infinite redeliveries.</li>\n\t<li><em>Exception destination</em>: What happens to a message that is redelivered redelivery-count times? The JMS provider can do any of the following:\n\t<ul>\n\t\t<li>Log the message</li>\n\t\t<li>Forward the message to an exception or error destination</li>\n\t\t<li>Lose the message</li>\n\t</ul>\n\t</li>\n\t<li><em>Time to redeliver</em>: An application that has just rolled back messages might not be ready to reprocess the same messages. This parameter specifies the time to wait before redelivering the message. This delay lets the JMS provider and the application recover to a stable state.</li>\n</ul>\n\n<p>The redelivered messages maintain its original timestamp. So when they get back to the queue for redelivery, they go to the front of the queue (by default strategy of time-based delivery).</p>\n\n<h2>Ordering of Messages</h2>\n\n<p>The requirement for messages that were sent by the same sender to be processed in order relative to each other, also known as&nbsp;<i>causal ordering</i>&nbsp;is quite common. But this functionality is not available by default.</p>\n\n<p>The&nbsp;<i>exclusive consumer</i>&nbsp;model involves dispatching all messages from a queue to a single consumer. Using this approach, when multiple application instances or threads connect to a queue, they subscribe with a specific destination option:&nbsp;my.queue?consumer.exclusive=true. When an exclusive consumer is connected, it receives all of the messages. When a second consumer connects, it receives no messages until the first one disconnects. This second consumer is effectively a warm-standby, while the first consumer will now receive messages in the exact same order as they were written to the journal&mdash;in causal order.</p>\n\n<p>But the order requirement, typically, is not on a global basis. So, instead of sending all messages to a single consumer, we can partition the distribution based on some ID set to JMSXGroupID, (<i>JMS message groups</i>)&nbsp; ActiveMQ will make sure that al messages having same JMSXGroupID are dispatched to the same consumer.</p>\n\n<p>If a consumer fails, then any groups assigned to it will be reallocated between the remaining consumers, and any unacknowledged messages will be re-dispatched accordingly. <i>So while we can guarantee that all related messages will be processed in order, we cannot say that they will be processed by the same consumer.</i></p>\n\n<h2>&nbsp;</h2>\n\n<h2>Handling Duplicate Message Consumption</h2>\n\n<p>Apache Camel provides in-built idempotent processing of messages.</p>\n\n<p>&nbsp;</p>\n\n<h2>Scaling</h2>\n\n<p><strong>Okay, so you have configured redelivery model, and now have a loosely coupled system of Producer application(s) and Consumer application(s). But what if the MOM broker itself goes down?</strong></p>\n\n<p>ActiveMQ (and other MOMs) supports broker clustering. So even if one broker goes down, others can take up the task of redelivering the message. ActiveMQ supports it by Master-Slave configuration and Replicated-Message-Stores configuration.</p>\n\n<p>For detail visit:&nbsp;<a href=\"http://activemq.apache.org/clustering.html\" target=\"_blank\">http://activemq.apache.org/clustering.html</a></p>\n\n<p>Note: It&rsquo;s not necessary to use only one AMQ setup for communication among all the apps. Identify and use dedicated AMQs for logically grouped apps. Or, use Kafka.</p>\n\n<p>&nbsp;</p>\n\n<hr />\n<h2>What about Kafka?</h2>\n\n<p>Unlike traditional messaging brokers, Kafka is not broker-centric, and instead is client-centric. Clients take away a lot of broker&rsquo;s responsibilities.</p>\n\n<p>Kafka unified both publish-subscribe and point-to-point messaging under a single destination type&mdash;the&nbsp;<i>topic</i>. This is confusing for people coming from a messaging background where the word topic refers to a broadcast mechanism from which consumption is nondurable, Kafka topics should be considered a hybrid destination type.</p>\n\n<p><i>Each&nbsp;topic in Kafka has its own journal ( not a term used in Kafka docs).</i></p>\n\n<p>Kafka removes the oldest part of the journal irrespective of whether the message has been received by consumer or not. This responsibility goes to the clients.</p>\n\n<p>A Kafka journal is composed of multiple partitions (each implemented as a rolling log file). Kafka provides strict ordering guarantee in each partition, but not among the partitions (on a global level).</p>\n\n<ul>\n\t<li>A topic has multiple partitions</li>\n\t<li>Many consumer groups can consume from a topic at the same time</li>\n\t<li>A consumer group can have many separate instances</li>\n</ul>\n\n<p>The consumer group, referenced in the API through a user-defined&nbsp;group_id, corresponds to a&nbsp;<i>single logical consumer or system</i>. Many consumers can use same group_id, but the latest connected one will receive all the messages fro that point onwards (much like <i>Exclusive consumer</i> above). One consumer can read from multiple partitions (using the same <i>group_id</i>).</p>\n\n<p>A better word for &ldquo;Consumers&rdquo; in Kafka could be &ldquo;Auditors&rdquo;/&ldquo;Browsers&rdquo;, because the message is never actually consumed (up), it is just read and acknowledged.</p>\n\n<p><i>How to allow multiple parallel consumers for a consumer group?</i></p>\n\n<p>Kafka-esque solution is to use more partitions. In order to enable parallel processing of messages in parallel from 20 threads, you would therefore need a&nbsp;<i>minimum</i>&nbsp;of 20 partitions. Any fewer partitions, and you would be left with consumers that are not allocated anything to work on, as described in our exclusive-consumer discussion earlier.</p>\n\n<p><span style=\"color:#8e44ad;\"><strong><em>All that a Kafka broker has to do is sequentially feed messages to a consumer as the latter asks for them.</em></strong></span></p>\n\n<p>The responsibility for deciding which partition to send a message to is assigned to the producer of that message.</p>\n\n<p>When a message is sent using the Kafka Producer API, it is handed to a partitioning function that, given the message and the current state of the Kafka cluster, returns a partition ID to which the message should be sent. This function is implemented through the&nbsp;Partitioner&nbsp;interface in Java.</p>\n\n<p>The default implementation of the Partitioner uses a general-purpose hashing algorithm over the key, or round-robin if no key is provided, to determine the partition.</p>\n\n<p>If you use a JSON message as Key, then you&rsquo;d have to write custom implementation of Partitioner to produce key by parsing the JSON message.</p>\n\n<p>Kafka includes checksums to detect corruption of messages in storage and has a comprehensive set of security features.</p>\n\n<p>The number of partitions in a topic can change over time, as they can be added to if the traffic goes beyond what was initially expected. As such, message keys may need to be associated with the partition that they were initially sent to, implying a piece of state that needs to be shared across producer instances.</p>\n\n<p>Another factor to consider is the evenness of the distribution of messages among partitions. Typically, keys are not evenly distributed across messages, and hash functions are not guaranteed to distribute messages fairly for a small set of keys.</p>\n\n<p>It is important to note that however you decide to partition the messages, the partitioner itself may need to be reused.</p>\n\n<p>Consider the requirement to replicate data between Kafka clusters in different geographical locations. Kafka comes with a standalone command-line tool called MirrorMaker for this purpose, used to consume messages from one cluster and produce them into another.</p>\n\n<p>MirrorMaker needs to understand the keys of the topic being replicated in order to maintain relative ordering between messages as it replicates between clusters, as the number of partitions for that topic may not be the same in the two clusters.</p>\n\n<p>Producer&rsquo;s send() : What happens is that the message (ProducerRecord) is written into a send buffer for each active partition and transmitted on to the broker by a background thread within the Kafka client library. While this makes the operation incredibly fast, it does mean that a naively written application could lose messages if its process goes down.</p>\n\n<p>To avoid that, you can choose reliability at the cost of performance. The size of this buffer can be tuned to be 0, and the sending application thread can be forced to wait until the transmission of the message to the broker has been completed (use .get() on returned Future).</p>\n\n<p>In Kafka, there are two ways to commit the offset: automatically, and manually. In both cases, you may process the messages multiple times if you have processed the message but failed before commiting. You may also not process the message at all if the commit happened in the background and your code terminated before it got around to processing (a possibility in Kafka 0.9 and earlier).</p>\n\n<p>Controlling the offset commit process manually is enabled in the Kafka consumer API by setting the&nbsp;enable.auto.commit&nbsp;to&nbsp;false, and calling one of the following methods explicitly:</p>\n\n<pre>\n<code class=\"language-java\">void commitSync();\n\nvoid commitAsync();</code></pre>\n\n<p>If you care about at-least-once processing, you would commit the offset manually via&nbsp;commitSync(), executed immediately after your processing of messages.</p>\n\n<p>These methods prevent messages from being acknowledged before being processed, but do nothing to address the potential for duplicate processing, while at the same time giving the impression of transactionality. Kafka is nontransactional.&nbsp;</p>\n\n<p>&nbsp;</p>\n\n<p><b><i>So if we cannot rely on transactions, how do we ensure semantics closer to those provided by a traditional messaging system?</i></b></p>\n\n<p>If there is a possibility that the consumer&rsquo;s offset is incremented before the message has been processed, such as during a consumer crash, then there is no way for a consumer to know if its consumer group has missed messages when it is assigned a partition. As such, one strategy is to rewind the offset to a previous position. The Kafka Consumer API provides the following methods to enable this:</p>\n\n<p><i>void seek(TopicPartition partition, long offset);</i></p>\n\n<p><i>void seekToBeginning(Collection&lt;TopicPartition&gt; partitions);</i></p>\n\n<p>The&nbsp;<i>seek()</i>&nbsp;method can be used with the&nbsp;offsetsForTimes (Map&lt;TopicPartition,Long&gt; timestampsToSearch)&nbsp;method to rewind to a state at some specific point in the past.</p>\n\n<p>Implicitly, using this approach means that it is highly likely that some messages that were previously processed will be consumed and processed all over again.&nbsp;</p>\n\n<p>Kafka cluster - Brokers are connected to a cluster of&nbsp;<a href=\"http://zookeeper.apache.org/\">ZooKeeper</a>&nbsp;servers which acts as a registry of configuration information and is used to coordinate the roles of each broker. ZooKeeper is itself a distributed system, that provides high availability through replication of information in a&nbsp;<i>quorum</i>&nbsp;setup.</p>\n\n<p>At runtime,&nbsp;<i>for each topic partition</i>, the Controller assigns the roles of a&nbsp;<i>leader</i>&nbsp;(master) and&nbsp;<i>followers</i>&nbsp;(slaves) to the brokers. The broker acting as leader for a given&nbsp;partition is responsible for accepting all messages sent to it by producers, and distributing messages to consumers. As messages are sent into a topic partition, they are replicated to all broker nodes acting as followers for that partition. Each node that contains the logs for the partition is refered to as a&nbsp;<i>replica</i>. A broker may act as a leader for some partitions and as a follower for others.</p>\n\n<p>Part of the producer&rsquo;s configuration is an&nbsp;acks&nbsp;setting, which will dictate how long many replicas must acknowledge receipt of the message before the application thread continues when it is sent:&nbsp;0,&nbsp;1, or&nbsp;all. If set to&nbsp;all, on receipt of a message, the leader will send confirmation back to the producer once it has received acknowledgements of the write from a number of replicas (including itself), defined by the topic&rsquo;s&nbsp;min.insync.replicas&nbsp;setting (1&nbsp;by default). If a message cannot be successfully replicated, then the producer will raise an exception to the application (NotEnoughReplicas&nbsp;or&nbsp;NotEnoughReplicasAfterAppend). Replication happens to followers in parallel.</p>\n\n<p>Using this replication scheme, Kafka avoids the call to sync() for every message, which saves a lot of time. Kafka can also be configured to&nbsp;sync()&nbsp;batches of messages.&nbsp;</p>\n\n<p>Kafka allows you to configure retention policy for deciding when the topic should be purged.</p>\n\n<p>&nbsp;</p>\n\n<p><b>Dealing with Failures</b></p>\n\n<p>When producing messages, the primary failure that needs to be considered is a broker outage. Client libraries usually provide logic around reconnection and resending of unacknowledged messages in the event that the broker becomes unavailable.</p>\n\n<p>Reconnection involves cycling through the set of known addresses for a broker, with delays in-between. The exact details vary between client libraries. Note that the thread will be blocked during this time. This can result into &ldquo;HTTP 503 Service Unavailable.&rdquo; In extreme cases, when all threads of web-server are blocked. Circuit-Breaker pattern can handle this gracefully.</p>\n\n<p>Asynchronous sends, such as those performed by Kafka, are not in themselves a workaround for this issue. An asynchronous send will involve messages being placed into a finite in-memory buffer that is periodically sent by a background thread to the broker. In the case of Kafka&rsquo;s client library, if this buffer becomes full before the client is able to reconnect, then any subsequent sends will be blocked (i.e., become synchronous). At this time the application thread will wait for some period until eventually the operation is abandoned and a&nbsp;TimeoutException&nbsp;is thrown. At best, asynchronous sends will delay the exhaustion of an application&rsquo;s thread pool.</p>\n\n<p>Failures during consumption:</p>\n\n<p>Permanent Failure: JMS-based MQs guarantee redelivery JMS-based message brokers provide a redelivery mechanism that is used with transactions. Here, messages are redispatched for processing by the consumer when an exception is thrown. When messages are redelivered, the broker keeps track of this by updating two message headers: JMSRedelivered, JMSXDeliveryCount</p>\n\n<p>Once the delivery count exceeds a preconfigured threshold, the message is sent to a&nbsp;<i>dead-letter queue</i>&nbsp;or DLQ. DLQs have a tendency to be used as a dumping ground in most message-based systems and are rarely given much thought. If left unconsumed, these queues can prevent the cleanup of journals and ultimately cause brokers to run out of disk space. they should be drained to either a log file or some form of database for periodic inspection.</p>\n\n<p>Kafka provides no mechanism for transactional consumption and therefore no built-in mechanism for message redelivery on error. It is the responsibility of your client code to provide redelivery logic and send messages to dead-letter topics if needed.</p>\n\n<p>Temporary failures in message consumption fall into one of two&nbsp;categories:</p>\n\n<p>Global: Affecting all messages. This includes situations such as a consumer&rsquo;s backend system being unavailable.</p>\n\n<p>Local: The current message cannot be processed, but other messages on the queue can. An example of this is a database record relating to a message being locked and therefore temporarily not being updateable.</p>\n\n<p>Kafka is moving away from ZooKeeper.</p>\n\n<hr />\n<h2>Is usisng a messaging system worth it?</h2>\n\n<p>Read this:</p>\n\n<p><a href=\"https://www.programmableweb.com/news/why-messaging-queues-suck/analysis/2017/02/13\" target=\"_blank\">https://www.programmableweb.com/news/why-messaging-queues-suck/analysis/2017/02/13</a></p>\n\n<p>Summary of the linked article:</p>\n\n<p>This is what happens in Pub-Sub model. There&#39;s a TOPIC to which many queues subscribe. When a service pushes a Message to the topic, the topic sends a copy to each of the queues and then flushes the Message. Consuming services listen to the queues, and consume the message from the queue.</p>\n\n<p>The benefit is that &quot;publisher of the message knows nothing about consumers of the message, the system is decoupled&quot;. <strong><em>Is that so?</em></strong>&nbsp;You&rsquo;re not going to let just anybody subscribe to a topic. You would be checking some permissions, onboard the subscribers. What if you develop a mechanism of registering the interested consumers directly to the producer service? If you are in a cloud-based&nbsp;environment like AWS, it could save you much cost (you will save the cost incurred by message sitting there in the topic until every consumer picks up a copy).</p>\n\n<p>The thing is that the knowledge of consumers, their list, is pushed to another component <em>Topic</em>. But ultimately you own the topic and you are responsible for granting access to it.&nbsp;</p>\n\n<p>So, where are the queues useful? - On the consumer side, it will allow parallel processing, throttling etc. The cost of storing a message is now pushed to the consumers. But be careful with it, as now you have to send a copy of the message to everyone interested by yourself. (The cost associated with it will probably be cancelled out by the cost incurred by making sure that the consumer is valid (security)).&nbsp;<br />\nAlso, be careful as not to reinvent the wheel by creating your own topic implementation. (Like when you start implementing the requirements like guaranteed delivery (what if a consumer is down), retry logic (what if a consumer is slow), backpressure), fault tolerance (keeping a fast-changing service highly available is more difficult than keeping a dedicated broker up).&nbsp;</p>\n\n<p>And you really need to calculate how much cost you actually save.</p>\n\n<p>&nbsp;</p>\n\n<p>Code:</p>\n\n<h2>How to use JMS API?</h2>\n\n<p style=\"margin-left: 160px;\"><img alt=\"\" src=\"/images/jms_api.png\" style=\"width: 500px; height: 291px;\" /></p>\n\n<p>This is the basic code structure for the basic flow of JMS. Using ActiveMQ implementation.&nbsp;</p>\n\n<p>(1) Get the <strong>ConnectionFactory</strong> object:</p>\n\n<ul>\n\t<li>Create one programmatically&nbsp;\n\t<pre>\n<code class=\"language-java\">String url = \u201ctcp://localhost:61616\u201d\nConnectionFactory factory = new ActiveMQConnectionFactory(url);</code></pre>\n\n\t<p>&nbsp;</p>\n\t</li>\n\t<li>Create one using Admin console of MOM provider / application-server, and then use JNDI to get it into your program/application.\n\t<pre>\n<code class=\"language-java\">InitialContext jndiContext = new InitialContext();\nConnectionFactory cf = jndiContext.lookup(connectionfactoryname);</code></pre>\n\n\t<p>&nbsp;</p>\n\t</li>\n</ul>\n\n<p>(2) Create Session using your ConnectionFactory: Session is basically program&#39;s view of Connection.</p>\n\n<pre>\n<code class=\"language-java\">//create a connection\nConnection connection = cf.createConnection();\n//create a session\nSession session = connection.createSession(false,Session.AUTO_ACKNOWLEDGE);</code></pre>\n\n<p>(3) Get the destination (Queue or Topic)</p>\n\n<ul>\n\t<li>You can either create one programmatically&nbsp;\n\t<pre>\n<code class=\"language-java\">Topic topic = session.createTopic(\u201cTestTopic\u201d);</code></pre>\n\n\t<p>&nbsp;</p>\n\t</li>\n\t<li>Or, create using Admin console of MOM / application-server and use that through JNDI\n\t<pre>\n<code class=\"language-java\">Destination queue = (Queue) jndiContext.lookup(\u201c/jms/myQueue\u201d); </code></pre>\n\n\t<p>&nbsp;</p>\n\t</li>\n</ul>\n\n<p>(4) Create Producer in one application, send the message</p>\n\n<pre>\n<code class=\"language-java\">MessageProducer producer = session.createProducer(topic);\n// Create and send the message\nTextMessage msg = session.createTextMessage();\nmsg.setText(\u201cHello JMS World\u201d);\nproducer.send(msg);</code></pre>\n\n<p>Create Consumer in maybe another application, listen for messages</p>\n\n<pre>\n<code class=\"language-java\">MessageConsumer consumer = session.createConsumer(topic);\n// Listen for arriving messages asynchronously\nMessageListener listener = new MessageListener() {\npublic void onMessage(Message msg) { /* do something */ }\n};\nconsumer.setMessageListener(listener);\nconnection.start();\n\n//You can also get message in synchronous way\nMessage m = consumer.receive();</code></pre>\n\n<p>&nbsp;</p>\n\n<h2>JMS Application using Spring Boot &amp; ActiveMQ:</h2>\n\n<p>As always Spring Boot makes it easy to work with anything. Go to&nbsp;<a href=\"https://start.spring.io/\" target=\"_blank\">https://start.spring.io/</a> select the Web and JMS as dependencies. Generate the skeleton project. Import in your IDE (IntelliJ, or other).</p>\n\n<p>How To Use ActiveMQ in an application?</p>\n\n<ul>\n\t<li>Spring provides a JMS Template, which you can/should use to send and receive messages on queues.</li>\n\t<li>Spring wraps JMS Exceptions into runtime exceptions.</li>\n\t<li>Spring provides easy configuration to connect with a running ActiveMQ instance, it even provides an embedded ActiveMQ instance if you do not have an explicit one (but use this only for development/testing purpose).</li>\n\t<li>Provide an ActiveMQConnectionFactory which requires ActiveMQ server&#39;s URL, username and password.</li>\n\t<li>Provide <code>DefaultJmsListenerContainerFactory</code> which requires a <code>ActiveMQConnectionFactory</code>, this is so that consumer/receivers become active.</li>\n\t<li>You will also need to provide MessageConverter. There are many types: <code>MappingJackson2MessageConverter</code>, <code>SimpleMessageCoverter</code>, <code>MessagingMessageConverter </code>etc.</li>\n</ul>\n\n<p>Spring will wire up these beans where needed e.g. the JMSTemplate provided by Spring will use your provided MessageConverter automatically.</p>\n\n<p>&nbsp;</p>\n\n<p><em>References: ActiveMQ doc,&nbsp;Understanding Message Brokers book, etc</em>&nbsp;</p>\n", "authorId": 1, "subject": "programming", "tags": [], "img": "/images/messaging.jpg", "summary": "JMS provides you a standard way in which you can interconnect different systems which talk to each other in an asynchronous way.", "lastUpdated": "2021-06-06 10:49:59.003347"}