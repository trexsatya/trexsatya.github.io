{"name": "Databases", "id": 222, "content": "<div style=\"background:#eeeeee;border:1px solid #cccccc;padding:5px 10px;\">\n<ol>\n\t<li>Why databases are important? Why do we even need databases, why can&#39;t we just use huge files?</li>\n\t<li>If you were to create a DBMS, what are the core components that need to be developed?</li>\n\t<li>How would you optimize performance in DBMS operations?</li>\n\t<li>How would you handle concurrency (multiple users operating on same data set)? What models could you implement?</li>\n</ol>\n</div>\n\n<p><br />\nDatabases are probably the most important component of any system. And choosing correct DBMS, handling data storage and querying efficiently is of utmost importance to make your system fast.</p>\n\n<blockquote>\n<p>Note: This article has more links than explanations. Visit the links to get in depth knowledge.</p>\n</blockquote>\n\n<p>Read this article: <a href=\"http://coding-geek.com/how-databases-work/\" target=\"_blank\">how databases work</a> and <a href=\"https://stackoverflow.com/questions/172925/how-do-databases-work-internally\" target=\"_blank\">this</a>. Watch <a href=\"https://www.youtube.com/watch?v=aZjYr87r1b8\" target=\"_blank\">this video</a>.</p>\n\n<p>This guy implemented a clone of sqlite: <a href=\"https://cstack.github.io/db_tutorial/parts/part1.html\" target=\"_blank\">Read here</a>.</p>\n\n<h2>Why Database?</h2>\n\n<p>You should definitely use database for <strong><em>persistent storage</em></strong>. But you should be able to answer why database instead of just a file or filesystem storage.</p>\n\n<p>See this <a href=\"https://stackoverflow.com/questions/2356851/database-vs-flat-files\" target=\"_blank\">Stackoverflow thread</a>.</p>\n\n<p>Ask yourself these questions?</p>\n\n<ul>\n\t<li>Do you need to make queries and CRUD operations to file data? If yes, what sort of queries?</li>\n\t<li>Do you have relational data, relationship between records? Do you have contraints on those relationships?</li>\n\t<li>Is the file going to be accessed by only one client at a time? How do you make sure of that?</li>\n\t<li>Can you store your whole data on the same server as application server, or might you need to move it to another server because of the size?</li>\n\t<li>Do you need to manage access control to the data?</li>\n</ul>\n\n<p>Databases can help in all these scenarios.</p>\n\n<h2>Database components</h2>\n\n<p><u>The core components:</u></p>\n\n<ul>\n\t<li><strong>The process manager</strong>: Many databases have a <strong>pool of processes/threads</strong> that needs to be managed. Moreover, in order to gain nanoseconds, some modern databases use their own threads instead of the Operating System threads.</li>\n\t<li><strong>The network manager</strong>: Network I/O is a big issue, especially for distributed databases. That&rsquo;s why some databases have their own manager.</li>\n\t<li><strong>File system manager</strong>: <strong>Disk I/O is the first bottleneck of a database</strong>. Having a manager that will perfectly handle the Operating System file system or even replace it is important.</li>\n\t<li><strong>The memory manager</strong>: To avoid the disk I/O penalty a large quantity of ram is required. But if you handle a large amount of memory, you need an efficient memory manager. Especially when you have many queries using memory at the same time.</li>\n\t<li><strong>Security Manager</strong>: for managing the authentication and the authorizations&nbsp;of the users</li>\n\t<li><strong>Client manager</strong>: for managing the client connections</li>\n\t<li>&hellip;</li>\n</ul>\n\n<p><u>The tools:</u></p>\n\n<ul>\n\t<li><strong>Backup manager</strong>: for saving and restoring a database.</li>\n\t<li><strong>Recovery manager</strong>: for restarting the database in a <strong>coherent state</strong> after a crash</li>\n\t<li><strong>Monitor manager</strong>: for logging the activity of the database and providing tools to monitor a database</li>\n\t<li><strong>Administration manager</strong>: for storing metadata (like the names and the structures of the tables) and providing tools to manage databases, schemas, tablespaces, &hellip;</li>\n\t<li>&hellip;</li>\n</ul>\n\n<p><u>The query Manager:</u></p>\n\n<ul>\n\t<li><strong>Query parser</strong>: to check if a query is valid</li>\n\t<li><strong>Query rewriter</strong>: to pre-optimize a query</li>\n\t<li><strong>Query optimizer</strong>: to optimize a query</li>\n\t<li><strong>Query executor</strong>: to compile and execute a query</li>\n</ul>\n\n<p><u>The data manager:</u></p>\n\n<ul>\n\t<li><strong>Transaction manager</strong>: to handle transactions</li>\n\t<li><strong>Cache manager</strong>: to put data in memory before using them and put data in memory before writing them on disk</li>\n\t<li><strong>Data access manager</strong>: to access data on disk</li>\n</ul>\n\n<h2>How Does A Database Store Data?</h2>\n\n<p>Where does MySQL store data and what is the directory structure?&nbsp;</p>\n\n<p>Run this command to find out:&nbsp;&nbsp;&nbsp;<code>SHOW VARIABLES LIKE &#39;datadir&#39;;</code></p>\n\n<p>References: (<a href=\"https://stackoverflow.com/questions/10378693/how-does-mysql-store-data\" target=\"_blank\">Stackoverflow link</a>)&nbsp;<a href=\"https://stackoverflow.com/questions/172925/how-do-databases-work-internally\" target=\"_blank\">How do DBs work internally Stackoverflow</a>:</p>\n\n<p><em><strong>Can you store the whole table in a file?</strong></em> - Sure, you can (Heap File Organisation/ file contains records unsorted), you could also keep entries in file in sorted order&nbsp;(Sorted Files), you could use pointer chaining.&nbsp;</p>\n\n<p><strong><em>What about indexes (and other DB objects)?</em></strong> - You could store indexes (etc) in the same file, or in a separate file.</p>\n\n<p>Different DBMSs use different strategies to split data and organize the data on external storage (disks etc). In Oracle <em>&quot;A database is divided into one or more logical storage units called <a href=\"https://docs.oracle.com/cd/E11882_01/win.112/e10845/ap_raw.htm#NTQRF210\" target=\"_blank\">tablespaces</a>. Tablespaces are divided into logical units of storage called segments, which are further divided into extents.&nbsp;Datafiles for tablespaces can be stored on a <strong>file system</strong> or on <strong>raw partitions</strong>. A raw partition is a portion of a physical disk that is accessed at the lowest possible level. Input/output (I/O) to a raw partition offers approximately a 5% to 10% performance improvement over I/O to a partition with a file system on it.</em><a id=\"i432558\"><em>&quot;</em>&nbsp;</a></p>\n\n<p>Databases may store data in many data structure types.<sup id=\"cite_ref-Physical_Database_Design_1-0\"><a href=\"https://en.wikipedia.org/wiki/Database_engine#cite_note-Physical_Database_Design-1\">[1]</a></sup>&nbsp;Common examples are the following:</p>\n\n<ul>\n\t<li>ordered/unordered&nbsp;<a href=\"https://en.wikipedia.org/wiki/Flat_file_database\" title=\"Flat file database\">flat files</a></li>\n\t<li><a href=\"https://en.wikipedia.org/wiki/Hash_table\" title=\"Hash table\">hash tables</a></li>\n\t<li><a href=\"https://en.wikipedia.org/wiki/B%2B_tree\" title=\"B+ tree\">B+ trees</a></li>\n\t<li><a href=\"https://en.wikipedia.org/wiki/ISAM\" title=\"ISAM\">ISAM</a></li>\n\t<li><a href=\"https://en.wikipedia.org/wiki/Heap_(data_structure)\" title=\"Heap (data structure)\">heaps</a></li>\n</ul>\n\n<p><strong>Indexing</strong> is a technique some storage engines use for improving database performance. The many types of indexes share the common property that they reduce the need to examine every entry when running a query.</p>\n\n<p>An Index is a collection of Data Entries. A DataEntry is a <code>&lt;SearchKey, X&gt;</code>&nbsp;where <code>X</code>&nbsp; could be the Record itself, or the RecordId, or a set of RecorIds. In case of Indexed Files based organisation DataEntry is identical to DataRecord.</p>\n\n<p>MySQL allows you to create two types of indexes. B-Tree and Hash. <a href=\"https://dev.mysql.com/doc/refman/5.5/en/index-btree-hash.html\" target=\"_blank\">See the difference here</a>.<br />\nPostgresSQL offers more fine-tuning through different kinds of indexes. (trees, expression indexes, partial indexes, and hash indexes).</p>\n\n<p>An index stores copy of data from table. It&#39;s redundancy. <a href=\"https://use-the-index-luke.com/sql/anatomy\" target=\"_blank\">https://use-the-index-luke.com/sql/anatomy</a></p>\n\n<p><strong><em>Are Indexes always used if present?</em></strong></p>\n\n<p>No,&nbsp;The following&nbsp;<a href=\"https://dev.mysql.com/doc/refman/8.0/en/select.html\" title=\"13.2.10\u00a0SELECT Statement\"><code>SELECT</code></a>&nbsp;statements do not use indexes<a href=\"https://dev.mysql.com/doc/refman/8.0/en/index-btree-hash.html\"> (MySQL documentation)</a>:</p>\n\n<pre>\n<code class=\"language-sql\">SELECT * FROM tbl_name WHERE key_col LIKE '%Satya%';\nSELECT * FROM tbl_name WHERE key_col LIKE other_col;</code></pre>\n\n<p>In the first statement, the&nbsp;<code>LIKE</code>&nbsp;value begins with a wildcard character. In the second statement, the&nbsp;<code>LIKE</code>&nbsp;value is not a constant.</p>\n\n<p>Sometimes MySQL does not use an index, even if one is available. One circumstance under which this occurs is when the optimizer estimates that using the index would require MySQL to access a very large percentage of the rows in the table. (In this case, a table scan is likely to be much faster because it requires fewer seeks.) However, if such a query uses&nbsp;<code>LIMIT</code>&nbsp;to retrieve only some of the rows, MySQL uses an index anyway, because it can much more quickly find the few rows to return in the result.</p>\n\n<p>Hash-Based Indexes are very fast for Key-Value storage where you can use only operators&nbsp;<code>=</code>&nbsp;or&nbsp;<code>&lt;=&gt;</code>&nbsp;</p>\n\n<p>Leaf nodes in the B+ Tree store index information (column &amp; pointer to row). The Leaf Nodes are connected with each other forming a doubly linked list. The non-leaf nodes store the first key of the block they are referring to leaf nodes or tree nodes on the next level. The structure of B+ Tree makes it easy to perform Range Queries. It&#39;s a balanced Search Tree.</p>\n\n<p style=\"margin-left: 40px;\"><u><strong>B Tree vs B+ Tree vs M-way Search Tree:</strong></u></p>\n\n<p style=\"margin-left: 40px;\">M-way search trees are extension over Binary Search Trees, having m children instead of just two. Node can have more than one key (m-1 to be precise). M-way search trees are not balanced. So they can degenerate into list easily giving you search complexity of O(N).</p>\n\n<p style=\"margin-left: 40px;\">B Tree: Are extension over M-way Search Tree. It is balanced because it has some rules when inserting into the tree. Before creating a new node, you must have at least half of the node filled (except for root). All leaves must be at the same level. Creation process is bottom up.</p>\n\n<p style=\"margin-left: 40px;\">B+ Tree: are same as B Tree. But although each node in&nbsp; B Tree can have record pointers in each node, B+ trees have record pointers only in leaf nodes. Also leaf nodes are not connected in B Tree. Also B+ tree has all the keys in leaf nodes, and duplicates in non-leaf nodes.<br />\n&nbsp;</p>\n\n<h2>How Does DBMS Execute Queries?</h2>\n\n<p>&nbsp;</p>\n\n<p>Before using indexes DBMS estimates the cost of using the index E.g.</p>\n\n<p>&nbsp;</p>\n\n<div style=\"max-width: 100%;overflow: scroll;\"><img alt=\"Tooltips for COUNT queries (with and without index hints)\" src=\"https://sqlperformance.com/wp-content/uploads/2017/03/WSI-tooltips.png\" />\n<p>&nbsp;</p>\n</div>\n\n<p>&nbsp;</p>\n\n<h2>Performance Problems of DB</h2>\n\n<p><strong><em>Slowness despite having indexes?</em></strong></p>\n\n<p>An index lookup requires three steps:</p>\n\n<ol>\n\t<li>the tree traversal;</li>\n\t<li>following the leaf node chain;</li>\n\t<li>fetching the table data.</li>\n</ol>\n\n<p>The tree traversal is the only step that has an upper bound for the number of accessed blocks&mdash;the index depth. The other two steps might need to access many blocks&mdash;they cause a slow index lookup. <a href=\"https://use-the-index-luke.com/sql/anatomy/slow-indexes\" target=\"_blank\">Read here</a>.</p>\n\n<p>One index on a table is not a big deal. You automatically have an index on columns (or combinations of columns) that are primary keys or declared as unique. (<a href=\"https://stackoverflow.com/questions/41410482/what-are-the-disadvantages-to-indexes-in-database-tables\" target=\"_blank\">Read this stackoverflow thread</a>). <span style=\"color:#27ae60;\"><em>More indexes means more work when insertion or deletion to table is happening.</em></span></p>\n\n<p>Some DBs like MySQL have clustered and non-clustered indexes. Clustered means indexes have both index and data pages (It&#39;s not just index, it also has table data). While there can be only one clustered index on a table, a table can have up to 999 nonclustered indexes. <a href=\"https://stackoverflow.com/questions/1251636/what-do-clustered-and-non-clustered-index-actually-mean\" target=\"_blank\">Read this stackoverflow thread</a>. Basically in clustered indexes, the leaf level of B+ Tree is the table itself. It means there is only one clustered index possible. That&#39;s why we need non-clustered indexes, which can have different key order.</p>\n\n<p>If the table has no clustered index it is called a heap.</p>\n\n<p>Non clustered indexes can be built on either a heap or a clustered index. They always contain a row locator back to the base table. In the case of a heap this is a physical row identifier (rid) and consists of three components (File:Page:Slot). In the case of a Clustered index the row locator is logical (the clustered index key).</p>\n\n<p><strong><em>Which index is faster? Clustered or Non-clustered?</em></strong> Just remember that the searching process using non-clustered indexes involves bookmark/pointer visiting also, and if query optimizer decides that the cost of visiting bookmarks is high, it can avoid usage of index altogether. <a href=\"https://www.youtube.com/watch?v=ITcOiLSfVJQ\" target=\"_blank\">Watch this video</a>. By default indexes created for Primary Key constraints are Clustered, and for other sorts Non-clustered.&nbsp; <a href=\"https://sqlperformance.com/2017/03/sql-indexes/performance-myths-clustered-vs-non-clustered\">Read this as well</a>.</p>\n\n<p>&nbsp;</p>\n\n<h2>Database Transactions</h2>\n\n<p>In a Database Management System, a transaction is a single unit of logic or work, sometimes made up of multiple operations. Any logical calculation done in a consistent mode in a database is known as a transaction. One example is a transfer from one bank account to another: the complete transaction requires subtracting the amount to be transferred from one account and adding that same amount to the other.</p>\n\n<p>The requirements for this are ACID:</p>\n\n<p><strong>A</strong>tomic: Either all statements executed or none (everything reverted). Handles even unusual situations like power failures, errors and crashes.</p>\n\n<p><strong>C</strong>onsistency: any data written to the database must be valid according to all defined rules, including <a class=\"mw-redirect\" href=\"https://en.wikipedia.org/wiki/Integrity_constraints\" title=\"Integrity constraints\">constraints</a>, <a class=\"mw-redirect\" href=\"https://en.wikipedia.org/wiki/Cascading_rollback\" title=\"Cascading rollback\">cascades</a>, <a href=\"https://en.wikipedia.org/wiki/Database_trigger\" title=\"Database trigger\">triggers</a>, and any combination thereof. In case of clustered setup, this means that any data written is updated to all data nodes.</p>\n\n<p><strong>I</strong>solation: Transactions are executed concurrently. So we need some sort of concurrency control.</p>\n\n<p><strong>D</strong>urability: Once a transaction has been committed, it must remain so. Simply, it means that transaction has taken its effect into disk (non-volatile memory).</p>\n\n<p>&nbsp;</p>\n\n<p><strong>How is ACID achieved?</strong></p>\n\n<p>&nbsp;</p>\n\n<p><strong>How is Isolation achieved?</strong></p>\n\n<p>Isolation mechanism is similar to achieving thread-safety in concurrent processing.</p>\n\n<p>When two transactions (T1, T2) run concurrently, they can run into different situations.</p>\n\n<ol>\n\t<li>T1 updates something, T2 reads updated data, but T1 reverts the change that it made. =&gt; <strong>Dirty Read</strong><br />\n\tSolve the problem with isolation-level&nbsp;READ COMMITTED.<br />\n\t&nbsp;</li>\n\t<li>T2&nbsp;reads a row with id=1, T1&nbsp;updates the row with id=1 and commits, T2 reads the row again. T2 got different data from reading the row within the same transaction, which can cause problems in the result. =&gt; <strong>Non-Repeatable Read.&nbsp;</strong><br />\n\tBut why would a transaction read a row twice in the same transaction? - It&#39;s actually not required, it&#39;s just to demonstrate the problem, that the calculation/decision would be based on stale data.<br />\n\tSolve the problem with&nbsp;REPEATABLE READ. Repeatable can be implemented by locking&nbsp;all the rows examined in the query, or by using Snapshot Isolation (although for some DBMSs REPEATABLE READ and&nbsp;&nbsp;SNAPSHOT ISOLATION is exactly same thing).<br />\n\t&nbsp;</li>\n\t<li>&nbsp;</li>\n</ol>\n\n<p>&nbsp;</p>\n\n<p>&nbsp;</p>\n\n<h2>Database Designing</h2>\n\n<h3>Normalization vs Denormalization:</h3>\n\n<p>Normalization is done in order to structure data to reduce possibility of problems with data inconsistency.</p>\n\n<p>DeNormalization is done in order to avoid performance impact introduced by highly structured data which results into heavy join operations while querying data. You willingly introduce data redundancy in order to increase performance.&nbsp;</p>\n\n<p>It&#39;s classic Time-Space tradeoff decision.&nbsp;</p>\n\n<h3>Different Normal Forms:</h3>\n\n<p><em>Candidate Key: A set of attributes which could be used as a Primary Key (to uniquely identify the records in the table).</em></p>\n\n<p><em>Non-Trivial Multivalued Dependency X&nbsp;<img alt=\"{\\displaystyle \\twoheadrightarrow }\" aria-hidden=\"true\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/4b9c2ec85d900b1485fad362aabc2349a4d54ad3\" />&nbsp;Y: a dependency where Y is not subset of X and X+Y is not equal to all attributes in the table.</em></p>\n\n<p>&nbsp;</p>\n\n<p>1NF: Each field contains only one value, not a set of values.&nbsp;</p>\n\n<p>2NF: Every non-candidate-key attribute depends upon whole candidate key (not just part of it).&nbsp;</p>\n\n<p>3NF: Doesn&#39;t have transitional dependencies within same table.</p>\n\n<p>BCNF: For every functional dependency&nbsp;<i>X &rarr; Y,&nbsp;</i>either&nbsp;Y &sube; X or X is a super-key. Sometimes achieving BCNF is not feasible.</p>\n\n<p>4NF: For every Non-Trivial Multivalued Dependency X&nbsp;<img alt=\"{\\displaystyle \\twoheadrightarrow }\" aria-hidden=\"true\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/4b9c2ec85d900b1485fad362aabc2349a4d54ad3\" />&nbsp;Y, X is a super key (i.e. a candidate key or super-set of a candidate key). A subset of attributes does not depend upon subset of Super-Key.</p>\n\n<p>What&#39;s the process of normalization?</p>\n\n<p>The most practical way is to have some initial tables, add examples as per business scenario, then see which tables contain duplicate data.&nbsp;When you see duplicates, decompose into more tables.</p>\n\n<p>Indexes</p>\n\n<p>&nbsp;</p>\n\n<h2>Distributed Databases</h2>\n\n<p><strong>MySQL Cluster</strong></p>\n\n<p>MySQL Cluster uses NDBCLUSTER as its storage/database engine.&nbsp;&nbsp;<a href=\"https://dev.mysql.com/doc/mysql-cluster-excerpt/8.0/en/mysql-cluster.html\" title=\"Chapter\u00a02\u00a0MySQL NDB Cluster 8.0\"><code>NDBCLUSTER</code></a>&nbsp;(also known as&nbsp;<code><a href=\"https://dev.mysql.com/doc/mysql-cluster-excerpt/8.0/en/mysql-cluster.html\" title=\"Chapter\u00a02\u00a0MySQL NDB Cluster 8.0\">NDB</a></code>) is an in-memory storage engine <em>[NDB Cluster tables are normally stored completely in memory rather than on disk]</em> offering high-availability and data-persistence features.&nbsp; In an NDB Cluster, each part of the cluster is considered to be a&nbsp;node. A node implies a <em><strong>process</strong></em>, there can be one or more nodes on a single computer (aka cluster-host).&nbsp;</p>\n\n<ol>\n\t<li>Management Node: Started first, manages other nodes. Stores (global) configuration data.&nbsp;</li>\n\t<li>Data&nbsp;Node:&nbsp;</li>\n\t<li>SQL Node:&nbsp;An SQL node is a&nbsp;<strong>mysqld</strong>&nbsp;process started with the&nbsp;<a href=\"https://dev.mysql.com/doc/mysql-cluster-excerpt/8.0/en/mysql-cluster-program-options-mysqld.html#option_mysqld_ndbcluster\"><code>--ndbcluster</code></a>&nbsp;and&nbsp;<code>--ndb-connectstring</code></li>\n</ol>\n\n<p>API Nodes are any application processes that access cluster data (this means SQL nodes as well). E.g.&nbsp;the&nbsp;<a href=\"https://dev.mysql.com/doc/mysql-cluster-excerpt/8.0/en/mysql-cluster-programs-ndb-restore.html\" title=\"6.23\u00a0ndb_restore \u2014 Restore an NDB Cluster Backup\"><strong>ndb_restore</strong></a>&nbsp;utility.</p>\n\n<p>NDB Cluster is currently designed with the intention that data nodes are homogeneous in terms of processor power, memory space, and bandwidth.</p>\n\n<p>[# of node groups] = [# of data nodes] / NoOfReplicas.&nbsp;You can add new node groups (and thus new data nodes) online, to a running NDB Cluster;</p>\n\n<p>Each node stores at least one <em><strong>copy</strong></em> of any partitions (portion of data) assigned to it (aka Partition Replica/Fragment Replica). You can control the number of partitions.&nbsp;A fragment replica belongs entirely to a single node; a node can (and usually does) store several fragment replicas.</p>\n\n<p>Replicas (backup of partitions) are stored on nodes such that so long as at least one node in node group is alive and functioning, the whole of data is available.</p>\n\n<p>A little detail of NDB source code:</p>\n\n<div style=\"font-size: smaller;\" title=\"src\">\n<p><a href=\"https://downloads.mysql.com/docs/ndb-internals-en.pdf\">NDB Kernel Blocks:</a>&nbsp;</p>\n\n<ol>\n\t<li>BACKUP :&nbsp;backup whenever required, handle checkpoints</li>\n\t<li>RESTORE : restore from online backups</li>\n\t<li>CMVMI Config mgt -&nbsp;</li>\n\t<li>DBACC Access Control &amp; Lock Mgt: also handles&nbsp;primary key and unique key hash indexes storage</li>\n\t<li>DBDICT Data Dictionary: metadata for all tables</li>\n\t<li>DBDIH Data Distribution: handles&nbsp;table partition, and fragment replica of each partition, also handles local and global checkpoints. Also manages node and system restarts.</li>\n\t<li>DBLQH (Local) Low Query handler:&nbsp;manages data and transactions local to the cluster&#39;s data nodes, and acts as a coordinator of 2-phase commits. Participates in operations on tuples.s</li>\n\t<li>DBSPJ : handles joins pushed down from sql nodes</li>\n\t<li>DBTC Txn Coordinator: handles distributed transactions and other global-level operations</li>\n\t<li>DBTUP : manages physicaal storage of cluster data</li>\n\t<li>DBTUX : provides local management of ordered indexes</li>\n\t<li>DBUTIL :&nbsp;provides internal interfaces to transaction and data operations, performing essential operations on signals passed between nodes</li>\n\t<li>LGMAN log group manager: handles&nbsp;undo logs for Disk Data tables</li>\n\t<li>NDBCNTR : handles block initialisation, configuration, graceful&nbsp; shutdown of data nodes.</li>\n\t<li>NDBFS : file system abstraction layer</li>\n\t<li>PGMAN :&nbsp;page and buffer management for Disk Data tables</li>\n\t<li>QMGR Query Manager:&nbsp;This is the logical cluster management block, and handles node membership in the cluster using a heartbeat mechanism.</li>\n\t<li>SUMA Subscription Mgr:&nbsp;handles event logging and reporting functions.</li>\n\t<li>THRMAN Thread Mgr:&nbsp;</li>\n\t<li>TRPMAN (signal) Transport Mgr:&nbsp;</li>\n\t<li>TSMAN TableSpace Mgr:&nbsp;</li>\n\t<li>TRIX :&nbsp;responsible for the handling of internal triggers and unique indexes.&nbsp;TRIX, like DBUTIL, is a utility block containing many helper functions for building indexes and handling signals between nodes</li>\n</ol>\n</div>\n\n<p>&nbsp;</p>\n\n<p><em><strong>How is data replicated in MySQL Cluster?</strong></em></p>\n\n<p>&nbsp;</p>\n\n<p>&nbsp;</p>\n\n<p><strong>MongoDB Cluster&nbsp;</strong></p>\n\n<p>&nbsp;</p>\n\n<p>&nbsp;</p>\n\n<p>&nbsp;</p>\n\n<h2>Database Sharding</h2>\n\n<p>&nbsp;</p>\n\n<p>&nbsp;</p>\n\n<h2>Is MySQL Cluster Consistent?</h2>\n\n<p>It depends: Single MySQL Cluster is CP (from CAP). It guarantees <strong>Strong Consistency</strong>. Data is synchronously replicated using 2PC Commit.</p>\n\n<blockquote>\n<p><span style=\"left: 391.2px; top: 158.324px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.829379);\">MySQL Cluster is implemented as a</span><span style=\"left: 601.314px; top: 158.324px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.804029);\">strongly <span class=\"highlight selected\">consisten</span>t,</span><span style=\"left: 715.034px; top: 158.324px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.80443);\">active/active, multi</span><span style=\"left: 823.6015px; top: 158.32441406249995px; font-size: 14px; font-family: sans-serif;\">-</span><span style=\"left: 828.319px; top: 158.324px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.755729);\">master database </span><span style=\"left: 391.2px; top: 179.124px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.793524);\">ensuring </span><span style=\"left: 443.529px; top: 179.124px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.768164);\">updates </span><span style=\"left: 490.346px; top: 179.124px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.772073);\">can be </span><span style=\"left: 530.459px; top: 179.124px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.783579);\">made to any </span><span style=\"left: 603.237px; top: 179.124px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.77805);\">node </span><span style=\"left: 634.316px; top: 179.124px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.775148);\">and </span><span style=\"left: 658.312px; top: 179.124px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.795787);\">are instantly available to </span><span style=\"left: 800.712px; top: 179.124px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.782657);\">the rest of the</span><span style=\"left: 881.755px; top: 179.124px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.801475);\">cluster, </span><span style=\"left: 391.2px; top: 199.924px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.824144);\">without any </span><span style=\"left: 462.026px; top: 199.924px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.8015);\">replication </span><span style=\"left: 526.143px; top: 199.924px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.801985);\">lag</span></p>\n\n<p><span style=\"left: 391.2px; top: 229.124px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.795097);\">Tables are au</span><span style=\"left: 466.709px; top: 229.124px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.798969);\">tomatically sharded across a pool of low cost commodity data nodes, enabling </span><span style=\"left: 391.2px; top: 250.324px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.822316);\">the database to scale horizontally, accessed both from SQL and directly via NoSQL APIs. </span><span style=\"left: 391.2px; top: 271.124px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.79254);\">New nodes can be added on</span><span style=\"left: 549.7309999999999px; top: 271.1244140624999px; font-size: 14px; font-family: sans-serif;\">-</span><span style=\"left: 554.449px; top: 271.124px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.788546);\">line, instantly scaling database capacity and performance, even </span><span style=\"left: 391.2px; top: 291.5244140624998px; font-size: 14px; font-family: sans-serif;\">f</span><span style=\"left: 395.925px; top: 291.524px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.797267);\">or the heaviest write loads.</span></p>\n\n<p><span style=\"left: 391.2px; top: 433.5244140624999px; font-size: 14px; font-family: sans-serif;\">U</span><span style=\"left: 401.431px; top: 433.524px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.788589);\">nlike other distributed databases, </span><span style=\"left: 591.449px; top: 433.524px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.840565);\">MySQL Cluster preserves</span><span style=\"left: 742.932px; top: 433.524px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.98928);\">ACID</span><span style=\"left: 777.5598333333334px; top: 433.5244140624999px; font-size: 14px; font-family: sans-serif;\">-</span><span style=\"left: 782.278px; top: 433.524px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.754682);\">guarantees,</span><span style=\"left: 849.929px; top: 433.524px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.819622);\">the fl</span><span style=\"left: 879.438px; top: 433.524px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.860881);\">exibility </span><span style=\"left: 391.2px; top: 454.324px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.854778);\">of </span><span style=\"left: 406.55px; top: 454.324px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.855156);\">JOIN operations</span><span style=\"left: 503.337px; top: 454.324px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.757193);\">and</span><span style=\"left: 527.333px; top: 454.324px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.787511);\">maintain</span><span style=\"left: 576.9021666666666px; top: 454.32441406249984px; font-size: 14px; font-family: sans-serif;\">s</span><span style=\"left: 585.957px; top: 454.324px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.794957);\">referential integrity</span><span style=\"left: 699.242px; top: 454.324px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.775833);\">between tables</span><span style=\"left: 786.566px; top: 454.324px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.798507);\">on different nodes, </span><span style=\"left: 896.731px; top: 454.324px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.806909);\">on </span><span style=\"left: 391.2px; top: 474.724px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.79695);\">different shards, </span><span style=\"left: 486.804px; top: 474.724px; font-size: 14px; font-family: sans-serif; transform: scaleX(0.783);\">even in different data centers</span><span style=\"left: 651.222px; top: 474.7244140624998px; font-size: 14px; font-family: sans-serif;\">.</span></p>\n\n<p><span style=\"left: 651.222px; top: 474.7244140624998px; font-size: 14px; font-family: sans-serif;\">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - <a href=\"https://www.mysql.com/products/cluster/mysql-cluster-datasheet.pdf\" target=\"_blank\">MySQL Docs</a> </span></p>\n</blockquote>\n\n<p>MySQL NDB (Network Database Cluster) is different from MySQL Replication (which is a master-slave configuration; asynchronous replication). NDB has option for async replication though.</p>\n\n<p>There must be a separate management node which will (normally) act as arbitrator. There can be multiple management servers.</p>\n\n<p>There should be multiple data nodes (for storage and replication).</p>\n\n<p>There should be multiple SQL nodes (instances of MySQL servers with support for&nbsp;<a class=\"link\" href=\"https://dev.mysql.com/doc/refman/5.7/en/mysql-cluster.html\" title=\"Chapter\u00a021\u00a0MySQL NDB Cluster 7.5 and NDB Cluster 7.6\"><code class=\"literal\">NDBCLUSTER</code></a> storage engine and started with the <code class=\"option\">--ndb-cluster</code> option to enable the engine and the <code class=\"option\">--ndb-connectstring</code> option to enable it to connect to an NDB Cluster management server.)</p>\n\n<p><strong>Is NDB Cluster Transaction safe?</strong></p>\n\n<p><span class=\"emphasis\"><em>Yes</em></span>. For tables created with the <a class=\"link\" href=\"https://dev.mysql.com/doc/refman/5.7/en/mysql-cluster.html\" title=\"Chapter\u00a021\u00a0MySQL NDB Cluster 7.5 and NDB Cluster 7.6\"><code class=\"literal\">NDB</code></a> storage engine, transactions are supported. Currently, NDB Cluster supports only the <a class=\"link\" href=\"https://dev.mysql.com/doc/refman/5.7/en/innodb-transaction-isolation-levels.html#isolevel_read-committed\"><code class=\"literal\">READ COMMITTED</code></a> transaction isolation level.</p>\n\n<p>In order for a table to be shared between nodes in an NDB Cluster, the table must be created using <code class=\"literal\">ENGINE=NDB</code></p>\n\n<p>Arbitrator: In Split-Brain scenarios, when network partitioning somehow caused the cluster to divide into two (or more) parts where the nodes in one set can see each other but not the nodes in other part. In this scenario, each set of nodes tries to behave as a full cluster, this is handled by Arbitrator.</p>\n\n<p>Arbitrator selects the node set as cluster, whichever contacts it first; and instructs other sets to shut down.</p>\n\n<p>&nbsp;</p>\n\n<h2>Is MongoDB Consistent?</h2>\n\n<p>Read this: <a href=\"https://stackoverflow.com/questions/11292215/where-does-mongodb-stand-in-the-cap-theorem\" target=\"_blank\">Stackoverflow thread</a>.</p>\n\n<p>Summary: MongoDB is strongly consistent when you use a single connection or the correct <a href=\"https://docs.mongodb.com/manual/reference/write-concern/\" rel=\"noreferrer\" target=\"_blank\">Write</a>/<a href=\"https://docs.mongodb.com/manual/reference/read-concern/#read-concern-levels\" rel=\"noreferrer\" target=\"_blank\">Read Concern Level</a> (<a href=\"http://techidiocy.com/write-concern-mongodb-performance-comparison/\" rel=\"noreferrer\" target=\"_blank\">Which will cost you execution speed</a>). Reads from secondaries have to be approved by majority, which ensures strong consistency, if majority concern level is set for both read and write (<a href=\"https://docs.mongodb.com/manual/core/replica-set-members/#replica-set-secondary-members\" target=\"_blank\">See doc</a>). As soon as you don&#39;t meet those conditions (especially when you are reading from a secondary-replica) MongoDB becomes Eventually Consistent.</p>\n\n<p>Sometimes consistency is sacrificed to achieve availability. E.g. when Primary goes down, new Primary is elected, every write done by old Primary but not sync&#39;ed to secondaries will be reverted and saved to a rollback-file, as soon as it reconnects, the old primary is now a secondary with inconsistent data.</p>\n\n<p>&nbsp;</p>\n\n<h2>Database Connection Pools</h2>\n\n<p>Database clients can maintain a <a href=\"https://stackoverflow.blog/2020/10/14/improve-database-performance-with-connection-pooling/#:~:text=Instead%20of%20opening%20and%20closing,of%20clients%20accessing%20it%20grow.\" target=\"_blank\">pool of DB connections</a>, because physical establishment of a DB connection is a costly process (You have to open up network sessions, authenticate, have authorisation checked, and so on).</p>\n\n<p>Libraries which provide connection pools: <a href=\"https://www.mchange.com/projects/c3p0/\" target=\"_blank\">C3P0</a>, <a href=\"https://commons.apache.org/proper/commons-dbcp/download_dbcp.cgi\">Apache Commons DBCP Component</a>, <a href=\"https://brettwooldridge.github.io/HikariCP/\">HikariCP</a></p>\n\n<p>There can be many cinguration parameters, some common ones are: max pool size, min pool size,max prepared statement size, max idle connections, idleTimeout etc.</p>\n\n<p>&nbsp;</p>\n\n<hr />\n<p>An example of Dynamic Procedure in Oracle SQL:</p>\n\n<pre>\n<code class=\"language-sql\">create or replace PROCEDURE proc_name (table_name IN VARCHAR2 DEFAULT 'default_tbl_name')\n As\n   TYPE cur_typ IS REF CURSOR;\n   cur_var cur_typ;\n\n   counter number(10);\n   str_var VARCHAR2(100);\n   query_str VARCHAR2(300);\n   num_var Number(30);\n\nBEGIN\n    begin\n        execute immediate 'alter table ' || table_name || ' add col_name number(30)'; --Add some column if required\n    exception\n        when others \n        THEN dbms_output.put_line(SQLCODE);\n    end;\n    \n    num_var :=0;\n    query_str := 'SELECT a FROM ' || table_name || ' where some_col_name = :col';\n\n    str_var := 'my_column';\n    open item for query_str using str_var; -- parameter binding is index-based\n\n    LOOP\n        fetch item into num_var; -- index based assignment\n        query_str2 := 'SELECT ....';\n\n        execute immediate 'merge into ....';\n\n       counter := counter +1;\n\n       IF (counter =1000)\n       THEN\n            counter :=0;\n            COMMIT;\n       END IF;\n    END LOOP;\n    close item; --close cursor\n\n    commit;\nEND;\n</code></pre>\n\n<p>&nbsp;</p>\n<style type=\"text/css\">@import url('https://fonts.googleapis.com/css?family=Montserrat');\n  .content h1, .content h3, .content h2 {\n    font-family: \"Montserrat\" !important;\n    text-shadow: 7px 7px 0px #d2d2d22e;\n    text-align: center;\n    padding: 1em;\n    /* margin-bottom: 1em; */\n    text-decoration: underline;\n    font-size: 2em !important;\n    line-height: 2em !important;\n    color: #986729;\n  }\n</style>\n", "authorId": 1, "subject": "architecture", "tags": [], "img": "", "summary": "", "lastUpdated": "2024-05-02 20:52:48.645512"}