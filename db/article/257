{"name": "Evolution Of Application/Systems", "id": 257, "content": "<p>You create an <em>application/system</em> to support a business. <em>Business</em> means that your are providing some <em>service</em> to people(<em>users</em>).&nbsp;</p>\n\n<p>What your application/system&nbsp;does largely depends upon what kind of business it is supporting. But in general, it will provide assistance to the users of the system, make things easier for them, make things automatic for them.</p>\n\n<p>How the system does this thing again depends upon what kind of business it is, but in general your system will provide an interface to your users (e.g. a web app, a mobile app, SMS facility, voice call facility, a desktop app, or even a hardware device, etc), your users will interact with this interface and the interface will make some requests to your system, your system will do some things like parse and understand the request, store some data, fetch some data, do some calculations, and then give response back the requester interface.</p>\n\n<p>So, in summary, and from a higher perspective, your system just accepts some requests, stores data, and makes some computations, and serves data.</p>\n\n<p>Simple Case:</p>\n\n<h3>A single application server + A single DB instance</h3>\n\n<p>How much throughput with a reasonable response time can this setup give?&nbsp;</p>\n\n<p>There&#39;s no accurate answer, because it depends upon the webserver implementation <em>(whether it uses event-drive/asynchronous sockets or one hardware thread per request)</em>, web-server configuration, hardware of the server, how much resources your application/DB gets from the hardware (because there&#39;d always be other processes running on the machine, also if you are using VMs from cloud service providers it will be shared with other users).</p>\n\n<p>Nginx (with default config) can handle 300,000 or more open connections. But this many connections, doesn&#39;t mean this many requests can be served simultaneously because the processing of requests will also take time.</p>\n\n<p>It&#39;s better to do stress test on the system to see how much it can handle.</p>\n\n<p><a href=\"http://highscalability.com/blog/2013/5/13/the-secret-to-10-million-concurrent-connections-the-kernel-i.html\">10M concurrent connections with one server</a></p>\n\n<blockquote>\n<p>If we were designing a kernel for handling one application per server we would design it very differently than for a multi-user kernel.&nbsp;</p>\n\n<p><strong>Don&rsquo;t let the kernel do all the heavy lifting</strong>. Take packet handling, memory management, and processor scheduling out of the kernel and put it into the application, where it can be done efficiently. Let Linux handle the control plane and let the the application handle the data plane.</p>\n\n<ul>\n\t<li dir=\"ltr\">\n\t<p dir=\"ltr\">Servers could not handle 10K concurrent connections because of O(n^2) algorithms used in the kernel.</p>\n\n\t<ul>\n\t\t<li>\n\t\t<p dir=\"ltr\">Two basic problems in the kernel:</p>\n\n\t\t<ul>\n\t\t\t<li>\n\t\t\t<p dir=\"ltr\">Connection = thread/process. As a packet came in it would walk down all 10K processes in the kernel to figure out which thread should handle the packet</p>\n\t\t\t</li>\n\t\t\t<li>\n\t\t\t<p dir=\"ltr\">Connections = select/poll (single thread). Same scalability problem. Each packet had to walk a list of sockets.</p>\n\t\t\t</li>\n\t\t</ul>\n\t\t</li>\n\t\t<li>\n\t\t<p dir=\"ltr\">Solution: fix the kernel to make lookups in constant time</p>\n\n\t\t<ul>\n\t\t\t<li>\n\t\t\t<p dir=\"ltr\">Threads now constant time context switch regardless of number of threads.</p>\n\t\t\t</li>\n\t\t\t<li>\n\t\t\t<p dir=\"ltr\">Came with a new scalable epoll()/IOCompletionPort constant time socket lookup.</p>\n\t\t\t</li>\n\t\t</ul>\n\t\t</li>\n\t</ul>\n\t</li>\n\t<li dir=\"ltr\">\n\t<p dir=\"ltr\">Thread scheduling still didn&rsquo;t scale so servers scaled using epoll with sockets which led to the asynchronous programming model embodied in Node and Nginx.&nbsp;What Nginx says it don&rsquo;t use thread scheduling as the packet scheduler. Do the packet scheduling yourself. Use select to find the socket, we know it has data so we can read immediately and it won&rsquo;t block, and then process the data.</p>\n\t</li>\n</ul>\n\n<p dir=\"ltr\"><strong>Packet Scaling - Write Your Own Custom Driver To Bypass The Stack:</strong>&nbsp;The problem with packets is they go through the Unix kernel. The network stack is complicated and slow. The path of packets to your application needs to be more direct. Don&rsquo;t let the OS handle the packets.</p>\n\n<p dir=\"ltr\"><strong>Multi-core scalibility:</strong>&nbsp;</p>\n\n<p dir=\"ltr\">&nbsp;</p>\n</blockquote>\n\n<p>&nbsp;</p>\n\n<p>&nbsp;</p>\n\n<p>&nbsp;</p>\n", "authorId": 1, "subject": "architecture", "tags": [], "img": "", "summary": "string", "lastUpdated": "2021-01-26 07:37:52.927349"}